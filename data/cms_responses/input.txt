Christine Konicki: 
Over the past week, I built a bot named ShowerThoughtsBot (@BotShowerThauts) that uses a Markov chain to generate new shower thoughts from a collection of ~1000 posts to r/Showerthoughts. The tweets are meant to look superficially insightful while actually being quite nonsensical. I set the bot to automatically generate new tweets every 5 minutes so that I have a substantial arsenal of tweets to present to the class on Wednesday. You can see what my bot has written so far [here](https://twitter.com/BotShowerThauts).

I came up with the idea because I really liked the site we saw last class that generated gibberish philosophical papers from genuinely insightful ones. I knew that this kind of bot relied on Markov chains (a.k.a. a Markov bot), so it was up to me to 1) find a tutorial online that would teach me how to build one, and 2) determine what the Markov bot would read from to generate tweets. The [tutorial](http://www.pygaze.org/2016/03/how-to-code-twitter-bot/) was quite easy to find, and it took me less than an hour to download the libraries I needed and write the script described.

The hardest part, surprisingly, was deciding what I wanted my bot to scramble up and turn into gibberish. I thought about having my bot read from a text file full of great movie lines, full of lecture notes from one of my classes, or full of Pink Floyd lyrics. Ultimately, after checking on r/Showerthoughts on Sunday night and being incredibly amused by what I was reading, I decided to have my Markov bot read posts from the subreddit. The collection of posts consists of the most popular ones from today, from the past year, and of all time. Copying and pasting a thousand different posts into a single text file was as tedious as it sounds, but I had a lot of fun reading the posts (and then reading pieces of them as tweets and knowing what the original post said).

I was surprised by how a lack of grammar and consistent spelling/capitalization affected the bot’s performance. Before letting my bot post to Twitter, I ran my tweet-writing script in the terminal and printed out each new tweet. Several of them weren’t even real statements/sentences. I found that a significant fraction of the posts I included in the data source for the bot had no punctuation marks altogether, included them where they didn’t need to be, or contained typos/words that were spelled wrong. Misspelled words could be easily attributed to how they were spelled in the text file, so I fixed any misspellings before letting my bot post to Twitter. But because we rely on probability to let the bot choose how a sentence (or sentences) begins and ends when writing a new tweet (especially since several of the posts contained multiple sentences), it’s not incredibly likely that the tweet will be completely grammatically correct, even if all the posts the bot reads from *are* grammatically correct. So I didn’t bother correcting the grammar of any original posts.


Erik Stayton: 
How will we protect the future from our nuclear waste? This question has been addressed by a government commission, beginning in 1981, called the Human Interference Task Force; this group of physicists, social scientists, and artists was tasked with proposing a variety of ways to warn the future inhabitants of Earth about nuclear waste sites. How would you design a durable marker that lasts, and is interpretable, for at least 10,000 years? This question has taken on greater importance as we accumulate more and more of this waste, with limited progress in storing and securing it. Much of the waste currently sitting in spent-fuel pools at nuclear sites around the country will need to find a more permanent home, possibly within the New Mexico-based Waste Isolation Pilot Plant. 

WIPP, carved into a bedded salt formation in the middle of the Delaware Basin in New Mexico, stands as the most likely current storage facility for materials from America's nuclear program. But this site will then need to sit, undisturbed, for at least tens of thousands of years before the waste stored there will be considered "safe" (10 half-lives is the normal standard for safety). Human societies, however, are not stable on the timescale of thousands of years. Nations collapse, languages shift, and so the creation of durable and interpretable markers is an extremely difficult task. Among the many ideas of how to mark the site for the future, outlined in Peter Galison and Rob Moss's new documentary film, _Containment_, is the creation of a nuclear theme park above the site. The so-called WIPP World park, modeled off Walt Disney World, would include rides and amusements centering on the figure of Nickey Nuke, a mouse-like character with the face of a nuclear hazard sign. Our myths and legends are the most enduring aspects of past cultures, and so the idea of WIPP World would be to produce a self-sustaining mythos to educate future generations to the hazards below. 

For this bot project, I have created a program to tweet out as WIPP World (@WIPPWorldBot), the official Twitter account of this transhuman, pan-historical amusement park (though the program currently exists only on my local environment, not on Twitter itself). The @WIPPWorldBOT account tweets several kinds of message. One is an automated warning not to dig in areas contaminated with nuclear material, which provides information about the amount of time left until different types of material are safe. The messages count down from the date of release of Galison and Moss's _Containment_, as if it marked the sealing of the WIPP site. (Given the timescales involved, any difference between this date and the actual closing of WIPP will likely be no more than a rounding error anyway). The other kind of message is a remixing of tweets from actual Disney accounts, including @Disney and  @WaltDisneyWorld. Currently the bot uses a manually curated set of templates, based on actual Disney tweets, to advertise the magic of WIPP World's resorts and amusements.

Making this work involved a variety of assemblages. I needed to access date and time libraries in Python to get the current date. I had to use a date converter to turn human readable dates into seconds since the start of the epoch, in order to do time calculations for determining e.g. how much longer a nuclear material interred back in April 2016 will be considered unsafe. I had to make a rudimentary calendar that could associate the current month with the appropriate upcoming holiday to tweet about. Python's "random" library also gets significant use here to select items from the tables of templates and values. Most of my time has been spent improving the bot's tweets: going for quality has meant manually turning appropriate Disney tweets into templates rather than using a Markov chain, which necessitates significant labor on my part, as does the process of coming up with appropriate/artful/punny values to slip into the templates on demand. What was perhaps most surprising to me was not about the creation of the bot itself, but just how many source tweets actually work almost without alteration. Finding a tweet about an attraction that will "glow like never before" convinced me I had selected the right source material!

Why should this bot eventually end up on Twitter? Because Twitter is one of the obligatory social platforms of the modern business. Because Twitter is an ideal home for both the pithy and the self-servingly sentimental and fawning. Because Twitter is a perfect place to disseminate hourly or daily reminders of anything, which surely must include the nearly unthinkable dangers and timescales involved in the disposal of nuclear waste, especially as Twitter itself may not last through next year. There is a dark irony to an automated warning system that would only be useful thousands of years in the future, which is nevertheless built on a possibly dying platform. For all these reasons, Twitter is an ideal place for these messages to co-exist side-by-side: 

>There’ll be magic and there’ll be cheer at the new #WIPPWorld attractions!

>What’s 7 feet tall, cute, cuddly & coming soon to #WIPPWorld? Diggy the Nuclear Bear!

>#WIPPWorld reminds you that it will be 241100 years until materials containing PU239 will be safe. Don't dig!

Retrofuture 1950s amusement land meets 31st Century post-collapse dystopia on a platform of 21st Century Silicon Valley social media hype.

See the code and sample output here: https://github.com/estayton/WIPPWorld

See a few manually tweeted outputs at: https://twitter.com/WIPPWorldBot

Maria Temming: 
The bot I made this week was inspired by McCoy’s @ilikelikeilike bot. I was intrigued by McCoy’s idea (audacity?) to delegate something like humor—which we often think of as a uniquely human creation—to a bot. I wanted to apply this notion to another creative process we often perceive as uniquely human: storytelling.

Since McCoy outsourced comedy creation to @ilikelikeilike via simple formula, “I like __ like I like __,” I wanted to use an analogous formula for storytelling. Fortunately, Matt Stone and Trey Parker broke it down for me in [this video](http://www.theafw.com/blog/south-park-writers-share-their-writing-rule-1/). Every beat of a story, they say, must be linked by either “therefore” or “but.” So I designed a very simple web app that I’m calling [TwoBeatStoryBot](https://youtu.be/usPd9DDnd5k), which generates (upon each page refresh) short South Park stories with two basic beats—each subject-verb-object—connected by either “and therefore” or “but then.” (The stories are South Park themed only in that the subjects and objects of the beats are often South Park character names). Comparable to the way @ilikelikeilike’s output is only humorous by accident, TwoBeatStoryBot’s output is sensical only by accident, especially because of grammatical hiccups. 

Geiger says that bots work to “simultaneously produce and rely upon a particular vision of how the world is and how it ought to be.” In this case, TwoBeatStoryBot relies on Matt Stone and Trey Parker’s vision of what storytelling is and how it ought to work. Moreover, because the bot’s  reservoir of nouns is loaded with South Park character names, the bot perpetuates a South Park ‘verse vision of the world. 

The code for TwoBeatStoryBot relies on three primary outside sources (usual infrastructure comprising electricity/hardware/software etc notwithstanding): a list of 100 South Park characters [drawn from a South Park Wiki](http://wiki.southpark.cc.com/wiki/List_of_Characters), a list of 4400 of the [most frequently-used English nouns](http://www.desiquintans.com/nounlist), and a list of 500 [transitive and intransitive-with-preposition verbs](http://www.eslwriting.org/wp-content/esl-transitive-verbs.pdf). As we saw in the discussion of @ilikelikeilike, “word lists may seem banal but they are not neutral.” In addition to skewing TwoBeatStoryBot’s output to be more comprehensible by picking lists of familiar nouns and verbs, I also reproduced my own values in the bot by loading the list of South Park characters (from the many hundreds listed on the Wiki) to the 100 I was most familiar with. 

In terms of what surprised me while making this bot…as a novice coder, many things. But most notably, I had a whole new appreciation for Latour’s theory of work displacement—that even if it *looks* like TwoBeatStoryBot has replaced me in writing South Park fic (absurdist and bitesize as this fic may be), I actually just moved “upstream,” as it were, laboring behind the scenes in Canopy. But now that TwoBeatStoryBot is up and running, do I feel like there’s an automated labor theory of storytelling akin to the automated labor theory of humor McCoy posits? Does TwoBeatStoryBot’s output now give me, as a human storyteller, more time to think, using those storylines as jumping-off points? If so, is TwoBeatStoryBot a shitpost-y South Park kinkmeme generator? (This is not a question I ever would have anticipated myself pondering, so I’m counting it as a surprise.)

On the topic of who’s doing the writing here—me or TwoBeatStoryBot—I think these kinds of projects problematize prevailing conceptions of authorship, comparable to the way Geiger sees bots problematizing our ideas about internet platforms. Similar to the “metaphors of platforms and sovereignty” Geiger describes, I think there’s a common notion of writers as sovereign over the worlds they write into existence—that there’s a static nothingness until a human author intervenes. Bot storytellers undercut that idea, cranking out fictional content independent of human interference. Sure, I coded TwoBeatStoryBot, but only based on Stone and Parker’s story outline philosophy and characters, using online word lists and Alyssa’s help, etc. So, much like @LatourLiturgies, TwoBeatStoryBot is “as far removed from a single human author as bologna is from a boar.” Romantic ideas of independent human authorship: undermined. 

Maria Temming: 
Honestly, by far the most valuable resource for this project was @cetacean-needed, who patiently sat with me for, like, an hour and a half on Friday to help me make A Thing that would work—and was kind enough not to laugh or give up on me when I asked, about an hour in, “Okay…but what *is* Terminal?” Alyssa is the most wonderful. 

**SDQ1: profile any of the authors: their academic training, key contributions and conversations in their field(s), basically who they are and why they matter**

**SDQ2: review any of the academic readings: their contribution to scholarly debate, where the conversation was before / after publication, important responses and critiques, basically what this reading is and why it matters**

**SDQ3: frame your own question, and then answer it**

**DQ4: What role does Truitt think ideas about magic and nature play(ed) in understanding the mechanical in the medieval era, and how does this compare to how we understand the technological today? Have you ever experienced a "touch of that old medieval wonder" while using a technology?**

Erica Yuen: 
In medieval times, magic was used to explain how things worked if they seemed to be going against the laws of Nature. There were phenomena that went against their established logic and predictions based on their understanding of the world around them, such as magnets or astronomical events. Today, magic seems to encompass effects with “black box” inner workings. However, to people of the medieval era, magic was the bridge between them and the unknown. When the inner workings of something was unclear, medieval people used magic as a consistent way to make sense of the world, similar to the way we use science and physics. Those who were experts of the magical realm were viewed as the ones who would advance the technology of the era, as they were able to build new creations and explain different illogical events.

Today, when some new technological development is announced, the sense of “magic” and “wonder” is still present as the average person does not understand how it works. For example, when wireless battery chargers first came out to the market, they did seem almost magical to my parents. To them, they understood that electricity travelled through wires, but suddenly, with this new technology, it seemed to travel through the air. For them, when they can’t see something happen, it suddenly becomes almost like magic. 

Individuals who do not understand how something works form their own mental model of the mechanics of a device. With this uncertain mental model comes wonder. Something suddenly becomes less “magical” and more “scientific” as soon as you understand how it works. For example, when AI bots such as IBM Watson and Siri first came out, I found it crazy how the line between humans and computers was becoming more and more blurred. However, after understanding the mathematical models and the algorithms used to program these bots, they suddenly become less “magical” and simply just the product of brilliant engineering. 


Hi Erica - 

I think you're right that most people experiment that shift between the magic and the scientific when they know (or think they know) how something works. The weird implication of that conclusion is that, for any given individual, the magicness/scienceness of any particular phenomenon is not inherent in the thing itself, but rather their own subject-position relative to it.  

Christina Wang: 
Truitt writes about how people turned to magic as an explanation for technology during medieval times in Europe. From preternatural forces to demons intervening with human affairs, they applied what they did understand or came to believe to phenomenon that they couldn’t understand. Magic was seen as a concrete explanation and was widely accepted and respected. I was reminded of the alchemists of the medieval era, whose “science” and studies of turning base metals into gold was viewed as a reputable and valued profession. Truitt writes that even as Europeans began constructing and replicating automata that other people had been building for years, they simply, “added ‘mechanical’ to the list of possible explanations,” instead of ruling out magic as the leading cause. 

In my response to our readings about the hidden jobs of data janitors, I wrote of the “magic” of technology for those who don’t care to understand the details of how computing or algorithms work. This was proven by the companies’ efforts to keep manual content moderation swept under the rug in fear it would taint the image of ease and brilliance, or magic, that technology offers.

Yet at the same time, tech companies also want consumers to understand, or at least appreciate, the mechanical intricacies behind the products they create, since it adds credibility to their ingenuity. In the commercials for the [Microsoft Surface Studio] (https://www.youtube.com/watch?v=BzMLA8YIgG0) and the [2016 MacBook Pro] (https://www.youtube.com/watch?v=WVPRkcczXCY), both released last week just one day apart, the machine is dismantled and then reassembled in an almost theatrical manner, showing potential buyers the layers of mechanical parts and components that make up the machine, boasting about the reduction in volume without compromising performance. Here, there is a transparency behind the “magic” of technology — while a ordinary user may not understand what all the parts inside of their laptop do, they can appreciate the beauty and detail of the mechanical make up while building trust in a company that clearly knows how to handle their craft. It’s a different type of magic than the demons and preternatural forces from medieval Europe, but to a common consumer, today’s technology definitely still carries magical powers. 

Christina - 

The 'theater of the mechanical' is a really sharp observation. It reminds me of Penn and Teller, who famously deconstruct their illusions before they perform them, and then perform them anyway and people are unable to see how they work. 

Casie Chen: 
Truitt discusses how the novelty of mechanical creations lent itself to a sense of wonder, and science and celestial determinism were somehow intertwined (see the example of the prophetic robot, a product of a rare alignment 30k years in the making). He talks of the evolution of people's understanding of mechanics - from being on the very edge of natural law to being governed by it (the representation of Nature as a being vs. nature as an invariant).

In Geiger's piece "The Lives of Bots," he hints at the tendency to "fall into the narrative of technological determinism" when it comes to understanding what controls the technology we use (specifically, in this case, Wikipedia). The idea that bots are somehow individual actors that are still influenced by the sociopolitical leanings of the day, the creator, the environment, etc., are often masked, and thus can often make technology seem similarly "magical." So, too, can the invisibility of human labor which goes into technology, as we discussed several weeks ago when talking about the massively outsourced and contracted work of training the algorithms which identify explicit material. Even the discussion of musical preferences from last week is influenced by sociopolitical factors (re: "ethnic" or "global" music), which are masked behind genre definitions and defining of preference. To a layperson, all these things might be magical, or even invisible and not worth consideration, where certainly there is a lot more labor and decision-making involved than is at first evident.

Perhaps the most surprising "wondrous" thing that I have recently experienced is one of Tumblr's [shitpost generators](http://shitpostgenerator.tumblr.com/), which I can only assume is based on some combination of a regularly updated set of what the creator considers to be shitposts, and some generation of Markov chains based upon that set. It's surprising to me how reflective it is of certain things I commonly see throughout Tumblr ([references to self-care](http://shitpostgenerator.tumblr.com/post/151765411300/self-care-is-mailing-your-friends-fucked-up-babies#notes) and [mental health](http://shitpostgenerator.tumblr.com/post/148804731800/my-goal-is-to-post-about-depression#notes), [common typos](http://shitpostgenerator.tumblr.com/post/151397207256/i-am-a-dissapointment#notes), [kaomoji](http://shitpostgenerator.tumblr.com/post/150833630741/friendly-reminder-that-furries-love-to-get-sent-to#notes), and [comments on gender](http://shitpostgenerator.tumblr.com/post/146707506163/gently-half-ass-gender#notes), to name a few.)

Hi Casie - 

I think it's wonderful that shitposting fills you with wonder. One point I try to make in my article (not clearly, because that wouldn't be fashionable) is that the existence of markov-authored posts that read like the human-authored tropes we all see online makes me wonder less if computers have a kind of authorial agency and more whether *humans* do, or if we ourselves are better understood as networked, erratic mechanical shitposters made of meat. 

Charles Bachmeier: 
DQ4: What role does Truitt think ideas about magic and nature play(ed) in understanding the mechanical in the medieval era, and how does this compare to how we understand the technological today? Have you ever experienced a "touch of that old medieval wonder" while using a technology?




The dark ages/medieval era was the time period between the fall of the Roman Empire and the Renaissance that was characterized by violence, famines, and plagues. There really wasn’t any time to focus on developing new technology when one had a savage visigoth breaking down your door and stealing your food, property, and family. In addition, the only real education that would occur would be in churches and monasteries where although some science and technology was developed, it was all to benefit the church or Christianity as a whole. Few lords even received formal education in reading and writing, let alone in mathematics and science. Thus not only when a peasant but even when the typical feudal lord or king, like Charlemagne came in contact with sophisticated technology from the muslim Caliphates to the south and could not explain how it functioned they most likely viewed it as being powered by some unknown force of nature or even magic from angels or demons.




But know seeing as the common man does receive an education and most of this education is formed by studying cold, hard facts instead of what’s written in the bible, when your average Joe finds a clock, he knows it’s not run by the devil but has a mechanical mechanism in the back powered by a battery. In addition, thanks to the Internet nearly all our information is shared, thus even if Joe didn’t know how something worked he can look it up. Though there are some cases where a piece of technology is so advanced, say for example a smartphone, that the typical person doesn’t care how it works, just that it does and are perfectly happy with this blackbox system.




I had the chance at the last X-Fair here at MIT to try out the Oculus Rift and if you have been living under a rock for the past couple of years and are posting your reddit comments from a potato, it’s basically a very advanced for of virtual reality where you can experience a simulated reality right before your very eyes. In addition, many forms of haptic feedback have been developed allowing one to interact with objects and feeling like they’re really holding them. When I got to play around with this demo I truly felt like I was in a different world and it certainly felt like magic. I can only imagine what the reaction would be like if an average medieval peasant was given a pair and was toured through the VR goggles.


[The Oculus Rift is very effective](https://www.reddit.com/r/gaming/comments/5915i2/the_future_of_gaming_looks_painful/)

Sharlene Chiu: 
The main difference between magic/nature and the mechanical seemed to be intent. While the intent of supposed preternatural phenomena could be read as either good or bad, this intent still belonged to forces outside the human realm. Preternatural events or objects couldn’t be controlled by humans, only interpreted or warded off. On the other hand, mechanical explanations of machines placed the intent on the designer or operator. This in turn shifted control of the world toward humans. Those who were aware of the mechanics behind automata and such tools would be assured that the abilities of those machines did not reach beyond human capability. While people couldn’t control natural phenomena that occurred, such as weather or magnetism, the mechanical explanation of the world insisted that there was no intent, i.e. no targeted harm or good toward those affected.

The most illustrative example that Truitt provides of the varying interpretations of intent is the story about Borra and the mechanical Death. Borra most likely held magic to the same degree of validity as the mechanical, if not higher, which explains why his reaction was so intense. If the figure was a product of the preternatural as he believed, then according to the vaguely systematic categorization of preternatural phenomena, the figure of Death intended to carry Borra to Hell. However, had Borra leaned more toward the mechanical mindset, he would’ve feared the intent of the operator instead of the intent of unexplainable forces. Granted, if it was known that the operator actually intended to kill Borra, then Borra’s reaction would have most likely been the same. 

The role of intent also comes into play in today’s understanding of technology. People sometimes personify technology by saying things like, “My car doesn’t want to start today” or “How does Google know where I had lunch two weeks ago?” I’ve definitely asked the latter several times in my life. In these cases, people tend to overestimate the limits of technology. In a sense, they see devices and machines run on unknown forces. For the longest time, I didn’t question how a computer works. It just does. But because I wasn’t fully aware of what a computer could do, I wasn’t fully aware of what a computer *couldn’t* do. Many people seem to share this level of ignorance, which can strike fear in the masses when the dangers of surveillance and artificial intelligence are called into question.

On the flip side, today’s version of the “touch of medieval wonder” stems from that very ignorance. Professional magicians and illusionists, for example, rely on mechanisms and technology to pull off their performances. In this age, nobody in the audience would believe the performer relied on preternatural forces, but the wonder comes from not knowing how the mechanisms and technology work. 

Hi Sharlene -- 

You make a very sharp observation! I don't think Truitt talks a lot about intent. I suppose she might argue that magicians/wizards/gods were understood to have intent, too, and as Erik/Christine pointed out above, even medieval magic was still understood as a kind of professional human practice, even if an occult one, in many cases. However, what *kind* of intent or skill it is thought to be is certainly a factor in what distinguishes science from magic. 

Christine Konicki: 
According to Truitt, most people in the medieval era, when encountering a mechanical marvel for the first time, either acknowledged that "[they] could not imagine how it was done" or tried to explain it using the forces around them that they did understand. These forces were magic and nature, ranging from the normal interactions between our world and the heavenly cosmos to the insidious work of devils. Today, we would try to use logic and science and mathematics to explain the amazing things we don't understand. These tools are customary for us, whether we're seeing something that's mechanically advanced or something that seems to defy logic. In medieval times, nature and magic were the customary tools.

Magic, however, was considered a rigorous study and demanded a lot of training, much like the STEM world today. It was used to understand the things that were "preternatural" and defied nature. Later, as mechanical devices such as astronomy equipment--used to study celestial bodies--first appeared, unknown marvels became easier to explain. People still believed in the preternatural, so it was considered entirely possible for a particular phenomenon to be created by demons and magic. But another source of understanding was considered as well: mechanical automata. The more abundant mechanical automata became, the more people relied on them to explain the unexplainable; likewise, they relied less and less on magic.

I experienced "a touch of the old medieval wonder" the first time I messed with a particular song's pitch on Audacity. There was a song I liked called "The Spy" by The Doors. I opened up Audacity just for fun to mess with how it sounded. I should mention at this point that a lot of what I did to mess with the song came from my music theory background: For most instruments, I can hear exactly what note(s) are being played at any given time. I can also hear a piece/song and tell what key it's in (assuming the music I'm hearing isn't completely atonal or something). I bring this up because I knew that if I shifted the pitch a certain amount of steps up or down, the key would change, and I knew roughly what the key would sound like. For example, I shifted the pitch down by a single semi-tone because I knew I wanted to hear the song with a darker, more brooding tone. I was right about what I would hear, but I was still fascinated by the way the song sounded.

After doing this pitch jumping with a few other songs, I decided to reflect on how certain keys sounded and how the song itself seemed to change with the key. The funny thing was, all I did was compress or stretch the sound waves ever so slightly in order to change the frequency. But this somehow changed the entire feel of the song in question. I'd feel more of an emotional connection with the song, I'd feel like the song sounded "cooler," I'd suddenly hate it, etc. I'll admit that the way certain notes sound when paired together isn't exactly witchcraft to me. A lot of it has to do with the way music theory works and how notes are typically arranged together to produce a particular sound (for example, a major key vs a minor key). But the way the choice of key affects everything, however subjective this may be, still means that one distance between two notes sounds different from the same distance between two notes (each translated a certain amount up or down from the previous note). This, to me, is where the medieval wonder comes from. When you have a line of people and tell them to each take one step forward, everything seems more or less the same. So how does everything change when you do essentially the same thing to a song's pitch using Audacity?

Hi Christine -- 

I think you make some good points about the process of 'naturalization' / 'familiarization.' Which two words I'm quoting because, weirdly, they sort of mean the opposite in this case, or at least evoke it: it's strange to think about the 'naturalization', or nature-inducing, of technical or occult things, and while science and technologies are now familiar to us, witches had familiars, too :) 





Jenn Yu: 
During the medieval era, engineering theory and practices were less established (or unknown), so magic and nature were the most readily available tools for people to use to explain observed phenomena. Despite our modern perception of magic being something random and illogical, people in medieval Europe actually applied magic and nature in a systematic, almost scientific way, in their quest for understanding the world around them. Although Truitt acknowledges that the lack of mechanical knowledge was apparent in the thinking of western Europeans, he maintains that the method and theories that they did use to explain these wonders had much more important implications. Magic wasn’t a single solution; rather, it was a framework by which people made sense of their existing theories on demons, extraterrestrial forces, and other possible causes of preternatural phenomena. 

What’s interesting is that even as new technologies did spread, mechanics was just another 
“theory” that medieval Europeans would add to their investigative framework. A moving statue could be driven by a clever system of gears, or it could be powered by some demonic spirit. The framework that magic and nature created was so deeply rooted through time and culture that it took centuries for a mechanistic world-view to prevail over preternatural theories. There was still a significant human component to understanding the mechanical in the medieval era: “because of a range of possible causes…reactions to them in this late medieval period tended to depend heavily on the perspective of the individual.”

It’s difficult to get an actual read on Truitt’s conclusions about the evolving roles magic and nature play, as technology continued to advance. He observes that mechanical explanations started prevailing over magical alternatives, only to counter by noting that some preternatural traces still cling on in our society’s scientific world-view, and flip-flopping between the two. I think that in today’s modern era, our investigative framework is grounded by scientific laws and technology, and magic is a single component thrown in there for entertainment and thrill. Our society has become much more secular, proposing that there is a logical cause for every effect we observe. For example, we now understand weather patterns and can use previous data to project upcoming extreme conditions. Agriculture has adapted through this understanding, and we no longer believe that a bad crop is due to an unsatisfactory sacrifice to the angry weather gods.

That being said, I think the human in us will always want to believe there’s a little magic involved in anything that amazes us. I’ve definitely felt the touch of old medieval wonder when I used a VR headset for the first time, and my senses were overwhelmed by the perception of being in another place, despite my brain telling me that I was still sitting in the same chair. I’ve seen the same excitement light up my grandparents’ faces when we Skyped for the first time, allowing them to see me from 7300 miles away. Perhaps this is what Truitt meant in his flip-flopping thoughts: as science and technology advance further, they are in a dynamic balance with our human inclination to believe in a little bit of fun magic. 


Hi Jenn -- 

I think you're right that Truitt's essay sort of peters out at the end. I don't think she (she's a she, by the way) would contend that there was a move from magic-to-scientific as a useful way of ordering and understanding the world. I'm not sure, however, if the break has been quite so clean, not only between technologists/nontechnologists but even among technologists. Certainly few at MIT would ascribe a poor crop to an inadequate sacrifice, but I think many of us have little 'unscientific' folk theories of how or why or under what occult conditions aspects of our computers do / do not work (turn it off and turn it on again). 

I think you're also right that there's something powerful about the idea of enchantment that transcends the superstitious/scientific divide and somehow makes certain technologies *alluring* and *fun* in a way that seems not-quite-of-this world. 

Erik Stayton: 
DQ4: Ever surrounded by daemons: bots, background processes, and the recurrence of magic

It is amusing to read Truitt's descriptions of Europeans' reactions to various imported automata as being alternately enchanted or possessed by demons. We modern humans, of course, have exorcized such non-materialist explanations from our lives (we like to think!). But we remain surrounded by demons and the fruits of demonic labor. I refer, of course, to the background processes running on all our machines, part of the huge web of actors that make computing possible.

Bringing up my System Monitor right now as I write this, I see, specifically noted as daemons ("daemon" or "...d"):

bamfdaemon (matches application windows to .desktop files)

dbus-daemon (message bus daemon for D-Bus, a way for applications to talk to one another)

gconfd-2 (daemon for the gconf system that stores application preferences)

gdu-notification-daemon (??)

gnome-keyring-daemon (handling user security credentials)

gnome-settings-daemon (handling configuration of the window manager)

goa-daemon ("The goa-daemon program provides the org.gnome.OnlineAccounts name on the session message bus." Started by 
dbus-daemon! https://developer.gnome.org/goa/stable/goa-daemon.8.html)

a whole host of "gvfsd-X" daemons

ubuntuone-syncdaemon (syncing for the Ubuntu One cloud storage application, this despite Ubuntu One being obsolete as of October 2014!)

unity-files-daemon (this and the following apply to the Ubuntu Unity window manager)

unity-music-daemon

unity-musicstore-daemon

zeitgeist-daemon (tracks activities on the system)


These live amongst a variety of other "services" and long-running background processes with other naming conventions.

I have attempted to provide short descriptions of what these dameons "do", or, barring that, what the applications they are a part of do. But, to be honest, I don't really know. In order to really account for this I would need to do a lot of research, including looking into the code. I know from experience that for any one of these daemons, a look into the code would prompt me to explore the code of tens to hundreds of other applications, libraries, or system packages. The network of actors that is necessary for them to operate is almost certainly going to be larger, and stranger, than one would imagine. Notice also that even among this relatively short list of background processes we have already found one clearly responsible for starting another (goa-daemon is automatically started by dbus-daemon). And we have found one that is superfluous, having been rendered useless two years ago! (Which perhaps says more about how often I clean out old packages than about anything else.) 

These daemons---like Maxwell's daemon, performing background tasks whose mechanics are invisible (in general, unless for instance they break and render parts of my computer inoperable in suggestive ways) but whose actions, on balance, are observable in the bulk properties of the system---are not unlike the bots that Geiger looks at on Wikipedia. And like the Medieval-era automata, we are resisted when we try to ask how they work. As a rational person, I know they are not magical. And as a programmer, I even have concepts for how they might work. But generally I do not look into them to find out. I carry on in blissful ignorance, stopping to check my processes only when I find something running slow, or hear my fans spin up like they are right now (because xflux goes crazy after my window manager restarts, and pegs one core to 100%---I just "fixed" this with ">ps aux|grep flux; >kill -9 2889"). 

And for those who are less familiar with these workings, the aura of magic continues to be powerful. Neither my mother nor my uncle (who I have assisted with technical issues) actually believes that computers run by magic (though the existence of the phrase "don't let the magic smoke out" among computer technicians and hackers suggests there is a strong cultural persistence to this idea, even as a joke at the expense of the uninitiated), but that their operation _may as well be_ sorcery. If it were, it would be equally intractable. As with the philosophy of resistentialism (https://en.wikipedia.org/wiki/Resistentialism), it is tempting to endow the world with a sort of machinic animism, particularly a vexing, accursed nature, when things mysteriously go wrong. What is magic but something that is controlled and enacted by people whose knowledge we do not understand---the scholar, the sage, the wizard, the witch-doctor? Magic is something that requires a lifetime of training, and induction into the inner circle, in order to use. Magic is controlled knowledge. It is not so different than the professional knowledge of guilds or programmers. And it should further be unsurprising that magic has such power when we examine the magical language that researchers and companies trade in, in the public arena, to describe their work:  systems that "teach themselves," that "learn to have conversations," that can "understand scenes." This language erases the work that is done, and takes advantage of assumed notions of what "teaching" is, what a "conversation" is, what it means to "understand" that are by no means identical to how they are operationalized as technical categories. Magical language breeds magical thinking. When people are taught not to see the mundanity in these systems, but to treat them with an aura of deference to their mysterious workings, the notion of the "daemon" moves away from being a pithy technical descriptor toward a powerful force of ignorance. 

We are surrounded by technological demons. The literacy to unmask them, at least partially, is perhaps one of the most important skills for a politically-relevant engagement with the sociotechnical world.

Hi Erik - 

Thanks for this; the daemons/processes metaphor is a particularly good one, and I sort of wonder what the history of that naming schema is. Another, of course, is 'magic' as a part of what makes Ruby work. After this, I sort of have more of an interest in taking some of Graham's classes to think about the tricks of the trade / the trade of the tricks! 

**DQ5: Describe a bot that you have created and/or encountered and compare it to some of the themes, questions, or issues raised in the Strauss, Sinders, and/or my reading, particularly when it comes to the issue of social work.**

Jonathan Sun: 
I *need* to talk about three bots: @arguetron, a troll-baiting conversation bot, @tiny_star_field, a generative art bot, and @everyword, perhaps the first popular twitter bot.

1.

The [@arguetron](https://twitter.com/arguetron) bot is relatively new (made in October of this year) and incredibly socially relevant. The premise of the bot is simple: it tweets argument-baiting statements, intended to bait “Internet bros” – gamergaters, MRAs, Anonymous, the alt-right and others. Such tweets include “more than two genders exist,” “nothing true is ever said in gamergate,” “street harassment is real and also bad,” and “feminism is neccessary for the liberation of women,” “safe spaces are good.” If anyone responds, @arguetron will tweet at them context-free responses such as “you’re wrong,” “your sources aren’t trustworthy,” “I’d be rooting for you if I liked being wrong,” and “how are all these Julian Assange fans finding me.” In doing so, it’s baited many harassers into long arguments, where the harassers don’t realize they are arguing with a bot – to make things more tempting, the bot’s display name is a female one, Liz. The bot’s create, Sarah Nyberg, has tweeted some of the most hilarious interactions: [here](https://twitter.com/srhbutts/status/784159982426083328), [here](https://twitter.com/srhbutts/status/784162449347883009), [here](https://twitter.com/srhbutts/status/784172957207670784), and [here](https://twitter.com/srhbutts/status/785573619426480128).

Sarah was one of the high-profile victims of GamerGate, and has stated that the bot was made as a response to the harassment she received, and what she learned about interacting with trolls.

I think @arguetron is incredibly sophisticated because what it’s done is point out the ridiculousness of this particular type of internet troll culture – in showing that these people will argue for hours with a bot without realizing it’s a bot, @arguetron has ridiculed and embarrassed them. It shows how hypersensitive this culture is and how over-the-top reactionary they will be to anyone disagreeing with them. [Verge](http://www.theverge.com/2016/10/7/13202794/arguetron-twitter-bot-alt-right-internet-bigots-4chan-sarah-nyberg) even fantasizes of a future where there exists “an army of decoys, distracting the worst parts of the internet, giving everyone else a moment of peace.”

After revealing that @arguetron was a bot, the crowd tried to get the bot banned, but it’s still here. In the words of twitter user @sonaralee: [“No humor is off limits for the free speech anti-PC party unless it makes them look like idiots.”](https://twitter.com/sonaralee/status/788103993209696256)

More reading on @arguetron: [The Verge](http://www.theverge.com/2016/10/7/13202794/arguetron-twitter-bot-alt-right-internet-bigots-4chan-sarah-nyberg), [BoingBoing](http://boingboing.net/2016/10/10/alt-right-trolls-argue-for-hou.html), [Gizmodo](http://gizmodo.com/these-bigots-have-no-idea-theyre-arguing-with-a-bot-1787534271), [DailyDot](http://www.dailydot.com/unclick/arguebot-twitter-bot-bait-jerks/), [Select All](http://nymag.com/selectall/2016/10/sarah-nybergs-arguing-twitter-bot-exposes-trolls.html).

2.

As a palette cleanser, my favorite art bot is [@tiny_star_field](https://twitter.com/tiny_star_field). A generative art bot, @tiny_star_field creates randomly generated star fields outs of different variations of asterisk characters, and I think is very elegant and beautiful. There are a number of generative art bots out there (@thetinygallery, @unicode_garden, @choochoobot, @tiny_bus_stop, @tiny_cityscapes, @tiny_gardens), but @tiny_star_field takes the cake because of how simple and elegant its elements are (the other bots seem too cartoonish or baroque to me). Every time it appears in my timeline it creates a sense of peace and wonder. It’s close to that sense of “old medieval wonder” *NOT* because I don’t know how it works, but *BECAUSE* I know exactly how it works. I find the tiny star fields generated to be even more breathtakingly beautiful because I know how simple it is. Yet, for whatever reason, they still create a sense of wonder within me.  

3.

Another bot I’m totally fascinated with is [@everyword](https://twitter.com/everyword). It is such a simple premise. It tweets every word, in alphabetical order (and finished its task in 2014). I love it for two reasons. The first that it operates on such a simple yet brilliant dramatic structure: the ticking clock. Because of how simple it is, it creates suspense due to expectation. When it was running, it had an audience where people would wait for certain words then celebrate when those words were tweeted by the bot. There was a clear structure and set of rules that allowed people to cheer for the bot. Notably, the words that the collective internet cheered for the most were curse words and inappropriate words – another element here being the “will this bot *actually* tweet this dirty word?” dynamic, then celebrating when the answer was yes. The second reason is that people started using it to create other tweets – because the bot effectively tweeted every word, accounts would retweet specific words in order as a joke. They would use @everyword’s words to create sentences! Again, these sentences were subversive. A cursory glance at @everyword’s favstar page (a site that shows a twitter accounts more popular tweets) shows that the top tweets made by @everyword are, in order: bush, nine, eleven, did, the, is, me, my, i, you, sex, weed, a, up, fucking, vagina, fuck, shit, nudes, melt, fuel, steel, send, jet. What this shows, to me, is essentially a words frequency list for what twitter finds funny. You can easily piece together a few memetic joke phrases: “bush did nine eleven”, “send nudes” and “(does) jet fuel melt steel (beams)”, as well as the gleefully dirty words that could be celebrated without context. @everyword, to me, illustrates a bot paradox – the simpler the bot is to understand (and the less its able to be “broken”), the more fun can be had with it; the more complex the bot is, the more people will try to break it (ie. Tay) and the less fun there is in interacting with the bot.


This is a good rundown! Why don't you go last on the icebreaker tonight and tell the class about all 3 of these...

Kyle Saleeby: 
Before the industrial revolution, tradesmen were known by their deeds and the work that they produced. While this is still the case in many industries today (demonstrated by the popularity of review aggregators such as Google reviews, Angie’s list, and comments on amazon) it has become very difficult to trace a work to it’s creator. As Peterson points out about a joke bot in his article *I like my bots like…*, some seemingly simple tasks require “a massive network of engineers and standards and chips just to tell when it is time to make a joke.” In networks and communities of people that all play a role in a product’s production, no matter how small, who takes ownership of the results that are created is now, metaphorically speaking, up in the cloud. 

Twitter bots provide a fascinating backdrop for a discussion of the effects of unintentional consequences facilitated by remote users. Twitter bots are frequently designed and given permission to post on their author’s behalf. The functions of these bots range from whimsical, such as one that replies “WHAT?! NINE THOUSAND?!” to anyone whose tweet contains the string “over 9000”, to more serious bots that combine popular phrases and comments to post tweets that simulate the personality of a teenager. Each bot adds material to social media that otherwise might not be created simply due to time consuming and tedious functions that humans would have to complete by hand. 

While bots themselves are tool to be used for convenience and scale, their results are not always evaluated for impact. Peterson’s article mentions that the author of @metaphorminute (a bot that creates “absurd, evocative” metaphors with pseudorandomly selected words) was horrified when his bot created particularly dark metaphorical insults. But, is he to blame for the results of his creation? There are few who could successfully argue the author of a random generator could predict the number it would pick, but I would guess there was also significant backlash at the comments his bot posted. In this sense, a work is not always representative of its creator, but rather sometimes a random occurrence. Given the context of social media’s popularity, influence, and prevalence, we must question the unintended consequences of our creations to prevent harm from occurring.

It would be naive to blame the creator of a random generator for the content that was chosen, but on the same hand, as inventors, we must also be weary of the unintentional consequences of our products. Bots can create hilarious replies to those with a sense of humor, but they could simultaneously create potentially devastating quips to those unaware of the bot. For example, an argumentative bot could reply without hesitation to the extreme, continually inciting a potentially dangerous conversation. It is also equally perilous to restrict ourselves from creating tools and bots as many have the potential for doing good (such as the Twitter bot @Congressedits that posts when wikipedia edits are made from congressional IP addresses.) Instead of restricting the development of these tools, we must continue improving in a way that prevents harm. In all things that we publish, we must design with a goal to prevent the unintentional in mind. 

Kenny (Kenneth) Friedman: 
When I first joined Twitter in 2011, it was mostly to follow journalists (especially tech journalists). Quickly, I found a lot of these journalists to be re-tweeting random phrases such as “Their negativity only served to push me deeper into the realms of soap making.” And overtime, I noticed that most of them were from an account with a blurry picture of a horse, called [horse_ebooks](https://twitter.com/horse_ebooks?lang=en).

Horse_ebooks was a Twitter bot that appeared to quote random phrases from horse-based ebooks (the bot also had a link to a store to buy these ebooks — a website that looked like it hadn’t been updated since the 90s-era web design). Sometimes these phrases would be the end of one sentence and the beginning of another, sometimes they would just be a words. This bot, which seemingly had no purpose and no sense of humor, made people laugh and gained hundreds of thousands of followers. 

Similar to @ilikelikeilike, the entertainment value didn’t grow from any one particular line being funny. Telling any single @ilikelikeilike joke to someone at a party would surely not get many laughs. But in context, they are hilarious. For the @ilikelikeilike, the context is the randomness of a bot continuously trying the same joke with different punch lines, over and over again. Missing any single component of that context, the humor would be lost (or at least, it would be an entirely different thing). If it wasn’t a bot, if it was a comedian (say, Seinfeld) tweeting those jokes over and over again, I would unfollow after a day. If the jokes weren’t in the same format, and it was just a bot that randomly tweeted from a corpus of jokes, it wouldn’t be as funny.

The context is similarly important for @horse_ebooks. Horse_ebooks, as everyone knew, was a bot that tweeted captions from its catalog of horse focused books. People assumed it was created as a poor attempt to advertise these books. If anyone of those aspects were missing — it wouldn’t be nearly as interesting.  And it turns out — one aspect of its context *was* missing. In 2012, a Gawker reporter ( [cached version](http://webcache.googleusercontent.com/search?q=cache:PmBpiLMZjM0J:gawker.com/5887697/how-i-found-the-human-being-behind-horseebooks-the-internets-favorite-spambot+&cd=1&hl=en&ct=clnk&gl=us&client=safari) #thanksThiel) tried to track down the original creator, and found most of his basic biographic information. Then in 2013, [The New Yorker](http://www.newyorker.com/tech/elements/horse_ebooks-is-human-after-all) revealed that a human was in charge of the bot for at least the past two years. The bot wasn’t a bot after all, it was a digital piece of performance art by a BuzzFeed employee.

Suddenly, as the curtain was pulled back,  horse_ebooks became much less interesting. It lost thousands of followers (including myself). The feeling of an innocent piece of spam that was so absurd it became an online sensation was replaced by the feeling that horse_ebooks was a corporate, profit driven stunt.

It’s fascinating how much context matters in these types of systems. It doesn’t really matter whether or not it was a bot or a human, if the “readers” (observers?) believe it is one thing — the content was different once horse_ebooks was revealed to be a human, but the context changed and the magic was lost.

i am a full time internet 

Frankie Schembri: 

One of the most interesting bots I’ve encountered is @nyt_diff (“Editing the NewYorkTimes”), a bot that crawls the New York Times homepage, tracks changes to the articles that appear there, and posts the changes with highlighter marks on a Twitter account. The bot was created by an Argentinian web developer who goes by the name of Juan E. D., and, according to him, is based off of a similar, more comprehensive project called NewsDiffs which uses a bot to track changes in published articles on all pages of the websites associated with the New York Times, Washington Post, CNN, Politico, and the BBC. NewsDiffs was actually born out of a hackathon at MIT in 2012 and was recently archived by the Library of Congress as culturally and historically significant.
The developers of both bots provide links to their code on Github. Both bots work using the diff utility to track changes in the text displayed on the websites over small time increments. NewsDiffs is vastly more comprehensive and invaluable for anyone wanting to follow in depth coverage of a specific story, but I think @nyt_diff is more accessible and manageable to the average reader, and makes the changes more visually compelling.
The work of both these bots is closely aligned with the bot mentioned in the Sinders reading, in that they work to make transparent and visible some of the “invisible” activity on public information sites. In both the Sinders article and the news bots, the bots serve as watchdogs on society’s presumed watchdogs – the elected officials, the editors of online encyclopedias, and the reporters of news. However, the news bots are not concerned with who makes the edits as much as what the changes actually are. And news sites are not meant to be encyclopedic repositories of information like Wikipedia, they are much more time dependent and the home pages of international news sites have many more unique daily visitors than individual Wikipedia pages. 
As Latour would say, these bots do not replace the work of journalists and citizens in holding each other accountable in the process of making and disseminating meaning for society based on what is considered “newsworthy.” They merely displace some of the more tedious labor of sorting through changes in the wording of this news by delegating it to an automated entity. This collaboration with bots gives journalists and citizens more time to make sense of the changes in the articles and headlines, and the semantic, linguistic, and cultural ramifications of these changes. 
The work of these bots is of great personal interest to me as I am interested in the changing nature of journalistic work, especially how the field has evolved since the introduction of online journalism. Digital reporting and editing is much more continuous and fluid process than its print predecessors where once the paper was sent to print it was essentially set in stone, at least until the next edition came out. While there is little doubt that real-time updating is a great feature of online journalism and allows readers to be better informed in the case of evolving stories, unexplained corrections and mysterious changes in content can erode the reader trust newspapers are so dependent on. Bots like @nyt_diff hold news sources accountable to the changes they make to their online content and will hopefully encourage more transparency between the sources and their readers as to why certain changes are made. Beyond this, these bots offer a fascinating look at the way language is selected to express news and the way in which different words can give vastly different meanings to events.  Beyond forcing readers to notice changes in the news they are receiving, and forcing editors to own up to these changes, these bots offer readers a powerful lesson in the explicit and implicit meaning of language and the effect just one word can have on an entire story.   

I remember newsdiffs - it was made at the first civic media conference hackathon when I was a grad student :) 

I do think Latour would say some of this work is displacing, but just to be clear, I also think he would say that a bot can hold someone accountable as much as a journalist or a judge. It's one of the more controversial conclusions of his willingness to put human and nonhuman actors on the same plane of existence. 

Kenny (Kenneth) Friedman: 
> Digital reporting and editing is much more continuous and fluid process than its print predecessors where once the paper was sent to print it was essentially set in stone, at least until the next edition came out

So true. I recently found out that a lot generally well respected online publications (The Verge, Vox, WaPo, etc) A/B test their headlines, and then based on how frequently the articles are clicked, overtime settle on the most likely clicked headline as the permanent headline for a given article. For some reason, this just barely crosses the line of bot-generated content that feels slimily to me. 

More info: https://www.washingtonpost.com/pr/wp/2016/02/08/the-washington-post-unveils-new-real-time-content-testing-tool-bandito/

Mike Sun: 
I have an iPhone, which means that I come into regular contact with Siri, a voice-based personal assistant chatbot. In many ways, Siri’s social function is not dissimilar to Tay’s: to hold a conversation in natural language with the humans in its environment. Siri seems to have a default response structure to mundane requests such as searching the web or setting alarms, but can also parse other types of statements that suggest a deeper and more complex form of natural language learning and processing. However, this language learning seems to be structural and audial learning, not content learning, which narrows the set of tasks Siri can respond to and carry out, preventing Siri from meeting the same downfall as Microsoft Tay.

The biggest problem with Tay, as Sinders points out, is that “Microsoft didn’t leave on any training wheels, and didn’t make the bot self-reflective”, and so Tay’s neural algorithm [“didn’t know that she should just ignore the people who act like Nazis, and so she became one herself”](https://www.linkedin.com/pulse/ais-subconscious-mind-microsofts-tay-turns-racist-nymph-brandon-wirtz). As past events have demonstrated, it is often the initial training stage of deep learning that is responsible for inherent biases and content disparities. In fact, the East Asia branch of Microsoft released a carbon copy of Tay, Xiaoice, on Chinese platforms Weibo and WeChat last year, and the response was overwhelmingly more positive. In fact, Xiaoice still reports over [40 million users in China and Japan](http://www.theregister.co.uk/2016/09/29/microsofts_chatbots_show_cultural_differences_between_the_east_and_west/?imm_mid=0e93c0&cmp=em-data-na-na-newsltr_ai_20161010), likely due to the fact that Xiaoice’s beta testing (read: training stage) was carried out solely in China, whose digital culture already taboos the very extremist forms of expression that Tay learned from Twitter. In this case, the Chinese government performed the duties that Sinders delegated as the designer’s responsibility: enforcing a code of conduct with respect to certain kinds of language, expressions, and behaviors – allowing Xiaoice to carry out its intended social work.

One of the primary reasons why Siri has continued to succeed ties into one of Sinders’s principles of bots in social work – that there has to be some kind of content inequality built into the design of the interaction system. At a base level, Siri does not use unsupervised learning like Tay – if anything it is at best semi-supervised learning. This means that Apple engineers most likely preprogrammed Siri’s content filter and learning criterion, training it to respond to secretarial but not profane commands, so while Siri might be adapting to the sound of your voice, it is not adapting to the content in any way. Since it is a query-based natural language bot, Siri will understand and respond to most queries while producing a non-response when given declarative statements and failing to produce conversation, even when its responses would suggest otherwise. I tried multiple times – but Siri doesn’t seem to understand the [continuity between statements](http://imgur.com/a/s6J31). I can even repeat the same command multiple times, and if it is out of Siri’s jurisdiction of tasks, it will provide me with the same response. Siri is definitely a “safer” bot – using semi-supervised learning to understand some features of the people it is built to interact with, but having a one-minded goal and a corresponding content hierarchy built into its design that prevents it from falling victim to the same issues as Microsoft Tay.



Mike - 

I knew nothing about Xiaoice! But I think you're right to observe the role of the Chinese government (and taboos) wrapped up in policing that content. Will definitely ask you to talk about this tonight. 


**DQ6: What does Geiger mean when he says, in his pieces, that bots are a delegated order, and that not all of the code that runs Wikipedia runs on Wikipedia? How does his conception of what bots are / what they do support or complicate the idea of artificial intelligence and autonomous devices?**

Maria Temming: 
Geiger categorizes bots under the umbrella term “bespoke code,” which he defines as code that runs alongside a platform, not integrated into the server-side codebases by people with privileged access. This independently created code does indeed help run Wikipedia; its so integral to the platform, Geiger points out, that many of the features/functions users take for granted as inherent facets of Wikipedia aren’t actually included in the ‘stock’ version of MediaWiki. In fact, Geiger estimates that Wikipedia relies on 10 times more bespoke code than stock code—not including all the non-Wiki software that members use every single day to coordinate infrastructure/administrative tasks. 

Bots do a fair amount of work to keep Wikipedia running, inserting themselves into daily practices, but are not part of the “master plan” of stock code; rather, they are operated on computers independent of the servers hosting Wikipedia. Bots edit articles and engage in back-and-forth with human editors about changes; they create new content, enforce rules, patrol for vandalism, do general administrative work, and greet newcomers; and they contribute to the “hidden order of Wikipedia” by coordinating in WikiProjects, choosing featured articles, curating Did You Know and In the News sections, promoting users, and deciding upon article deletions, among other things. In short, much of the work done to run Wikipedia is accomplished by independent bots—although obviously the work of bots isn’t completely siloed from the work done by stock platfrom code: “together, bots and software platforms like MediaWiki are more than the sum of their parts.”

Acknowledging bots as important and prolific nonhuman actors on sites like Wikipedia, Geiger says, “complicates the common metaphors of platforms and sovereignty that we typically use to discuss the governance and regulation of software systems through code.” We typically think of platforms as spatial territories where code is law, developers are governors, and users are subjects. But recognizing work done by bots independent of the platform problematizes this idea of a static, coherent platform infrastructure—especially because bespoke code, like bots, can up and disappear in ways the platform code usually can’t (RIP, AfDStatBot). 

Without acknowledging the work done by bots, Wikipedia looks like some kind of mystically self-organizing system where every functionality is baked into the stock code—just as sleek and neatly automated as the tech companies in “Justice for Data Janitors.” Acknowledging the hidden work done by bots (and the people who create them and all the other infrastructure that supports them) complicates that notion.

Geiger, because he thinks of bots as social actors, also argues that “understanding how code operates in a social context requires more than parsing through lines of PHP and decoding algorithmic instructions”—aka, what an AI *really is* is not just written in its code. A defining aspect of an AI is also the environment/context under which it’s developed and deployed. “The ways in which the artificial agent appears to the use are just as important and essential as the code behind it,” Geiger says (Sinders would probably agree). AIs not only impact/complicate the world around them through social networks, but that they too are impacted—defined, even—by their interactions with other human and nonhuman actors.

Thanks Maria! Curious: what did you think of Geiger's bespoke-article, including the little vignettes? 

Maria Temming: 
I really liked that he took this opportunity for a meta-style to include the vignettes--especially because I think they take a different angle on the "bots are more than mere code" argument, which I'm not sure Geiger even knows he's making. In the standard-style components of his essay, Geiger talks about how bots shape/are shaped by the social interactions they have with other actors in the communities they join, like Wikipedia. But the personal vignettes speak more to how bots are shaped (and shape in return) the humans that make them. Like, obviously Geiger's stories talk about how he shaped AfDStatBot, but also these little phrases like "my bot and I" and "my bot *died*", and talking about the user profile his bot had...Geiger might have been way more upset about his breakup than the death of AfDStatBot, but he clearly had some deeply felt connection to this personified piece of code, and it also shaped the way he interacted with the Wikipedia community. So, in addition to saying bots and platforms are more than the sum of their parts, I think the vignettes allude to the idea that bots and their creators are more than the sum of their parts. (I feel like there's a Big Hero Six reference to be made here, somewhere...)

Also, I just really like this idea of the care and keeping of bots, and the sense of protectiveness that sometimes comes with it (like with Tawker and AntiVandalBot). As someone who has never created a bot--but has definitely gotten very attached to stories I've written--I feel like I know better understand the human experience of making a bot. And intimidated as I am by having to code my own, it makes the prospect of forging something new more exciting, and more akin to my own creative experiences.

Daniela Morin: 
Bots are a delegated order because people, programmers and developers and site administrators content contributors and the masses of people online who voice their opinions on the efficacy of the imposed infrastructure on informational sites such as Wikipedia, are widely thought to be solely responsible for the maintenance of these sites. 
Bespoke code challenges many of the default assumptions and discourses of platform sovereignty that underpin public held opinions about the sociality of software…”wikipedia’s ‘minimally regulated’ peer production environments actually rests on top of bespoke code that has been specifically developed to produce sustain and enforce particular understandings of what the wiki way is and ought to be.” 
This disrupts the widely held public notion of automation and AI being separate entities of self governance with their own means and agendas and dismantles the idea of sovereignty as the ideal method to conceptualize the modes of power that operate within the sites socio- technical infrastructure.
Geiger “Platform” implications of spatial abstraction represents the criteria by which these technologies will be judged in the public imagination the familiarization and evaluation of theses technologies by the masses and its effect on the progress and efficacy of the program is not to be underestimated.
The power dynamics between the bespoke code of bots that run on wikipedia is not compatible with the platform sovereignty  conceptualization because it undermines previously held assumptions people have of such relationships. “The ways in which the AI agent appears to the user are just as important and essential as the code behind it…..Abstract high level seemingly immaterial entities like art, culture science truth profit etc. all rely on materially existing infrastructures, artefacts people and practices often operating behind the scenes that often fundamentally shape and structure how those seemingly immaterial abstractions operate.”
It seems that Greiger wants the public to keep in mind the reality of the ‘hidden’ order of wikipedia is actually largely maintained by work done by bots instructed by bureaucratic and formalized procedures implemented by human programmers, developers and administrators. 
Bots subvert the fundamental idea that wiki pages are documents that users edit, undermining the concept of wikipedia being minimally regulated ‘laissez faire’ mode of production that assumes the ‘wisdom of the masses’ self regulates it. 
This argument  is highlighted by the sharp contrast between the 600,000 lines of code that makes up mediawiki the software platform of wikipedia and the estimated 6 million lines of bespoke code that runs wikipedia but does not run on it.
I think Geiger is trying to justify and gain recognition for his under appreciated/ unrecognized bot’s role and his intentions in implementing it as part of the ArbCom member by employing Latour’s scholarship to demonstrate that the bot is an integral part of the functioning of wikipedia and should be merited and acclaimed as such. 

**DQ7: Compare, contrast, or complicate the relationship between platforms and the labor that enables them as described by Geiger and me this week vs Latour, Irani, and Chen from a few weeks ago.**

**Thread for SDQ1: profile any of the authors: their academic training, key contributions and conversations in their field(s), basically who they are and why they matter**

**Thread for SDQ2: review any of the academic readings: their contribution to scholarly debate, where the conversation was before / after publication, important responses and critiques, basically what this reading is and why it matters**


**Thread for SDQ3: frame your own question, and then answer it**

Maria Temming: 
**Gupta and Ferguson describe/identify the flaws in the cultural critique mode of anthropological study—(how) does this apply to Ingold’s essay?**

Gupta and Ferguson describe cultural critique as a dialogic relation wherein examination of an “other” culture abroad provides a new critical viewpoint on “our own culture” at home. Ingold’s essay adheres to this description by drawing on examples from cultures around the world that seem to exhibit wayfaring qualities—often cultures that have been examined through the eyes of other Western scholars before him (i.e., the unnamed Canadian writer who studies Inuit people, or the Australian James Weiner who studies Foi people in Papau New Ginea). Ingold then uses these examples to scaffold his argument about Western people in modern metropolitan culture, to critique the way they live their lives as transporters and suggest that “we might do better to revert from the paradigm of [transport] to that of [wayfaring].”

Moreover, according to G&F, cultural critique assumes some pre-existing segregation between distinct cultures. Ingold’s whole argument, drawing a contrast between wayfarers/transporters, hinges on the idea that there is a “fundamental difference not only in the dynamics of movement [between wayfarers and transporters] but also the integration of knowledge.” He uses the example of Inuit people moving *along* paths through the world and British people sailing *across* it, and says that these “are lines of fundamentally different kinds.”

G&F argue that one problem with cultural critique is that there’s an implicit “we” perspective throughout the study—“we” being the author’s perceived home-base culture (i.e., line from Ingold’s thesis quoted above). Ingold continually situates himself in a Western cultural perspective by referring to things like “the Royal Navy,” simply assuming his (likely British or otherwise Western) readers will understand he means the British navy. G&F say that it’s not good enough for an author to simply replace “our society” in the text with the “ethnographer’s society,” but that’s pretty much exactly what Ingold does: in his thesis, Ingold talks about “people in modern metropolitan societies,” skirting the fact that as a man living in Aberdeen, UK, this demographic (I assume) includes him. 

Another problem that G&F have with cultural critique is that “once excluded from that privileged domain ‘of our own society,’ ‘the other’ is subtly nativized—placed in a separate frame of analysis and ‘spatially incarcerated’.” This kind of “spatialized understanding of culture difference” happens repeatedly in Ingold’s piece, when he refers to “*an example from the other side of the world*…Batek women *from Pahang*,” “Orochon people *of north-central Sakhalin*,” “the *Australian Western Desert* Aboriginal people,” and so on. All the illustrative examples of wayfaring cultures are inextricably tied to a geographical location. 

What’s more, G&F say that these “other” people are often cast as “primordial”—an idea that seems to resonate in Ingold’s argument about wayfaring being the most “fundamental” way to live (that it’s the way *animals* live), and that people in Western metropolitan societies need to “revert” to this more natural way of living, the way these “other” people around the world still are living. G&F state that “other” cultures are also portrayed as “survivors” of history, rather than producers of it. The way Ingold talks about wayfaring peoples does make it seem like technological development is happening *to* these “other” people, rather than *by* them (“today the wayfarer may even drive a machine”!). 

Ingold does say that in his “meshwork” model, “there are no insiders or outsiders, only openings and ways through,” and that wayfaring people are neither aimless wanderers nor people confined to certain locales. But no matter how much he insists that he views wayfarers as “neither placeless nor place-bound but place-making”…is this idea really reflected in the rhetorical choices and exemplary building blocks he uses to construct his essay? I’m not so sure. From what I can tell, the Ingold essay fits more the mold of cultural critique that G&F find fault with. 

Maria Temming: 
I feel like I'm being really down on Ingold here, but just to throw it out there, I really enjoyed his essay. I read it just after typing up notes from an interview with Ethan Zuckerman, who was telling me (in the context of talking about graduate school/deciding what you want to do with your life): "I think the whole point of being in your twenties is that you do keep changing what the shape of your arc is going to be. If you’re not changing the shape of your arc, you’re probably not thinking about it enough." I feel like Ingold's essay is just one long, meandering way of saying precisely this, just on a bigger scale. So, noted--live each era of your life like a flourish, not like a line in connect-the-dots. 

Erik Stayton: 
SDQ3: Of similarity spaces, meshworks, and filter-bubbles: is there anything computationally in the "meshwork" concept that justifies or makes possible other useful information cartographies?

Classifiers, as Seaver's introduction makes clear, work with intangible spaces, imagined geographies of characteristics. From what is essentially the simplest classification algorithm, k-nearest neighbors, up to word2vec and other more complex representations of linguistic content (the area I am most familiar with), classifiers exist to assort objects and make quantifiable and useful some notion of "distance" between them. But the choice of the features, and the distance metric, is always up to the programmer, and must be chosen based on the desired outcomes. And this, to me, is the key point about algorithmic classification: the metrics to use need to be chosen based on external factors, and this means there is ideally a lot of subjective leeway in terms of the programmer's choice; however, in practice, choice is often further constrained by the goals of the project. Whether that's accuracy of POS tagging or recommendation success, the measure of success is not entirely arbitrary. Spotify's imagined geography is particularly "successful" because people find it knows them so well that it is uncanny; though one could produce innumerable classification geographies for music--such as one that associates songs most strongly based on date of release--these different geographies will have markedly different effects on listeners: they will be received with various levels of business success. The point of Spotify's classification is not merely to introduce listeners to new music, or music that is "good" for them, but to make Spotify more money. Questions of taste are ultimately subservient to questions of value:  what classification is most effective for making Spotify an indispensable part of listeners' lives?

So if we are going to consider how meshwork geographies might compare to similarity networks, we also need to consider how they might be received and who they might best serve. A "meshwork classification algorithm," if such a thing were to exist, would need to tangle trajectories together rather than associating points in space. So individual components of data would not be individual songs, with tens or hundreds of discrete characteristics, but some kind of path through space. One such path could be the nearly-continuous (thanks digitization!) sound wave itself, such that each song makes a path through a space of tempos, moods, pitches, instruments, and other properties. Crossings of paths become sites of interest, and sources of recommendations. Alternatively, the paths could be those of artists themselves, who over time wander through genres and labels and levels of popularity. Again, the process of recommendation becomes one of moving along the path and finding the other items with which it crosses or intertwines, and then following those, etc. Would such an algorithm be an effective recommender? Possibly. Would it produce the same playlists that Discover Weekly does? Almost certainly not. It would be an interesting experiment to program some of these and see what happens, but there is no reason to think they would produce "better" results from the point of view of Spotify--possibly more exploratory, and more eclectic, but likely with more misses. While the idea of the meshwork might pull together more items that, in traditional classifying cartographies are relegated to far-flung corners of the vector space, this presents the same kinds of issues as the "filter-bubble." Whether or not it is good for us to be exposed to some ska punk because it crosses paths with The Lumineers somewhere in our classifier is beside the point if we ignore such juxtapositions as "misses" and go searching for the musical homophily we wanted in the first place, perhaps because it is easy and comfortable, and does not shake up our ideas about the world. The business case for the meshwork classifier is very much up for debate, but I think this is an interesting point of discussion regardless.

**Thread for DQ4: what is the difference between a network and a meshwork? Thinking about this class, how might “meshwork cultures” be different from “network cultures”?**

Jonathan Sun: 
Ingold’s piece and the discussion here brings up a question for me in specifying not only the difference between network and meshwork, but what a “social network” is in comparison to a “social meshwork.”

We are familiar with the concept of the social network – offline and online. Online, social connections are made explicit – imagined (or sometimes literal) lines are drawn between individuals or entities which have a social connection. We are incredibly familiar with this structure and language. The dots, the points of data, are usually people. We can even define the network paths between these points using a number of different values along a spectrum of intimacy: mutual, one-directional, neutral (neither follows the other), or negatively-weighted (muted, blocked, etc.). This is the language with which we all understand social relationships. It is person-based, and in a sense transport- or destination-based given Ingold’s definition – look no further than the concept of “6 degrees of separation” to understand how origin-destination transport plays out on a social network. Whether or not due to online social networks and social media, I believe this way of understanding people and relationships is intuitive to us. “How do you know them?” “Who do you know here?” “Oh, I met them years ago through a close friend.” 

In relating the network and transport, and in relating meshwork and wayfaring, Ingold essentially argues that network/transport as some sort of abstraction or perhaps reduction of a more complex set of processes: meshwork/wayfaring. I believe this holds for social networks and a concept of social meshworks as well. I hesitated to adopt the term “culture” for this response because, in a sense, I believe the “social meshwork” of the “social network” *IS* “network culture.”

Meshwork seems to refer to the more “knotty” relationships and is what can be reduced to a network. It is the continuous line versus the network’s discrete set of connected points. The social meshwork, then, is all the complexity of social relationships that is reduced down to the social network. If the social network of Twitter is, perhaps, a connect map of users, creating communities, the social meshwork is all the tweets of all those users, all the users who interacted with all the tweets, and all the measurable and immeasurable social effects of those tweets. In Ingold’s meshwork-network analogy – we too don’t study social meshworks because it is simply far too much – it must be abstracted or reduced to measurable relationships – the social network.

If the social meshwork is “the social everything” that we can’t contend with, at least we are able to observe artifacts that come from it. For example, I would see trending hashtags on Twitter as closer to the meshwork than the network – it arises and is the product of the culture of the network. Similarly, Every Noise at Once is a measurement of the meshwork of the discussion of music – whereas the network in the analogy is… what, I wonder? The actual measureable relationships of songs to artists, or songs to playlists, perhaps. 

In this sense, I would say that the complex reality of our social world online is the true social meshwork, whereas the social network is our attempt to understand, describe, and simplify that complex meshwork. Now that we have done a pretty good job at that, we start to add complexity again and venture into trying to understand the meshwork.


Erica Yuen: 
While both a network and a meshwork are representations of a mass of connections, networks focus on the points that are connected, whereas meshworks focus on the connections themselves. So, in networks, the source and destination of a connection is more important. For meshworks, the properties of the journey to the destination is more important. Networks are often designed to make a connection is straight-forward as possible, but meshworks are given more freedom in their formation. In his article, Ingold draws an analogy of this concept to wayfarers and transports and their goals. Transports move as if they are in a network; they only care about if they reach their designated destination.  On the other hand, wayfarers enjoy the journey and unplanned experiences. 

Due to the disparity of freedom levels between the two representations, there is also a difference in efficiency and design between the two. Since networks focus on making a connection from point A to point B, most likely to share information, networks are engineered and planned. For example, in terms of the Internet, email would be an example of an engineered network infrastructure that fulfills the main purpose of connecting two parties efficiently. On the other hand, meshworks are given opportunities to develop on its own; their future properties may be hard to predict and be surprising. Examples of a meshwork in an Internet context would Youtube: users are given a platform to freely create content, which inspires other users to make new content. Over the years, content has evolved and branched out: there are DIY tutorials, news videos, videos of people falling over, viral challenges, etc. Youtube provided a platform to connect viewers with video makers, but the freedom allowed it to change over the years. 

This class, “Network Cultures,” focuses on the defined infrastructures used to design the Internet. We talk about thought processes in the design of the Internet and how bodies of government and companies apply laws and moderation to guide the way it connects people with others. We talk about the algorithms used to control the connections, and the sources and destinations of the connections when we focus on the people using the internet. In the context of this class and the Internet, a “Meshwork Cultures” class would focus on how the Internet evolved and changed given the freedom to do so. We would focus on the journey of information as it eventually reaches new people over the world, and possible forms of the Internet in the future.


Christina Wang: 
Most dictionary results of meshwork actually include the term network in its definition, along with the idea of it being a physical structure of interlaced material. By the second definition then, a meshwork is something more tangible and identifiable than a network, while a network is an intersection. While this highlights similarities between the two, they are both still fundamentally different. Ultimately, this difference lies within the subtleties between “interlaced” and “intersecting.” Something that is intersecting is crossing paths; intersecting trails are connected to one another despite each trail maintaining its uniqueness of an individual journey. Meanwhile, something that is interlaced is interdependent; the existence and identity of one line or route is imperative to the identify of another within that meshwork. Together they create one larger picture.

According to Ingold, networks are the connecting points of intersecting paths, unlike a meshwork of interwoven trails. The focus of meshworks is on the entanglement of lines rather than the clean connection of points (as shown in Figure 3.1). Ingold contrasts “two modalities of travel” to stress this distinction: wayfaring and transport. A wayfarer explores by foot, cherishing the journey regardless of the destination, focusing on the interactions between others whom they bump into upon on the trail. In contrast, transport is just a means of getting somewhere; events that happen in between are not the focus. The entanglement of a meshwork also applies to its literal definition of a physical interwoven structure. A net or a fence is held together by joint material. If you took apart all the smaller pieces, each’s existence would not be as significant. 

Ingold emphasizes the differences of the two, arguing that Chatwin mislabels the Aboriginal country as a network instead of a meshwork, which embodies a more distinct sense of community. While our class is called “Network Cultures,” I actually think we cover topics that include both meshworks and networks. A lot of the ideas we read about are on the connections people make through the internet and other technologies. These connections create a network; they are forms of transportations that users take in order to reach their destinations of getting in touch with one another or for conducting research. Yet at the same time, people also find meaning or conflict in the interactions themselves. We looked into the hidden jobs of data janitors sieving through Facebook posts, and teens turning to web forums to learn more about themselves and their sexuality. We also look at the algorithms that dictate the results we get at a “destination.” These all make up a meshwork. I picture meshworks and networks on a venn diagram where our class lies somewhere in the space between the two overlapping circles. While the focus of each is slightly different, it’s inevitable that a course about people’s interactions with the internet will dip into both categories of meshworks and networks. 

Charles Bachmeier: 
DQ4: what is the difference between a network and a meshwork? Thinking about this class, how might “meshwork cultures” be different from “network cultures”?


Ingold makes the distinction between a meshwork and network by describing a network as a well planned out series of connections between points that interweave between each other. Where as a meshwork has a much more free form feel and although it is made up of lines connecting points like a network, the main difference is that little to no planning went into its creation thus the line may not be straight instead bending and twisting in random fashion and the path from point A to point B may not be the most efficient. Ingold describes meshworks as the common default for human beings as demonstrated by Aboriginal people in Australia, where borders are not stagnant and destinations move around. But networks are often created when someone or some group wants to bring order to an area thus make hard borders and pathways linking people and resources.


A good example of the difference between a meshwork and a network are the streets in Boston compared to NYC. Boston’s streets were based on old cow trails, thus they weave in and out as cows are not the best at urban planning but NYC was made to be a very efficient city that controlled a lot of wealth and power. They needed people to get to and from their places of business quickly or else lose money, thus the street plan is a near perfect grid or network.


I think most people would agree that not a lot of planning went into the organization of websites, the endpoints, if you will, of the grid, and there was no person or organization who tried to create this perfect organized and efficient Internet roadmap. Even if they did, humans would get distracted by Youtube, Reddit, and Tumblr and begin to meander, getting lost into the Internet wormhole with no regard to any predesigned road plan. However because there are no hard lines and barriers on the Internet (for the most part) like there are for city streets, ‘short-circuits’ could be made to connect one point to the other. If you know what site you want to go to you can enter into the search bar and you’ll get there immediately. This is why business is still incredibly effective online and a dominant force in the world’s economics. Thus the Internet is a giant meshwork web with a seemingly endless number of points making it feel very free form and not too structured but still maintains the ability to quickly get to a desired location making it still viable for companies to conduct business.


Daniela Morin: 
I think the analogy between NYC and Boston streets was spot on in describing the infrastructural differences between networks and meshworks, and also agree with an earlier post that the paths of interest users take, rather than the online "destinations" are of more importance to corporation in the business of personalizing someone's experience i.e.- music industry and song recommendations. Perhaps they may be shaping the contents ( music/ songs and beats) to be more easily categorized, tracked and recommended to become more widely heard and liked for the benefit of the profit driven corporation, which may be the cause of the recent and annoying digitization of music which is overriding the quality of music and suppressing actual human talent in favor of ratings and popularity. It is also interesting to consider how such algorithms like the google rank algorithm has come to determine the "paths" that users take in their search for knowledge upon typing in a query in the search engine, and how these come to influence the path the user will take in their search for specific questions and curiosities depending on the accessibility and what the user finds relevant to their query. Hyperlinks of recommendations "you may also like"... highlight the advertising industries attempt to establish and narrow out a more predictable network out of the innumerable possibilities someone might take during their time on the web, finding an opportunity to fill a gap that the user may not have considered yet by deviating attention from the current place to the next possibility, without the users consent to do so. 

Mike Sun: 
A “meshwork”, as philosopher Henri Lefebrve defined it, is defined by “the reticular patterns left by animals, both wild and domestic, and by people (in and around the houses of village or small town, as in the town’s immediate environs)”. The main difference between a network and a meshwork, and the reason Ingold objects to the classification of Aboriginal country as a network, is the same distinction Ingold makes between wayfaring and transport. On the surface the two may appear very similar – both are constantly moving from place to place, but Ingold states that the main distinction lies in how their paths are defined – travelling across a trail versus travelling along it. A transporter’s path is defined by a series of pointwise destinations – travelling from point A to point B, without necessarily giving any attention to what path they are taking or what lies along the way. In the cultural sense, Ingold characterizes a transporter’s life by a series of destinations joined with shortest-path edges by the commonality of the being that walks them. When two transporters collide, since the goal of transport lies solely in its destination the resulting interactions are often detached, fleeting and merely by chance. A network operates under the same underlying principles – we can see this in today’s technological networks, which are defined by their nodes (pointwise locations) and the operations that take place at them. 

In contrast, a meshwork is more closely related to Ingold’s portrayal of wayfaring – transportation with no destination. Ingold uses an analogy of line diagrams to represent the difference between networks and meshworks. In a network, the focus is on the points. Points exist in space, and lines connect the two in the most direct pattern possible, and if two lines happen to touch, that’s merely due to coincidence. However, in a meshwork, the entire focus is entanglement, and that’s why when two lines cross in Ingold’s meshwork, they travel together for a bit. A meshwork is much more focused on the journey than it is the destination.

We can extend the definition of networks and meshworks to cultures and the various topics we studied in class. In our class, even though it is called “Network Cultures”, I would argue that we study a little bit of both. A “network culture”, under Ingold’s definition, would probably refer to a subsection of culture defined by tasks and the shortest-path algorithms that solve them. Going back to two weeks ago, one of the reasons Grimmelmann thinks search cannot be made transparent is because it is inherently a network culture, not a meshwork culture. When I search for something on Google, I don’t necessarily care what parts of the algorithm play into which search results, because in the end, I am only interested in getting quick results, and it doesn’t matter so much that the results are objectively the best, but rather that they are useful or good enough given the time spent reaching them. For the overwhelming majority of search engine users, time spent immersing themselves in the algorithm’s inner workings is time wasted – they are only interested in the answers and how fast they got them.  

On the other hand, “meshwork cultures” are more related to interaction-based technology, and the paths that various users take when using them, much like Ingold views the Aboriginal country. One example of a meshwork culture would be social media. I can’t tell you the number of times I (and, as I’m sure, many other people) have logged on to Facebook with no set goal in mind. I talk to a friend here, tag people in memes there, and suddenly I’ve wasted three hours. This immersion is at the very heart of what Ingold defines a wayfarer as – travel and interaction for the sake of interaction, with no set objective or destination. When we study meshwork cultures and technology, we are looking more at an ethnographic study, as Seaver would put it. We study how users interact with one another, how they use the technology, and how the cultures of the workplace and of society affect the culture being studied. 

Christine Konicki: 
The difference between a network and a meshwork is a matter of focus. In a network, lines are made to connect different points together, and we may not necessarily focus on how the lines touch each other, how straight or curved they are, etc. In a meshwork, the entanglement of lines are the focus, regardless of whether or not the lines connect specific nodes together. Ingold compares the lines of a meshwork to “trails” and the lines of a network to “routes,” which I think is a perfect explanation. You may follow a trail to get from point A to point B (e.g. on a hike), but the interesting part about the trail is what you see while you’re on it. You may follow a route (e.g. a highway) to get from point A to point B, and the transportation is just that: transportation. You don’t care about what you see on the highway.

In fact, when I think of a meshwork, I imagine a piece of knitting, crochet, or macrame. I imagine tracing my fingers along the yarn, transfixed by the paths it takes. I don’t care so much about moving my finger from one end of the design to the other. When I think of a network, I imagine a graph with nodes and edges, much like one would find in 6.006 or 6.046. I imagine mapping out what edges map particular nodes together, seeing whether the graph is directed or not, and noting the weight of the edges. I don’t care about the shape or the weaving of the edges.

To extend this definition to the name of our class -- “Network Cultures” -- I think that we call the class by this name because we don’t care about how the connections between different pieces of the Internet intersect or what kind of paths are taken to connect people, websites, apps, products etc. together. A lot of that comes from the fact that this class isn’t highly technical. We talk extensively about algorithmic systems, about the ways that information gets from one place to another, etc., but we don’t talk about how a call in some code might travel through these systems. We don’t know about where exactly it would go, what kinds of databases it would pull from, how many iterations it would take to do something, etc. And we certainly don’t know what kinds of calls would have these things in common with each other. If this class were called “Meshwork Cultures,” then I think we would care much more about these kinds of things, and the readings would be more technically oriented.

But we could look at non-technical meshworks too. For example, everyone travels different paths on different sites, from the way people document their lives on Facebook to the kinds of things people buy over time on Amazon to the way their music tastes progress on Spotify or Pandora. We could look at meshworks of how user preferences and statements change over time, or at least make educated guesses about them since none of these companies would provide us with certain data. In this case, we don’t care about the destination because there is no destination; we just care about the hills and valleys that happened to get the user to the present on these particular sites.

**Thread for DQ5: Do you agree with Ingold’s argument that wayfaring is fundamental while transport is not? Why or why not?**

Kenny (Kenneth) Friedman: 
Never before have I read a piece that put such an emphasis on prepositions. But I guess that is to be expected for a chapter titled “Up, across, and along”. I am also impressed by his focus of relating concepts to lines, both in this piece, and (from a quick Wikipedia read), books titled “The Life of Lines”, “Redrawing Anthropology: Materials, movements, lines.”, and this book “Lines: A Brief History”.

While I appreciate his detailed examples, I don’t think he makes a strong enough case to declare wayfaring, as opposed to transport, as a fundamental mode of living. I would not argue the opposite: that transport is fundamental, either. Instead, it appears that the tension between wayfaring and transport is fundamental. There are times in which it is clear that wayfaring is the proper view of the process, and Ingold provides a myriad of examples of these. But it is also the case that transport can be an appropriate model to understand certain behavior or interactions.

Ingold appears quick to dismiss transport. In fact, he states that “pure transport is… an illusion.” His proof of impossibility of a purely destination view is that you can not detach movement from location. But you can. Or, at least you should be able to consider it. If you can’t explore a particular occurrence in isolation, one would be completely overwhelmed by the unnecessary details, trying to fit a mold that doesn’t make sense.

(As a course 6), the analogy that jumps to mind is someone arguing between “discrete” and “continuous” data. (The analogy matches closely enough that discrete is to transport as continuous is to wayfaring, though I’m not trying to make the case that either of those two are equivalent). An electrical engineer might argue that the world is continuous, and that dealing in the discrete-time world is “an illusion”, but then computer science would be effectively impossible. It would also be impossible to consider the world entirely discrete, as there would be a total overload of data at nearly infinitely small points. It’s the fact that we can model the world in either discrete or continuous ways, depending on the task and what we want to evaluate.

To dismiss transport as an illusion is to consider wayfaring to the be the ground truth. Taking in a personally held belief that knowing the ground truth is impossible, wayfaring and transport become two ways to “model” the behavior in movement and knowledge. For some reason, Ignold’s diagrams of the hub and spokes as well as the entangled lifelines are described in the piece as models, but wayfaring and transport are not. It appears that he uses the labels that he mentions as models, but never explicitly admits that they are a way to view the world, but not the "real" view. Once you explicitly consider these to be two models, it becomes difficult to try to make a case that one is fundamental and the other can be dismissed.

I maintain that neither are universally fundamental, they are two models that can be used to analyze life, each useful for certain, but not all, domains. 

Nick Gomez: 
Ingold makes some interesting points and poignant illustrations in his argument that wayfaring is fundamental while transport is not. He presents this idea that wayfaring is more natural - more intuitive, inherently complex, and 'real' than transport, which he depicts as rogue, mechanical, or artificial. My issue this treatment of paths is that he makes transport seem disconnected or less integral to the connectedness and our representation of the world. Instead, I see transport as a (the?) fundamental way in which humans organize and make sense of the world, even if you can argue that the voided paths that are drawn between points are drawn as a consequence of the intersection of the meshwork of people’s lives. 

The primitive meandering wayfarer may not particularly care for the voiding, straight paths between the locations he passes, but in reality, humans and all civilizations have evolved in the space that they inhabit by making these discrete, direct connections between locations, knowledge, people, and power. I’d argue that these simplified, direct connections between these nodes is actually the fundamental reason that humans can be so versatile - they are not only preoccupied with everything ephemerally around them, they can also draw on the vast networks created before them to guide their own path. The simplification and shortening of distance between collections of nodes  allows us to transverse the world quickly and expansively.


Indeed, the ruler of a civilization does not necessarily care for the meshwork of situations and experiences that have allowed him to come into power - he cares much more about the resulting network of direct connections that allow him to express his power and influence, and how he can leverage this network to express his power and create new nodes or connect to other existing ones.

Similarly, a scientist does not necessarily care for the meshwork of the situations and experiences that have given about the current state of his area of study, he cares much more about the ability to transverse all the knowledge he finds relevant quickly and effectively, attempting to draw connections to new nodes of knowledge. It’d be quite inhibitive if every mathematician had to rediscover - i.e. re-trace along - the fundamental rules of calculus. Instead, it’s much more effective for the mathematician to transverse the routes created by those before him in order to guide his own, unique path to new knowledge.

In Ingold’s view, this scientist is as disregarding of nuance as the imperialist he so belittles, and that is my main issue with his line of thinking. In my mind, being able to draw these short and direct lines of everything - history, knowledge, location, etc - is fundamentally exactly what makes us human and more capable than the average, meandering mammal. 

Frankie Schembri: 
While this was a fascinating read and I think Ingold’s argument makes some interesting points, especially in taking a non-Western look at how humans move through the world and create meaning through the journey, I disagree with his argument that wayfaring is intrinsically more fundamental to human anthropology than transport. 

In my understanding of early development, human beings make, store, and incorporate knowledge based on the relationships they have with what psychologists often call “transformational objects.” But the key distinction is that the human realizes that he and the object are separate entities. Continuing along with this theory, the relationship with the transformational object serves as a way to transport the developing human to the next stage of their psychosocial integration with the world around them, and the other people and objects in it. Humans are definitely travelling along a path on the journey of development, but the relationships they make, break, and maintain throughout this journey are separate and diverse. Much in the way Latour examined the lines between objects in a network, it is important to see them as evolving relationships between two actors.

Transport is arguably a more Western methodology for describing movement through physical and intellectual space, but there are also many people in the world who find greater development possible when grounded in a common space. Too many variables can inhibit learning, and learning does not always stem from movement across. The ancient rhetoricians talked of topos, commonplaces from which to begin arguments. Everyone needed to be centered around an idea or physical place in order for the rhetorical work to be completed. While Ingold describes transport as artificial and an inorganic way of integrating knowledge, there are individuals who respond better to the bottom-up (or top-down) structure of lists, who need to spend time at each step of the process staying still in order to better parse what they experienced in transit.  

“Fundamental” is also subjective on what the goals of the process or society are. In the case of the digitized Western world, the goals are often expediency and efficiency so more time can be spent on leisure, intellectual pursuits, and advancing collective knowledge. While wayfaring makes the most sense for other cultures with different goals, the societal structure in place in the Western world prioritizes divisions between leisure and learning. Is it more organic and fundamentally human for people to learn by exploring and mixing play with work? Perhaps, but given the priorities of certain societies, it is impractical and inefficient to conduct gestural learning on a mass scale. Commonplaces to visit, carry out work, and leave allow for the construction of greater collective knowledge. Information on the Internet does not travel by walking, it is routed through the fastest path through the nodes of the network. This principle is fundamental to its working the way people expect and need in order to carry out work and play. 

**Thread for DQ6: What kinds of “imaginative geography” (Said, in the Modell reading) are in play in McDonald’s piece and on Every Noise at Once? How well does Modell’s critique apply to them?**

Casie Chen: 
Modell refers to imaginative geography as "a way of knowing an other based on place and knowing a self based on an other." It seems that for Modell, this "other" in the music world is epitomized in the "world music" genre, which assumes that the listener is in the Global North. In some sense, I feel this imaginative geography is less about specifically physical geography, but refers to limited scope/perspective - in the case of Modell's writing, the perspective of the listener is assumed to be limited to the Global North. In McDonald's piece, this limitation of perspective seems to be more individual. In creating a map of the "world" of music, the creator inherently imbues the map with their own sense of "self," and therefore generates some element of "other." However, it also allows us to more accurately map genres and identify similar music, given, as McDonald points out, the overpowering weight given to popular music artists without that "self."

Where Modell represents code as a "decree," which defines some sense of self through Pandora's music tailoring, and seems to treat it as a bad thing, at least through the lens of overdeveloped societies defining what tech considers to be "exotic," in terms of music and potentially othehr things, it seems to me that McDonald acknowledges that without using these human elements to shape the code, we would not be able to categorize music and genres - and therefore personalize music - in the ways that we are able to today.

(I actually had a lot of trouble with this week's readings, so forgive me if this isn't a very accurate reading of the two pieces. I am very confused in general about all of the readings wow.)

Jenn Yu: 
Garfinkel and Barlow asserted that the Internet displaces any physical sense of place; Modell goes even further to present algorithmic technology as the driving force behind this displacement. The code of music-sorting services redefines our perceptions of selfness, otherness, and all the criss-crossing relations in between. Through her study of the Music Genome Project, she identifies the role that “imaginative geography” plays in guiding listeners through a discourse of self-exploration. As users give their thumbs-ups, build playlists, and recommend music for other listeners, they are creating and inhabiting new spaces within the imaginative map. I found her implications of self-exploration within Pandora interesting, and almost un-intuitive and scary: “consumers may entrust time, money, information, or their biological material in exchange for information about this themselves…self-knowledge is accessible through code.” Even though I have found some of my favorite songs by randomly clicking through recommended playlists, I am still consciously aware of my preferences and will replay or skip forward accordingly. The thought of music services, like Pandora and Spotify, having pre-established “selves” that internal code is fitting me (at the expense of my time, money, and personal information) into is frightening.

Modell identified genres as dynamic components of the music genome, and this is certainly true on Every Noise at Once. Genres are created based on preferences and trends on Spotify, with bands coming and going regularly. In this way, users can plant the “seeds” Modell mentioned, allowing new genres to organically grow and self-regulate continuously. Additionally, there are no exclusive boundaries to a genre, allowing for the nuances and fluidity that are inherent parts of human identity (who knew there was a distinction between “atmosphere black metal” and “chaotic black metal”).  
	
At the same time, McDonald observes overall contours taking shape on Every Noise at Once: the genres at the top of the map are more electric, while those towards the bottom are more acoustic; genres on the left are sonically denser, whereas the genres on the right are sonically sparer and spikier. This aligns with Modell’s assertion that genres are a reflection of both style and geography (the branching of hip hop into Hungarian hip hop, Deep Swedish hip hop, and Zouglou Detroit hip hop further support this).  

Modell seems to put greater power in the hands of code in the propagation of a user’s discourse of self-exploration, whereas McDonald recognizes the power of the users themselves in the creation of genres (“the approach allows us to seed, and then organically grow, a new genre or style from essentially any inspiration”, 3). However, Modell’s conclusion of music’s ability to give users a more accurate view of the world is spot on in McDonald’s piece. There are people and places that we never could have imagined, but following Every Noice at Once helps us “find a hidden valley with a hundred bands who’ve lived there for years.” We may argue on the specific wording of genres, or the bands categorized by them, but the fact that this disagreement is actively reflected in the “imaginative geography” of the music genome speaks to its power to transcend the boundaries imposed by physical geography.  


**Thread for DQ7: Gupta and Ferguson talk about the replacement of a singular spatial “grid” with many contiguous, connected grids. Does this answer Ingold’s critique of points and maps? Does it point to alternatives beyond the point/line dichotomy? How?**

Erik Stayton: 
SDQ3: What is the relationship between search neutrality, especially Grimmelman's arguments, and other types of devices: automated cars, IOT, etc. Do they give us any insight in terms of how to regulate algorithms in general?

I am particularly interested in Grimmelman's comments about search engine neutrality, because they relate quite strongly to thoughts I have had about how to ensure ethical algorithmic behavior in e.g. autonomous vehicles. Equality, objectivity, bias, self-interest, and transparency are all concerns for the engineering of large robots that move about the world at lethal speed. Though the topography of this space is not quite the same as for search engines, each of these terms is a useful locus of attention.

Equality: vehicles should treat people equally. But of course, some people are more equal than others. From this issue comes a slew of trolley-problem situations. If we have to hit someone, should we hit the old person or the young person? Or, more dystopically: the poor person or the rich person? Or, in more of a surveillance-state perhaps: the person with life/health insurance or the person without? Trying to minimize harm may actually cut against equality. 

Objectivity: people seem to like the idea that robotic vehicles will be objective in difficult situations, while people in those situations would be apt to make poor (non objective) decisions. But as we have hinted at with the problem of equality, there is no objective measure of the value of various human lives. It is more likely that there is an objectively best way to move to maximize free space ahead of the vehicle, but even this may not be clear. I submit that a better plan than seeking objectivity is to seek predictability:  the system should generally behave in the same way in whole sets of similar situations, and should not make erratic decisions in the search of local optimality.

Bias: all technologies have biases, but one of the promises of autonomous vehicles is unbiased accessibility. New types of people will finally have mobility. But of course, systems remained biased. A pay-by-the-mile ridesharing service is still going to be beyond the financial reach of large numbers of Americans for day-to-day use, even if you take human drivers out of the equation. While the blind and handicapped might have greater mobility, if vehicles are not designed to help them get in and out, they might yet find themselves shut out of the system.

Self-interest: one key concern for these systems is the self-interest of the driver. If the driver is protected at all costs, as is their self-interest and likely that of the company trying to sell cars to that driver, what about the principles of equality and objectivity? And from another angle, what does the self-interest of the company to be protected from lawsuits do to the way that they program the system?

Transparency: how do we assure that the answers to these problems are appropriate? One is to require code to be open. This has similar problems to what Grimmelmann outlines about search engine code. Open code in this case should allow better security, if enough people actually verify it. But it also gives away competitive advantages. And the code may be too complicated and rapidly changing to really be inspected thoroughly. One promising alternative seems to me to be transparency about decision-making processes within the organization itself. If we know implicit biases will be built into the technology anyway, and seeing the code itself may be of limited usefulness or come with high costs, what about scrutinizing the processes by which these decisions are made?

Maria Temming: 
**DQ5: Why does Grimmelmann think the idea of search neutrality is "a muddle"? How does his argument relate to that advanced by Gillespie in his case study of Santorum?**

Grimmelmann asserts that the idea of search neutrality is a “muddle” because there’s a “fundamental misfit between its avowed policy goal of protecting users and most of the tests it proposes to protect them” (437). In other words, although search neutrality claims to protect users, its core principles actually protect websites, which, Grimmelmann says, are the enemies of users, when it comes to searching. The bulk of Grimmelmann’s essay is devoted to unpacking each of these principles and showing why they’re not as clear-cut as the initial list might make them seem.

Gillepsie, meanwhile, makes a “parallel argument” to Grimmelmann in his analysis of the Rick Santorum search engine situation, wherein he examines how public actors try to make themselves recognizable to information intermediaries—which in turn are forced to discern between acceptable/unacceptable efforts to be seen (2). Gillepsie’s case study of Santorum reflects Grimmelmann’s piece because many facets of the Santorum case could be used as examples in Grimmelmann’s examination of the eight principles of search neutrality (I’ll just talk about three here):

**(1) Objectivity**: According to Grimmelmann’s essay, the principle of objectivity assumes that there are correct and incorrect results that a search engine can display in response to a certain query. Grimmelmann says this principle is faulty in two counts: first, search users “have highly personal, highly contextualized goals,” and second, “a search engine’s job always involves guesswork” (443). Gillepsie illustrates the importance of individual user goals and contexts when he quotes the Google representative: “There definitely are people who are finding [the Savage definition of ‘santorum’] to be the best answer to their question, and they are indicating this by either clicking on this result or linking to this result as the best answer to that question” (8). These people often include journalists or simply curious parties, not just trolls—so clearly there can be no correct or incorrect search result for “santorum.” Gillepsie expands on the importance of context when he spends an entire paragraph on page 7 listing all the societal and cultural factors that shape search trends. He also touches upon the “guesswork” of search engines when he challenges the myth that there is a real distinction between “coordinate efforts to ‘game’ a search engine” and “’genuine’ output of independent web producers” (5). 

**(2) Bias**: The principle of bias states that search engines shouldn’t unfairly distort the information landscape online, which Grimmelmann essentially calls BS on because “search engines systematically discriminate by design”—and determining when this is and isn’t “unfair” is itself a muddle (445). “Neither users nor websites are passive participants,” Grimmelman says. “Both can be wildly, profoundly biased” (446). Gillepsie similarly negates the idea that users or web producers are “passive”—he scorns the idea that these players are “merely standing on the edge of the field” waiting to be picked by a particular search engine (2). On the contrary, Gillepsie says, web producers trip over themselves to become more “algorithmically recognizable” with SEO and other techniques—as was the case when Savage loaded the meta tags of his sites with words like “senator” and “rick santorum” (2). Another problem Grimmelmann has with the principle of bias is that telling users what they *should* see intrudes on their personal agency. In Gillepsie’s piece, Google’s staunch refusal to eliminate offensive search results like JewWatch embodies this idea. 

**(3) Transparency**: Transparency is the principle of search neutrality that demands search engines disclose their algorithms. Grimmelmann explains that disclosed algorithms (a) give a search engine’s competitors its secret recipe, as it were, (b) help spammers find loopholes, and (c) “sharpens the question of regulators’ technical competence” (455). If we didn’t already know why technical competence would be a problem from Seaver’s piece, Gillepsie lays it out: Google had 92 major updates 2000-2012, and made 500-600 smaller changes each year, which were each “many changes bundled together” (9). Gillepsie says that it’s possible not even Google engineers know why the Savage santorum definition finally fell in the list of Google search results, as “changes to the algorithm are opaque to both users and critics” (11). In short, Gillepsie’s piece demonstrates why Grimmelmann thinks algorithmic transparency is unreasonable. 

Hi Maria -- 

Nice work mapping the two together! 

Peter Downs: 
**DQ4: what are some of the technologies Blair and Stallybrass identify as being useful to organizing information during their historical period of interest? How do those technologies compare and contrast to the kinds of knowledge management methods we use today?**

---

Kind of astonishing to realize that most people didn’t keep personal notes until the rise of cheap paper, which Blair and Stallybrass point out was driven by the printing press. Also incredibly meta that while reading this I was taking notes in a Markdown document on a computer, typing away and editing by hand. I get the feeling that Leibniz, who was so overwhelmed by the volume of his personal notes that he would give up hope on finding any particular work “after a few months”, would be interested in the full-text search software we have today, which helps me find exactly what I’m looking for even if I wrote it back in middle school.

Just as the tools that Leibniz and his contemporaries used (or could have used) were a response to a relative explosion in the amount of information they had to process, and inadequate to handle said explosion, so are our tools today. Sure, I have full text search over my files since middle school, but I also have every file I’ve created since middle school -- and the metadata associated with them. On a global scale, the numbers aren’t even remotely relatable; all the way back in 2010, internet-connected humans created [“as much information as we \[had ever created\] up to 2003” every “2 days”](https://techcrunch.com/2010/08/04/schmidt-data/) (of course TechCrunch is a real source, what do you mean?). Forget about two loops of string, one threaded through “miscellaneous letters” and one through “miscellaneous drafts”, as depicted in Jan Gossart’s Portrait of a Merchant (ca. 1530). Now we have massive data centers and [columnar stores](http://research.google.com/archive/bigtable.html), [full text search](https://en.wikipedia.org/wiki/Spotlight_(software) and [fuzzy text search](https://www.elastic.co/products/elasticsearch) and plain old fashioned [internet search](https://bing.com/) (jokes aside, you should use [DuckDuckGo](https://duckduckgo.com/) instead) and we’re still barely able to keep track of it all.

These technologies all help with the same task -- you (or someone else) stored a thought somewhere that wasn’t your head, and now you need to load it in. If quantity is its own quality, then that’s certainly one difference between the “gilded table books” that sailors and merchants and government agencies used during the Renaissance and the technologies we use today. But a bigger difference is a matter of method; card catalogs, lists of a book’s chapters and subchapters, and note slips cut and pasted from disparate sources all involved manual intervention. Now, not so much; those methods still exist, but more and more we’re relying on fully automated methods to index and retrieve our information. [ElasticSearch](https://www.elastic.co/products/elasticsearch) even allows fuzzy indexing, so you don’t have to remember exactly what you’re looking for. [Word2Vec](https://arxiv.org/abs/1402.3722) will let you search with analogies (“Like the Paris of Germany” -> “Did you mean Berlin?”), and neural nets let you search images by describing them, even if no one else has previously labeled the image -- [a computer will do it for you](http://thehackernews.com/2016/04/facebook-artificial-intelligence.html).

Although the notion of building a personal “beehive” of information you’ve gleaned from various different “flowers” still applies, we’re no longer copying information between three different notebooks, shorthand or longhand. I’m inclined to believe that the tools we have today are better.

Hi Peter - 

I share your belief. Although it's interesting to think if there's a bit of a Jevons paradox with data: the better we get at searching it, the more we have to search... 

You might also like this: https://mitpress.mit.edu/books/paper-machines

Mike Sun: 
**DQ5: Why does Grimmelmann think the idea of search neutrality is "a muddle"? How does his argument relate to that advanced by Gillespie in his case study of Santorum?**

In his paper “Some Skepticism About Search Neutrality”, Grimmelmann starts with the story of Adam Raff and Foundem. After reading his story of how Google seemed to abuse its power as the dominant search engine to cut down traffic to its competitor, the idea of search neutrality – founded on notions of equality and fairness – definitely seemed an attractive one. Unfortunately, while the objective is a very noble one, the concept itself is, as he puts it, “a muddle” – fundamentally flawed, impractical, and even undesirable. Grimmelmann analyzes eight principles governing search neutrality as proposed by search-engine critics and demonstrates that they are completely unworkable in the context of search regulation, as they are much more likely to protect websites rather than the intended users. 

Grimmelmann argues that search is a much different form of media than the Internet or news, and thus the arguments that are applied to net neutrality and news reporting cannot also be applied to search results. For example, search neutrality proponents call for equality, stating that search engines shouldn’t differentiate at all between websites. However, Grimmelmann states that this kind of differentiation is the entire *point* of search engines – they must inevitably favor one type of content over another in order to best accommodate perceived user needs. To weigh results of Peru and horny housewives equally under “Machu Picchu”, he says, is not just absurd, but nigh impossible. Grimmelmann similarly dismantles the remaining principles of search neutrality, demonstrating how each one of them does not achieve its desired outcome. Search neutrality advocates objectivity of search results, but searches are user-defined and thus inherently. We’d like for our search algorithms to be unbiased, but we also criticize Google for showing anti-Semitic results under “Jew”. And so on and so forth. 

Gillespie’s analysis of Dan Savage’s attempt to redefine Rick Santorum on Google draws from many of the same components as Grimmelmann’s essay – to the point where it starts to seem like a case study on the infeasibility of search neutrality. As an example, Google told Santorum in 2011 that if his redefinition appeared as the number one hit on Google, passing through all of its algorithmic checks, then there was no reason to believe it was not the desired definition people were looking. This is a direct parallel to why Grimmelmann says search objectivity is infeasible. By analyzing the different tactics used by Savage and his followers to proliferate Santorum’s redefinition and the resultant responses by Google and Santorum, Gillespie illustrates how search engines and content creators will always be at odds with one another: content providers are constantly seeking visibility and thus ways to make themselves “algorithmically relevant” to information intermediaries ("notice me Google senpai"). This in turn means that those same intermediaries (ex. search providers like Google) constantly have to make inherently biased decisions based on what they perceive as acceptable/unacceptable as well as general user needs. Since content providers are always in fierce competition with each other, Gillespie notes, a neutral, stagnant search engine is much more prone to manipulation. This is almost a direct echo of Grimmelmann, who himself states that “requiring search engines to behave “neutrally” will not produce the desired goal of neutral search results”. Finally, Gillespie’s primary argument is that, in studying the politics of search, analysts are treating content providers as independent of the search engine, or as Grimmelmann might put it, not cynically enough.


Hi Mike - 

I think you're right. Also: 

> We’d like for our search algorithms to be unbiased, but we also criticize Google for showing anti-Semitic results under “Jew”. And so on and so forth.

It feels like Twitter is one platform currently dealing with this kind of criticism, as its principle of free speech and constant harassment of certain people are in tension. 

Mike Sun: 
Hi Chris,

I think it's definitely a recurring theme among social media - you could probably draw some similarities to the pieces on content moderators from last week. I find it really interesting that people are trying to move the debate to search, however. Grimmelmann's entire argument is that the *point* of search engines is that they need to be biased in order to be useful. I think in the end, it comes down to whose free speech should we be allowing? [In Google's eyes, it is not the websites' free speech that is to be protected](http://www.slate.com/articles/technology/future_tense/2014/11/are_google_results_free_speech_protected_by_the_first_amendment.html)

Jenn Yu: 
DQ6: Does Geiger think that the blogosphere can be described as a Habermasian public sphere from the perspective of integrated knowledge and social solidarity? Why or why not?

A Habermasian public sphere is a space that is untouched by the influences of traditional institutions or corporations, allowing anyone from the public to generate and express his/her own opinions. During his time, Habermas saw the existing public spaces as incredibly flawed, as entrance into them had been monopolized by a select few mass media routes (eg. Radio stations could be bought out, town halls are physically constraining, etc). Therefore, he envisioned the Internet as a truly democratic space, one in which the only force was discourse (2).

Geiger finds that today’s blogosphere cannot be described as a Habermasian public sphere, due to the fact that fundamental assumptions made by Habermas regarding the Internet’s set up and its users are simply outdated. There are developments within cyberspace (the aggregation of data) that the philosopher did not foresee and account for. Geiger arrives at his conclusion by studying the propagation of discourse in two contexts: the public sphere and today’s aggregation mechanisms. 

Habermas saw the Internet as a multitude of “virtual coffeehouses”, consisting of online chat rooms, web forums, and other web-based communities that would provide discursive spaces in which the public could express political opinions in a more egalitarian way. However, as Rheingold pointed out, this representation of the Internet is a telltale sign that Habermas did not understand the ways that web users interact today. Rheingold specifically calls out Habermas’s original criticism of fragmentation, refuting it as a legitimate concern since today’s algorithms for aggregating data prevent the risk of “information overload”. Geiger continues his argument that today’s Internet is not a representative Habermasian space because it is just as susceptible to commoditization as previous mass media outlets. (We see this today through providers of high-speed Internet and telecommunication services) 	

 The post-Habermas networked public sphere that we see today is propagated by a non-discursive discourse: the aggregate effect of individual action coordinates a unified information environment, which is created by all the other uncoordinated individual actions of users across the web (19).  On a micro-level, this uncoordinated coordination seems to follow a true Habermasian public sphere, allowing individuals the equal ability to voice their opinions, despite their political status or background. However, on a macro-level, the blogosphere is facilitated by calculated, complex algorithms. People can still be overlooked and marginalized based on what a computer deems to be popular and relevant, and what can be buried into the deepest, darkest corners of the Internet. A true Habermasian public sphere requires its users to engage with each other purely through communication, but the sheer size of today’s blogosphere requires computers to intervene and prevent an information overload. 

Habermas projected assumptions about Internet users that are simply untrue today. He didn’t foresee the rise of algorithms and the role of computers in aggregating the massive amounts of data transferred across the web. The ideal public sphere that he envisioned is instead a public sphere unified by algorithms, not discourse. 


Hi Jenn -- 

This is mostly on point, but I think you slightly misread Geiger's argument. Geiger doesn't think that Habermas misunderstood the internet: instead, he argues that Rheingold and Benkler misunderstood _Habermas_ as they tried to apply his theory to the Internet. The key to Habermas, according to Geiger, is not to think about the sphere as a real (a coffeehouse, whether virtual or brick and mortar), but instead as an abstract space that exists when people actually respect and speak with each other to come to common agreement, as opposed to being split into different communities as organized by technical forces. 

Charles Bachmeier: 
DQ4: what are some of the technologies Blair and Stallybrass identify as being useful to organizing information during their historical period of interest? How do those technologies compare and contrast to the kinds of knowledge management methods we use today?


One complaint about the digital age is that it is too easy to become completely overwhelmed with simply how much information is around them and with websites like wikipedia that hold seeming endless material that would take many lifetimes to read, it is understandable that many feel lost in an endless sea of data. Though, in one of Ann Blair’s works, Too Much To Know: Managing Scholarly Information before the Modern Age, she argues that for most of recorded history humans have felt overloaded with just how much information is available. The only real difference between 1450 and our own modern age is where most of the knowledge is located. 


Back during the Enlightenment, many new and fascinating ideals were spreading around the continental Europe, new philosophies, new thoughts on how ruling power should be established, and thoughts on how to revolutionize religion, and the ability for this information to spread so quickly was the invention of the printing press, which allowed for mass scale productions of literature decreasing the barrier to entry for the common European citizen to acquire knowledge previously only attainable by the nobility. Although, many works were based off the personal notes and letters of esteemed individuals, such as Robert Boyle, and because of this, there was very little structure to the organization of the information in the book, causing the reader to become confused and lost in all of the information, much like someone today on the web. However unlike today, the only way to find the information someone was looking for was to go page by page looking for it. Thanks to search engines, no one has to go web page to web page trying to find the information they require, a seemingly impossible task given how many websites there are today.


Due to the shoddy organization of people like Boyle, a standard system of having a list of headings in the book which broke the book into categories based on what material was covered on which pages. This greatly reduced the number of pages one had to look through to find the information they were looking for and can still be seen on a site like Wikipedia which has a “Contents” section at the top of the page with links to each related section in the article. These headers evolved into the Table of Contents which is the common modern practice for organizing information in texts today.


Hi Charlie - 

I think you're right that the focus of Blair's work is how older information systems required sophisticated indexing systems that are different from, but realize similar goals to, our contemporary systems. One interesting distinction is, as you say, the hierarchical ordering of prior works by category/indices, which is different from the associative (by links or search) management of much knowledge on the web. 

Christine Konicki: 
**DQ5: Why does Grimmelmann think the idea of search neutrality is "a muddle"? How does his argument relate to that advanced by Gillespie in his case study of Santorum?**

Grimmelmann thinks the idea of search neutrality is "a muddle" because of all the contradictions existing between what the idea attempts to do and what it actually ends up doing, between the fact that a neutral search engine is supposed to protect users when in reality it ends up protecting websites. He lays out eight pieces of the plan for search neutrality and explains why putting the idea into action violates all eight of them. Meanwhile, Gillespie uses the case study of Santorum to illustrate how "public actors attempt to make themselves recognizable to information intermediaries" and "the way information intermediaries, algorithmic or otherwise, are forced to discern between acceptable and unacceptable efforts to be seen, when being seen has political currency." Ultimately, the common issue linking Gillespie and Grimmelmann is about interference in a supposedly "unbiased" search engine algorithm should be in order to optimize user satisfaction, specifically how much there should be and what the connotations of that intervention are. I will illustrate this by discussing how the Santorum case study relates to both the aforementioned commonality through a few of the deconstructed neutrality pieces discussed by Grimmelmann.

(1) Equality: Grimmelmann argues that not discriminating between websites in search results is a principle of search neutrality even though removing all discrimination and filters what completely go against the purpose of a search engine: to help a user easily find whatever it is they're searching for. The definition of "santorum" originated by Savage and his readers became so viral that to remove the sites associating the word with Savage's definition would alienate a whole host of users who were probably searching for the definition, not the senator. Later, when Savage's website dropped in relevance in the search results, it was hard to discern whether this was a deliberate attempt to change the search results associated with the word, a result from A/B testing, or something that came with a whole cascade of other updates to the search algorithm (such as an attempt to filter out sites that were overtly sexual or inappropriate). In any case, the search engine was functioning normally, so to "undo" whatever caused the site to plummet in relevance for the purposes of maintaining the site's equality would undo the entire update that Google made to improve user satisfaction. By extension, any discrimination would have to be undone so that all sites would remain equal; again, this would completely strip the interpretation that makes Google's search engine efficient for users. Creating a successful neutral search engine in the Santorum case would therefore be impossible. The fact that Savage's sites--originally created to mock Santorum--were being treated like other sites discussing the senator was so repulsive to some people that they couldn't tell if Google's algorithm was intentionally trying to "mislead" people or if people actually really were searching for the word (spoiler: the word was viral, so people were).

(2) Objectivity: Creating a neutral search engine for all users through objectivity and not distinguishing between results means applying a "one size fits all" principle to all users and assuming that all users would be equally happy with the same results, which is not at all true. In the case of Santorum, some people searching "santorum" probably really wanted to find the Senator's website while others really wanted to find Savage's website or an UrbanDictionary page coining the definition. Depending on factors like how viral certain pages pertaining to the word are or what the user's search history might indicate, the top hit may be either site. If Google removed all of these filters, then only one could be the top hit, and since Google would be treating all sites equally in this sense, a choice would have to be made for all users. The decision would carry with it a huge political connotation, and users would be wondering what kind of bias was present, if any. But because Google doesn't explain everything about the changes made to their search engine code, there would be no clear-cut response, and the issue would remain unanswered.

(3) Bias: A neutral search engine requires no bias whatsoever, but websites are full of biased information and the search queries are made by biased humans. A search engine depends on a search query and a bunch of sites in order to supply the results, so it is virtually impossible to remove all bias from the results. Now back to the Santorum case. A site talking about Santorum (excluding something intended to be objective like Wikipedia or a government site) carries with it some bias because it's probably encouraging people to support his election or promoting whatever causes he's working for. There's also sites that would be listed (excluding Savage's) that are essentially "I hate Rick Santorum" sites and have some bias. Savage's site, of course, was intended to make fun of Rick Santorum because of what he said about homosexual activity (e.g. anal sex), so it definitely has some bias. Now, a user who searches "santorum" using Google probably sits somewhere on this bias spectrum (between supporting him with a passion and hating him with a passion). So no pairing of user query and website returned in search results is without bias. In that sense, a suspicious user sitting on the spectrum looking at a website that sits on the spectrum could interpret some bias coming from the algorithm if they wanted to.
It's kind of like having an objective dealer working with a stacked deck during blackjack. All of the players are making informed, biased choices, and the cards they get are by nature stacked. The dealer just deals the cards according to the players' requests without thinking about it. But a player who sees something strange could assume that the dealer was stacking the cards when the cards were stacked ahead of time naturally without the dealer's involvement. Ultimately, there is only as much bias in a list of search results as a user chooses to see and acknowledge.

Hi Christine - 

I think this is a good reading of both Gillespie and Grimmelmann. One point I would make even more finely is that, for Grimmelmann, the idea of a 'neutral search engine' is an oxymoron: the whole reason we use search engines is because they're biased in useful ways. So the real question is what types of bias we find acceptable (or not) under what conditions. 

Kyle Saleeby: 
DQ4: what are some of the technologies Blair and Stallybrass identify as being useful to organizing information during their historical period of interest? How do those technologies compare and contrast to the kinds of knowledge management methods we use today?

Throughout this article, Blair and Stallybrass thoroughly research and explain a brief history of stationary recording. They not only describe each method, but also include evidence of variations of the method based on the writer’s purpose and needs for each approach. I found this article extremely interesting to read as it suggested links between seemingly unconnected increases in popularity of writing and organizational methods. 

One aspect of the article that especially stood out was the creative ways in which notes and writings were organized. It seems to me that many scholars, merchants, and scientists of the time frequently took notes on loose left paper, or smaller notes. These notes were no less valuable to the writer as a log book to a researcher, but theses notes were undoubtedly more difficult to organize and readily procure. Nicolas Peiresc was disorganized enough messy with his note and letter storage that it was mentioned in another scholar’s writings. Still, Peiresc was able to “readily procure” any note or parcel as long as his notes were left exactly as he placed them. On a side note, I connected with this as a young kid. Even though my room would be messy, I would know exactly where everything is. However, if it was cleaned in part or in whole by someone other than myself, things would undoubtedly be ‘lost’. 

In my opinion, the most creative solution to organization that was presented relates to the origin of the word “file” as one files papers into a folder. According to Blair and Stallybrass, the word “file” has roots in the Latin term filum, meaning “thread”. Merchants would in effect, thread their letters to preserve order and ease of access. Strings of letters were hung upside down with content facing a wall such that a merchant could simply flip up a letter when he or she wanted to read it. I found this to be an extremely efficient method of organization because of the possibilities of other systems that could be implemented alongside it to manage a large amount of letters. For example, the back sides of letters could be inscribed with a mark corresponding to the topic of the letter or date when it was received. Color coding, placement of strings, and a variety of other visual systems could be used with this system to make recalling a particular letter relatively efficient. Although these extra identifications may or may not have been used, I found this fundamental system extremely innovative and clever due to the possibilities it allowed.

When comparing the methods that Blair and Stallybrass describe, I can’t help but think of how similar our modern methods of organization are to the original filing structure. I may be oversimplifying some aspects of current structures but I believe one method in particular, the Dewey Decimal system for literature, is largely linear. In the Dewey system, each book is assigned a number based on its topic. Sub-categories also exist hierarchically within the main category. As books are published, they can be immediately placed in the most appropriate categorical location. Libraries do use two-dimensional space to store books as it would be unnecessary to actually keep them in a straight line, but the storage system fundamentally linear. In this aspect, one of the largest modern organizational systems has not been fundamentally changed since its implementation. I do not intend to criticize the system at all, but only suggest that a new system could be investigated. It might be an extremely interesting challenge to design a new system that is practical while including a non-linear or three-dimensional organizational structure.

Hi Kyle - 

You're right to connect the Dewey system to this reading. One common companion reading to Blair and Stallybrass is this which also goes into the Dewey system: https://mitpress.mit.edu/books/paper-machines

Frankie Schembri: 
**SDQ1: profile of Tarleton Gillespie, author of “Algorithmically recognizable: Santorum’s Google problem, and Google’s Santorum problem.”**

Tarleton Gillespie, born in Ithaca, NY, received his B.A. in English from Amherst College in 1994, and received his M.A. and Ph.D. in Communication from UCSD in 1997 and 2002 respectively. Gillespie is now an Adjunct Associate Professor in the Department of Communication at Cornell.
Gillespie also serves as a Principal Researcher at Microsoft Research New England, as part of a research team known as the Social Media Collective. Other members of the team include danah boyd (author of *It’s Complicated*) and Mary Gray (author of *Queering the Countryside: New Frontiers in Queer Rural Studies*). I was aware that Microsoft had a research branch, but I assumed that it would be focused on research into the technical side of the hardware, software, and manufacturing processes required to make Microsoft’s products. The Social Media Collective, established in 2010, is just one branch of Microsoft’s research in the Social Sciences. Other groups include the Data-Driven Conversation project, which examines how humans communicate with one another using devices and online interactions, and the VIBE (Visualization and Interaction for Business and Entertainment) group, which focuses primarily on topics in human-computer interaction and information visualization.
The Social Media Collective examines how social and communications technologies effect and affected by users’ practices. Gillespie’s research is in two main veins: (1) how social media platforms and other information systems moderation processes shape public discourse, i.e. how the guidelines imposed by the owners and moderators of social media platforms set the terms for what content is ‘appropriate’ user contributions, and how this private governance of cultural values has broader implications for freedom of expression and the character of public discourse, and how the algorithmic selection of information and culture has equally important consequences for public discourse, and (2) how the enforcement of copyright law through encryption has shifted from regulating copying to regulating the design of technology and what are the political, economic, and cultural implications.
The effects of copyright laws on the digital world were the subject of much of Gillespie’s research in the early 2000s and the subject of his first book *Wired Shut:
Copyright and the Shape of Digital Culture*, published in 2007 by the MIT Press. 
Since the 2010s, Gillespie has examined the effects of algorithms, especially those coded into social media platforms to sort content by learned user preferences, have consequences on public discourse and value systems. 
His 2010 essay “The Politics of Platforms” has been a key text in the anthropological and sociological study of online platforms – marketed as places for user expression, but actually governed and designed by owners to curb liability if the user says or does something “inappropriate.” These popular platforms are often thought of as places of unfiltered public discourse, but Gillespie sheds light on how content is carefully curated by both algorithms and moderators.
In his 2014 essay “The Relevance of Algorithms,” Gillespie identified and examined the many algorithmic methods to curate, control, and filter content across a variety of popular social platforms. He focused on how algorithms embedded in social media and search engines organize information based on implicit and unexamined assumptions about popularity, relevance, and value – that have implications for how public discourse functions.  The essay is highly cited by researchers of digital culture, and provides a vocabulary for the types of algorithmic information systems that are used to determine the content of social media platforms, which are deeply interwoven into the offline lives of users.

Hi frankie -- 

Nice bio on Tarleton! He's based here in Cambridge now. I've heard it said before that MSFT employs more PhD anthropologists than any American organization outside the US Gov't. 

Kenny (Kenneth) Friedman: 


*As I write this message on the 4th hour of my bus ride back to Boston, I hope it is somewhat coherent.*

**SDQ3: Does Chen’s piece on The Agency show a fundamental breakdown in the flow of information? Is the system working as designed?**

Ok, that question is a cheap ploy at trying to grapple with whether the activities discussed in this piece are major flaws that should be fixed, or the system of the internet working as intended. 

One could argue that there is a flaw in the architecture of the system. It shouldn’t be possible to spoof other people, but clearly that’s impossible. Even if the IP address or location were always available and couldn’t be altered, screenshot sharing and first-hand reporting on things like Twitter would still occur and couldn’t be verified.

So question turns from a problem with the architecture of the system and a problem of trust and reliability of information. The democratization of information also leads to the democratization of trust: when there were 3 news anchors delivering the news on TV each evening, there was some level of trust placed in these anchors. A level of trust that almost know one has from news that shows up on Twitter, or Reddit, or CNN.com.

But the trust in those anchors was likely misguided. Their reporters could have been misinformed, there might have been trolls sourcing them bad information. And that is true with almost any type of media. One could argue that it’s more widespread now.

The smearing article *What Does a New York Times Journalist Have in Common
With a Nazi From St. Petersburg?* can be more quickly developed now than in the past. But smearing people who disagree is not new. James Callendar was smearing politicians in 1800. It’s occurred in newspapers, between nations, and by word of mouth, since the beginning of time.

The IRA and Savchuk’s story don’t seem new to me. The medium has moved to the internet, but it feels like this type of work could have been done at any point in the past. 

And maybe that’s okay. This propaganda can be more easily created, but it can also be more easily vetted. The difference with the internet, in terms of trustworthiness of information, seems like a quantitative difference, not a qualitative one. 

Adrian Chen seems to be making a case that the internet enables this behavior. I’m not convinced. It’s an interesting read, but I think it says more about information battles between institutions of people (in this case, other countries against the US) than it does about the structure or network of the internet.

Hi Kenny - 

>are major flaws that should be fixed, or the system of the internet working as intended.

This is, btw, a great way to frame any question of any system :) 

>This propaganda can be more easily created, but it can also be more easily vetted. 

This seems like an empirical question that I don't think Chen answers. You might also compare http://www.dartmouth.edu/~nyhan/nyhan-reifler.pdf. 

Let's talk about this more in class. It's extremely timely. 

Nick Gomez: 

Geiger doesn’t believe that the blogosphere can adequately represent a full-fledged Habermasian public sphere. Geiger states that the blogosphere is “full insufficient to perform the kinds of socially integrating tasks that a Habermasian public sphere performs.” Specifically, he focuses on the lack of a discursive process in which blogs are propagated up the stream of importance, noting that they are brought up via automated, algorithmic systems (like via Google page ranking), so “what kind of discursive relationship can individuals possibly have with each other in a public sphere so constituted.”

That seems to be the sticking point of Geiger, that while open discussions do occur in the internet, the way in which they are propagated don’t quite hold up to the ‘discursive’ nature of a Habermasian public sphere. While in some sense I understand his point, I don’t find his argument entirely convincing or even relevant . For example, the modern media is highly interconnected via linking; in fact, the very algorithms that Geiger finds lacking heavily weigh linking between websites and posts. This allows search results to be results that are highly relevant and highly discussed or referenced, and in a way, being able to make a fairly impartial and cohesive narrative of the highly connected but sporadic internet. Additionally, his criticism points to a broader concern: what would be the ideal way in which a public sphere propagates discussion in a discursive manner, without the internet? The answer is that there isn’t any, as traditional non-internet forms of serious political discussion was limited to the privileged and connected, and forms of propagation were reserved for the mass media. The internet’s main barrier of entry, known as the “digital divide”, is much less pervasive and much easier to address, and discussion propagate to the public eye, and therefore open up to discussion, much more quickly and openly than ever before (e.g. Facebook and Twitter trends). More crucial to an effective public sphere, in my opinion, is the quality of well informed, rational discussion, which seems to be a much bigger issue on the internet and blogs than the method by which discussions are propagated. Boards, wikis, blogs, commentaries, videos, and all forms of media on the internet are often faced with a tremendous amount of trolling and unproductive discussions. Is that due to the nature of the internet? Or is it simply a limitation of a society in which the citizenry isn’t educated nor interested enough to have substantive open discussions? These, to me, are more important questions to ask and factors that impact the quality of a public sphere more than the points that Geiger discusses.

Hi Nick - 

This is an excellent question. You're right this is a dense and difficult to understand piece, but I actually think you get to the heart of it: 

>More crucial to an effective public sphere, in my opinion, is the quality of well informed, rational discussion, which seems to be a much bigger issue on the internet and blogs than the method by which discussions are propagated.

This is I think the point Geiger is trying to make: whereas some Internet theorists argued that the mere existence of these media forms was enough to create a public sphere, Geiger argues that the quality is more important, and is pessimistic that the technological systems that interconnect these spaces are capable of creating that kind of respectful, rational discussion. 

Erica Yuen: 
**DQ 3: Compare the Internet Research Agency to a typical media outlet pre-Internet and of today.  Should the information spread by trolls be controlled, and if so, how?**

Social media can be compared by news outlets, in the forms of television, radio, magazines, newspapers, etc., by the way that they convey information to a large audience. Like social media, news outlets are not guaranteed to be completely accurate, as exemplified by tabloids, occasional false reporting, and biased reporting. However, these news agencies are often consistent in their reliability, and audience members can choose whether or not they want to turn to these sources for their information. Unlike typical news agencies, the information spread by social media has less accountability, since it is often a lot more difficult to trace and verify a source. On the internet, you can take what ever identity you want, and if your information is deemed unreliable, you can easily start over again. Information spread over social media depends on not one source, but many to share and spread stories, which is the fundamental reason why the Internet Research Agency is able to continue to spread disinformation.  On the other hand, traditional news media requires an audience actively choosing to tune into a specific source, rather than passively encountering it while browsing through friends’ life updates on Twitter. 
	
When I was reading about the chemical spill hoax fabricated by the Internet Research Agency described in Chen’s The Agency, I was reminded of the [War of the Worlds](https://en.wikipedia.org/wiki/The_War_of_the_Worlds_(radio_drama)) news radio broadcast in 1938. This radio drama broadcast basically caused mass panic for over a million listeners after broadcasting about aliens from Mars invading the United States, even though they did have an introduction that the broadcast was an adaptation of a novel. This was right before WWII happened, so people then were in general really paranoid about invasions. There was a lot of public outcry after the panic about regulating radio after this. 

In a similar sense, the Internet Research Agency contributes to the paranoia via its industrialized propaganda and trolling. However, the Russian government supposedly sponsors this kind of media, as opposed to regulating it. It is really difficult to regulate “trolling” since there is not objective way of separating trolling from simple creative media and opinions, as opposed to dick pics and PG photos of your family. The main issue about regulating media is the fine line between free speech and censorship. 


Hi Erica - 

I think this is a great historical comparison, not only between cases (i.e. IRA vs War of the Worlds) but between media. Both mass media and Internet media are capable of circulating disinformation, but *how* they do so varies pretty significantly. 

Christina Wang: 
**SDQ3:Who makes up the internet troll demographic?**

First of all, I’m finding myself really enjoying these investigative pieces that are sprinkled in with our assigned readings, specifically with the work Adrian Chen does. I admire he’s ruthlessness as a journalist and ability to put two and two together while telling an exciting narrative. In this particular article, I appreciate how he begins the topic domestically, describing the scene and aftermath of the supposed Columbian Chemicals explosion in Louisiana, before expanding to the broader context of the “disinformation campaigns” run by agencies in Russian meant to propagate pro-government propaganda online. Finally, he connects back to the fake explosion in the US and the consequent ripple effect of the media, emphasizing the breadth of the agencies efforts and their ability to strategically infiltrate international social platforms as well. 

I’m pretty familiar with the term “internet troll” within the context of the US. From doxxing problematic twitter and Instagram users, to blatantly incendiary death threats within the Youtube comment sections, trolls are all too easy to come by. However, this article took trolling to the next level, introducing government backed entities tasked with supporting the state through covering potential threats to their reputation or by concocting entire profiles of individuals who kept personal blogs that were spotted with pro-Kremlin propaganda. To be honest, I was amazed by the lengths these government backed agencies and their employees went to to get their message across, including coding bots that generated hashtags and creating animations narrated in questionable American accents. Quite honestly, it seemed a little pathetic, if not cheap.

In a recent TIME magazine [cover story](http://time.com/4457110/internet-trolls/) that was published this summer, Joel Stein argues that the majority of internet trolls are alt-right conservatives battling culture wars (think: Donald Trump tweeting at 3 a.m.). So then, what do alt-right Americans have in common with false-information agencies in Russia? Inherently, I believe it reveals an insecurity of their being - both a precaution and a response to eschew potential risks to their reputation or ideology that can be constructed through the anonymity of the Internet. If they can scare their opponents out of a view point, or at least cover it up, then they of course can feel better about their cause.

My guess is that some of the 'alt-right' *are* false-information agencies. 

Erik Stayton: 
SDQ3: What is the broader context for the sociology of the missing masses? What is Latour trying to open up and why is this important for studying technologies in human society?

Once upon a time, there was a debate between Technological Determinists and Social Constructivists about the role of technologies in social life. (Of course nobody was ever entirely either of these things, nor did any such debate really happen in the sense of two groups of people sitting down and hashing things out in an auditorium. But this is the story by which we understand the past of our field, and so we will continue.) The Technological Determinists claimed, quite rightly, that technologies create lived reality. Technologies allow certain things, and disallow other things, and those allowances and disallowances require us to behave differently. The door lock allows us to impede the access of others into our homes. And the existence of the lock supports its own use---it is not strange to leave an non-lockable door unlocked, it is entirely expected. But a lockable door may now only be fully used by locking it. My computer allows me to do all manner of important things---like re-reading a PDF of Latour's _Reassembling the Social_---that help me prepare for this class. But it also allows me to get distracted by email in the middle of a conversation---and perhaps "allows" is too weak a word, it practically demands it. Likewise, the Social Constructivists of course, quite rightly, claimed that social realities create technologies. The door lock did not will itself into existence. A society in which door locks are useful---one in which people are not well-disciplined, and are apt to wander in and nick things---created the need for the technology itself. And that social context continues to operate e.g. in sleepy communities where "nobody," to this day, locks their doors. Social needs, such as my need to store and re-read PDFs of Latour, drove the development of computing technology. And social mores still drive my use of it: the stern professorial glance quickly diverts me from my inbox.

But these two theories are fundamentally at an impasse, because like all totalizing theories that live at extremes, they are both wrong. When we ask "why does society take the shape that it does?" and "why does technology take the shape that it does?" we are really asking the same question from two dichotomous perspectives. Latour's "sociology of the missing masses" is an attempt to bridge these perspectives into a useful dyad. Sociology is, by Latour's reckoning, rather like cosmology, in an unfortunate and desperate search for the "missing mass" that would provide the expected whole. "They are constantly looking," he writes in "Where Are the Missing Masses?," "somewhat desperately, for social links sturdy enough to tie all of us together or for moral laws that would be inflexible enough to make us behave properly. . .  Soft humans and weak moralities are all sociologists can get. The society they try to recompose with bodies and norms constantly crumbles. Something is missing, something that should be strongly social and highly moral" (p. 152). What could that be he asks? Technology, he answers. This is a grand claim, but it is what Latour means when he says that we live amongst "thousands of such lieutenants to which we have delegated competencies," and that actually most of our social relations happen with and via nonhumans ("Mixing Humans and Nonhumans Together," p. 310). This deep interpenetration of technological artifacts (from books to religious icons to slide rules to social media apps) into daily life means that in order to accurately explain how society operates, we need to take these artifacts with the utmost seriousness. 

Actor-network theory---more properly "actant-rhizome ontology," though this name has, for some peculiar reason, never stuck---is Latour's attempt to construct an ontology and methodology for doing a novel kind of sociological study, one that traces social connections through artifacts. As he writes in _Reassembling the Social_: we must "follow the actors in their weaving through the things they have added to social skills so as to render more durable the constantly shifting interactions" that otherwise surround them (p. 68). Objects too do things, and can be said to have agency. They are not uniform---there is a difference, as he recognizes, between a speed limit sign and a speed bump, as the former acts through moral law, and the latter through physical law in the destruction of your vehicle's suspension---but the important point is that we cannot know which actors, human and nonhuman, are more important than which other ones until we look carefully and see, until we follow the actors through their network of interactions.

As pure Actor-Network Theory (again, if there ever is or was such a thing) is now unfashionable, outmoded, and unreflexive, the STS field has moved on to approaches from studies of material culture, feminist, and postcolonial STS. Or this is the story that professors will tell you. Secretly, over drinks at the local pub, they will admit their continuing debt to the concept. But it is unfashionable to be seen as a Latourian in polite company. This second story, the one of secret debt, somewhat guiltily admitted, acknowledges the real importance of adding the artifact, on the level with the human, as a source and recipient of social actions. On a broad level it simply helps to see things in a new way by estranging them as actors---the door does not look the same before and after you conceive of it as replacing the work of a sledgehammer and a stonemason. Making the familiar strange is a powerful technique of social scientific inquiry. And on a more personal note, I see these dynamics continuing to play out in the engineering of the self-driving car. What is the autonomous vehicle but a groom for the road? All the questions Latour considers, about skilling/deskilling, disciplining, transcribing, etc. apply equally to the car. It is easier to discipline a few thousand sysadmins, supervisors, programmers, and test drivers than it is to discipline millions of American intent on drinking and texting even at the cost of their own self-destruction. But even meticulously designed objects continue to resist perfection in operation.


Hi Erik - 

>And social mores still drive my use of it: the stern professorial glance quickly diverts me from my inbox.

I'll keep that in mind! 

I'd never made the link to cosmology in quite that way, probably because I'm not well-versed enough in physics to make the (in retrospect obvious) comparison. At some point, perhaps over tea, we should talk about why it's unfashionable. I have my own theories, but I'd love to hear more of yours. 

Erik Stayton: 
In short: I think it is unfashionable because it is unreflexive, and because it has been taken (I think unfairly) to be incompatible with feminist/postcolonial theory. Where does gender/race fit in the network? It can't be a node, it has to be subsumed into each and every connection. But the primarily white men who profess to do ANT tend not to do this. There's a tendency to treat categories of people as colorless and classless ideal types. The lack of reflexivity is a greater concern in my mind, in that the default ANT position is to enter "knowing nothing." It is a method that seems to assume that you can go into a strange world and really "figure things out" by watching what the actors do without importing your own assumptions, which is a bit old-fashioned. But again, it's not impossible to write ANT accounts reflexively, it just isn't the positionality that Latour takes in e.g. _Laboratory Life_ or _Aramis_. Because he is rather old-fashioned too.

Maria Temming: 
**SDQ3: How does the civic labor of moderators described by Matias fit into the deconstructed sharing economy delineated by Cheng?**

Upon reading Cheng’s outline of sharing economy subcategories, I started to wonder which category the reddit moderators’ “civic labor” best fit (Matias). Matias talks about the different angles people take when examining moderator labor—viewing it as digital labor, civic participation, or oligarchy. But in order to classify the reddit moderators’ work according to Cheng’s framework, I think you have to adopt the approach of scholarship on digital labor, which “describes moderation as…free labor in peer production communities like Wikipedia” (Matias). In other words, although reddit moderators do exhibit some qualities of the gift economy—in that they largely give their services “without an agreed method of quid pro quo”—their labor is best classified as commons-based peer production (henceforth C-B PP in this comment), where “small contributions by countless volunteers result in cultural production” (Cheng). In this case, the cultural production would be a subreddit. 

*(Note: I didn’t have time this weekend to read all of Benkler’s “Coase's Penguin, or Linux and the Nature of the Firm” or his chapter in The Wealth of Networks, so I drew most of my info on C-B PP from the corresponding Wikipedia article, which was satisfyingly meta.)*

One way reddit moderator labor corresponds to C-B PP is that “the incentive to participate has to do with social recognition and personal satisfaction” (Cheng). C-B PP relies on people who “revel in creating something new or better” (Wiki). Judging by Matias’ article, moderators do stand to gain social recognition by their status—enough that they felt beholden to their communities when the 2015 blackout happened, for example. Moderators also appear to revel in making their subreddits better, since they leveraged the blackout to make reddit “better meet their needs *and the needs of their communities*.” Matias further alludes to the deep personal satisfaction of moderator work by likening subreddits to “neighborhood societies, churches, and social movements.” And whether moderators self-identify as hosts or dictators, it’s clear by the voluntary nature of their work that moderating is a labor of love.

Which brings me to the next distinction of C-B PP: “designed without a need for financial compensation for contributors” (Wiki). Moderators perform “uncompensated labor,” which, Matias points out, is not unvalued labor: professional services charged 4-25 cents per comment in 2014 (Matias). But again, it’s work noting that the moderators don’t demand monetary compensation, even during the blackout. 

Moderators also align with C-B PP in that they “self-assign tasks that suit their own skills, expertise, or interests” (Wiki). A reddit user can’t be forced to moderate a subreddit; on the contrary, they have to actively pursue the job through applications, mentorships, and sometimes even internships. Moreover, the varied cultures subreddits—which I assume reflect the “policies” some moderators tout, at least in part (Matias)—demonstrate that moderators help shape “dynamic content that reflects [their] individual skills” (Wiki). Moderators’ individual creative energies are also manifested in the foundations of new subreddits, and the unique communities that moderators develop therein. 

One way that moderator labor doesn’t quite fit the C-B PP model is that C-B PP supposedly has “less rigid hierarchical structures”—less rigid in comparison to firm production (Wiki). True, moderators do embody some of this “decentralized, participant-driven method of working” (Wiki). Matias talks about how moderators’ participation in the blackout were determined by various community-related factors and relations with other moderators. But there’s still some stringently “central decision-making” in reddit moderator work (Wiki): established moderators “gate-keep” the process of becoming a moderator, superior moderators can effectively fire newer moderators, they develop moderation policies, etc (Matias). Whether moderators describe themselves as dictators or defenders, reddit moderation seems more centralized than pure C-B PP should allow. 

Hi Maria - 

I actually took out Nate's article at the last minute, so I both apologize that you evidently read it before I did that but am also glad that you did (it's a good paper and tied into this course; in retrospect, I should have kept it here and moved Latour to the bots section, but so it goes). 

I think you bring up a good discussion of reddit moderation in the context of C-B PP, especially with how you've complicated the idea of what 'hierarchy' and 'centralization' even look like in this context. It's something I've long felt Benkler (admittedly, writing about a different system) was a bit too saccharine about. 

Christine Konicki: 
**SDQ3: Generally, when one imagines a menial job, one thinks of working at McDonald's, working as a janitor, or working as a cleaner of toilets and plumbing. How do Irani and Chen demonstrate the unpleasantness and menial nature of working as one of the invisible moderators/data workers ( a job that many college graduates ironically take to avoid the menial labor described in this question)?**

Irani talks about this invisible work force behind social media and technology as a group while Chen talks specifically about content moderators. The former is portrayed as a struggle between worker and manager; the latter is portrayed as a struggle between worker and the dark side of humanity. In this response, we shall look at both separately and then together through their commonalities.

Irani describes this invisible work force as "data janitors" who never partake in the luxuries of working at big companies like Google (free food, shuttle, celebrated and open workspaces, being showcased to everyone as the "engineers" and "thinkers" of the future). However, we know from this reading that none of the inventions and algorithms and AI applications would be remotely possible without the hidden work of off-the-books data janitors, some of whom don't even make minimum wage. In a world where many people fear automation and robots taking over the workspace and rendering the masses unemployed, no one (according to Irani) seems to be talking about the human microworkers and monitors who, in a way, control these automated beings.

A ML algorithm, robot, or other creation intended to be artificially intelligent in some fashion must be trained on data in order to classify and process data. Such processes include dividing data into groups, pattern-matching, recognizing information, etc. However, there is a cultural element to the data that applications based in AI cannot process and require additional settings from these human microworkers to train them further. Essentially, this "invisible" workforce is the hand that directs these automated machines. Big companies, however, consider these people a temporarily necessary hurdle that will be removed once AI is everywhere (even though this massive workforce--rather than the engineers--is what enables these applications to work properly). They fail to recognize that the algorithms they come up with are trained by underpaid, overworked people, not by a wizard or a series of hand-waves.

When a workforce is not recognized for its importance, the people don't make minimum wage, are unable to utilize their own judgment to contribute to the company's ideas, and never have the opportunity to problem solve or think creatively. Much like a 9-to-5 job sitting in a cubicle updating spreadsheets "Office Space"-style, the job of a data worker in a large company focused on technology and social media can feel dehumanizing, monotonous and robotic. Being a software engineer at Facebook or Amazon could feel this way to some people, particularly people not used to the corporate lifestyle. However, SDEs are at least compensated remarkably well by comparison, even if many do leave their companies after 2-4 years. A data janitor doesn't have this luxury and, depending on the company, may make less than someone in the service industry who flips burgers and smells like chicken fat all day. The people in the latter group, at least, are acknowledged and thanked regularly by the public for the services they provide; the general public doesn't seem to know that data workers exist and just assume that "magic and algorithms" take care of everything.

The subgroup of content moderators discussed by Chen is even worse off than someone who, say, trains ML algorithms all day without getting credit for it. Like the general group of data workers, the general public has no idea of their existence (particularly since moderators need to sign strict NDA's barring them from discussing their work with almost anyone). For the general public, this means that they never come into contact with the nastiness of the Internet; content moderators, however, spend their workdays hunting for posts, images, and videos that violate the terms of service and expectations of a given site (e.g. Twitter, YouTube, etc.). Potential categories for violation include porn, gore, involvement of minors in inappropriate acts, sexual solicitation, sexual images, racism, hate speech, abuse, etc.

If the moderation is active and performed in real time (with newer and newer posts constantly appearing at the top of a stack of posts), then the workers must decide quickly on whether a given post is in violation (spending a few seconds at the most). The pressure of keeping up with the moderation, staying active, and constantly clicking from inappropriate item to inappropriate item is hard enough, but the content, according to Chen, is what can make the job hellish.

For some, the graphic, violent content (such as brutal street fights, animal torture, suicide bombings, decapitations, horrific traffic accident, and other gory scenarios) is what takes a toll. For others, it's the content involving minors, particularly when sexual, violent or both. Whatever it is, the common theme seems to be that these workers are constantly being exposed to the darkest parts of what humanity are capable of, the kinds of things that most people may impulsively imagine but never actually commit. The sad part is, all the moderators see every single day is the sick shit that people who revel in their--for lack of a better word--evil do. The only thing worse than the fact that they do it is that they take pride in recording their "accomplishments" and putting them online.

Regardless of how good the pay is (one person consulted in the article was being paid well above minimum wage), there is a new level of dehumanization that can come from this kind of work. People argue that having to work for a fast food company and spend days and nights cleaning up messes and serving disgusting food is demeaning and awful (as someone who has done this, I definitely concur that it's unpleasant). However, I didn't have to hunt down kiddie porn or dog fights or videos of people hurting each other like the content moderators did; there's a whole new level of dehumanization that comes from doing this every day. You have to become immune (i.e. "used to") to the sick content in front of you in order to do the job successfully, but a side effect mentioned in the article is the paranoia about the other people you encounter in daily life.

When working a job in fast food, you grow to expect the worst from people: They'll probably be rude, they'll probably be obnoxious when they eat, and they'll probably have no qualms about making a mess or letting their kids run around like tornados destroying everything in their path. In general, you expect people to be inconsiderate assholes. But being a content moderator seems to carry with it a whole new expectation of how disgusting people can be. You'll expect people to enjoy abusing animals, abusing other people, abusing themselves by selling their bodies to solicit sex, and generally enjoy the sickness that they're trying to spread over the Internet. However, when working at McDonald's, you can put faces to the actions; content moderators cannot do this because the actions are linked to social media accounts, not actual people with faces. For all they know, they could pass the person whose content they just deleted on the street within an hour of leaving the office. In a way, the moderators grow to expect sickness everywhere, much like an American soldier traveling to the heart of darkness in *Apocalypse Now* or Travis Bickel cruising down the depraved streets in *Taxi Driver*.

In general, the data janitors (whether they're training algorithms or hunting for inappropriate content) are ignored, underrepresented, and treated like pieces of wood in a building. The work they do is assumed to be done automatically by some magical hand-waving and algorithms that are capable of reading people and interpreting content in a cultural and moral context. In reality, this reflects that the general public, despite using technology for hours at a time every day, is incredibly uneducated about how it works and who actually makes it happen. In order for the unseen jobs of data janitors and content moderators to carry at least the notoriety of a general menial laborer (who is seen by the general public every day), the public needs to learn more about this black box of social media and the Internet and (hopefully) make a stink about it.

Hi Christine - 

I think you've done a nice job here of deepening the comparison that Irani makes to service workers who are responsible for cleaning up the mess that other people left behind (and as a former restaurant dishwasher / floor mopper I too can relate). One thing worth considering here is that many, though not all, service workers are unionized: SEIU is one of the largest unions in the country. I found it interesting at the end of Irani's piece that she calls for GBI as a solution as opposed to unionization, which would seem to me to indicate a shift in what is seen as possible for workers in contemporary society. 

Mike Sun: 
**DQ8: How does Latour define the work that technologies - what he calls nonhuman actors - perform? What does he think these nonhumans do to/for humans, and how can we see it? And why does he think that, from the perspective of the social sciences, splitting the world into 'society' and 'technology' is analytically unhelpful?**

Latour uses the example of a door to define the type of work that nonhuman actors perform. He describes how the essential technology of a wall affords both asymmetry and irreversibility, separating the cold outside from the warm inside, and how this delineation necessitates doors. Without doors, after all, the effort required for a human to enter and exit a wall would involve some combination of destroying part of the wall and rebuilding it. Using Latour’s terminology, humans have translated, or delegated, the enormous effort of maintaining these wall properties to a door. And the exact work that nonhuman actors – such as a door hinge – perform is defined by the amount of work humans and nonhumans would have to do in their stead.

However, doors have a tendency to remain open if the humans that use them forget to close them, requiring the need for door-closers – delegating the larger effort of disciplining the entire human population to just disciplining one door-closer. As Latour goes on to argue, this door-closer could be human or nonhuman, depending on the technological and social constraints present. While a human door-closer (such as a bellboy) requires continuous and more strenuous discipline, the fixed nature of a nonhuman, automatic door-closer can exclude some groups of people from using it effectively. Since the choice is not always obvious – places such as hotels, which care more about servicing every customer might prefer a human to a nonhuman door-closer – there is a high degree of interchangeability between human and nonhuman actors, and so the separation of skills and jobs into “societal” and “technological” is useless. Instead, Latour believes that “Knowledge, morality, craft, force, sociability are not properties of humans but of humans accompanied by their retinue of delegated characters”, and thereby suggests that any study of social relations must also study the corresponding nonhuman scripts (which he defines as “the role human or nonhuman actors play”), just as any technological study should analyze the human-delegated tasks.

Finally, I find it interesting that Latour, a French sociologist, chose specifically this piece, a challenge to “the assumptions sociologists often hold about the “social context” of machines”, to write under the guise of “technologist Jim Johnson”. It feels as though Latour was trying to bridge the gap between society and technology on his credentials alone. After all, if a technologist is arguing sociology, doesn’t that mean the world shouldn’t be analyzed in this binary?


Hi Mike - 

If you read the footnote on the bottom of page 304 you will get a little bit of that. Yes, Latour is playing with a lot of things about agency in this piece, including how the 'technology' of an author-function, or of an academic paper, may do certain kinds of work delegated by the human being who proximately wrote the paper. Latour, who for many years taught at the French equivalent of MIT, definitely likes to position himself somewhere between sociologists and technologists, or, as Erik pointed out above, perhaps as the point that fuses them into a single thing. 

Frankie Schembri: 
**DQ8: How does Latour define the work that technologies - what he calls nonhuman actors - perform? What does he think these nonhumans do to/for humans, and how can we see it? And why does he think that, from the perspective of the social sciences, splitting the world into 'society' and 'technology' is analytically unhelpful?**

In “Mixing Humans and Non-Humans Together: The Sociology of a Door-Closer,” sociologist Bruno Latour, writing under a pseudonym as Jim Johnson (Latour is French and explains in a footnote that he didn’t think American sociologists would take him seriously) regards technologies as “nonhuman actors” and suggests the problems sociologists run into when ignoring the agency of these actors. Latour uses the example of a door-closing mechanism to illustrate how nonhuman and actors relate to one another from a sociological standpoint. When human actors use a door on hinges to open and close a section of wall instead of destroying and rebuilding the wall every time they need to access or exit the closed environment inside, they are translating or delegating a major effort into a minor one. The task of destroying and rebuilding the barrier between inside and outside has been translated by a human to a nonhuman (the hinges). In terms of making sure the door remains closed, humans could assign another human actor to this task, but it is more efficient to automate it, and so another nonhuman actor (a piston-spring mechanism or groom) is tasked with making sure the door shuts after it is opened by a human. 

In addition to human actors delegating and translating tasks to nonhuman actors, the nonhuman technologies also have agency over humans in social contexts. Latour asserts that nonhuman actors can prescribe behaviors – i.e. force humans to behave/react in a certain way – and discriminate between users based on the behaviors inscribed to them by the engineers who designed them. It’s a very circular phenomenon – human engineers or enunciators give the nonhuman machinery a set of inscribed attributes, which in turn prescribe behaviors back on human actors when they interact with the machinery. In the door example, Latour cites the fact that a door-closer with a strong spring could force humans to move quickly after each other through the door or else end up with a bloody nose. Similarly, the heavy piston mechanism on Latour’s house’s door discriminates against children and elderly people who cannot create enough force to close it properly. 

Latour argues against sociologists’ tendencies to create an artificial divide between human actors and their associated attributes, and nonhuman technologies. While some sociologists disagree with anthropomorphic projection (the application of human behaviors and attributes onto nonhuman technology), Latour argues that the word anthropomorphic in and of itself relates to things that are shaped like humans or give shape to humans. In this sense, the door-closing mechanism is both shaped by humans (made by men, substitute for the actions of men) and gives shape to humans by prescribing their behavior as they interact with the door. 

Although it is not explicitly mentioned in the article, Latour brings up many of the key words and concepts of a branch of social theory to which he helped to pioneer: actor-network theory. Actor-network theory treats both human and nonhuman actors as part of social networks. It defines social relationships as both material (between physical things) and semiotic (between non-physical concepts). Unlike other branches of network theory and sociology, actor-network theory does not attempt to explain why or how networks originate between human and nonhuman actors, but provides a methodology for analyzing the social relationships between the actors in a network. 

Looking back to Winner’s piece “Do Artifacts have Politics?” – Latour would definitely agree that nonhuman technological artifacts have both inscribed politics (built by political actors and designed for the translation of a political task) and the ability to prescribe politics on the human actors using them. Latour in fact takes the argument one step further than Winner and argues that nonhuman actors have just as much, if not more agency in exerting social and political power over human actors than other human beings.

This is fascinating piece and really places emphasis on the importance of developing a language through which to communicate one’s theories in order to properly and credibly explain one’s ideas. I’m a language junkie and one thing I found interesting was Latour’s preoccupation with classifying technological artifacts as nonhuman versus inhuman actors. I’m guessing this probably has to do with the fact the inhuman carries some negative connotations and seems to suggest that the thing is incapable or unwilling to carry human attributes – i.e. morality. Latour makes it very clear that nonhuman actors can be moral, and have, in his opinion, a more consistent morality than humans. I’m interested in reading more about sociologists and academics who view technological artifacts in such a positive light – was fear of the singularity not as pervasive in France when Latour wrote this piece? Or was he caught up in the technological utopianism of the late 20th century? 

Hi Frankie - 

> I’m a language junkie and one thing I found interesting was Latour’s preoccupation with classifying technological artifacts as nonhuman versus inhuman actors. 

Let's definitely talk about this more in class. It will be a good way to talk about this course and also to set us up for the bot unit later on. You might look into this a little bit more (i.e., why he made this choice) if you like, and also at Erik's point re: actant-rhizome ontology. 

I don't think that Latour would be classified as a technological utopian by any means. In my reading, he's always just allowed himself to be amazed by the tremendous amount of work done by everyday things which (he thinks) other people take for granted simply because they are done by nonhumans. His focus on morality is often read biographically (he's a devout Catholic), but I tend to interpret it as him critiquing human beings in reverse. 

A lot of people who don't like (frankly, don't read) Latour tend to dismiss him by saying "oh he's a crazy French dude who thinks technologies have agency,"; I tend to view his claim instead as being that *neither* humans nor nonhumans have what we would traditionally call "agency," but it's always been more complicated than that. 

Jenn Yu: 
DQ8: How does Latour define the work that technologies - what he calls nonhuman actors - perform? What does he think these nonhumans do to/for humans, and how can we see it? And why does he think that, from the perspective of the social sciences, splitting the world into 'society' and 'technology' is analytically unhelpful?

Latour defines the work of technologies as any effort saved by humans, by delegating it to a nonhuman actor. We can gain a more concrete idea of what these nonhuman actors do for us by imagining the work that humans and other nonhuman actors would have to do if this character in question did not exist. In Latour’s example of the door, a door hinge provides the work that is equivalent to what a prisoner would need to do to break out of jail, and then turn around and rebuild the hole that provided for his escape. Expanding this to a more generalized description, nonhuman actors arise due the lack of discipline humans have, and they serve to translate major efforts that we would have to expend, into minor ones.  

Technologies save us time and money. Going back to the door case, Latour identifies a simple problem: doors remain open after people go through them. To solve this problem, you can either discipline people to be decent human beings and close doors behind them, or you can substitute these unreliable people with human beings who are specifically delegated the task of opening/closing the doors. These delegated humans align with door hinge (a nonhuman actor) to facilitate the traffic flowing through doors, saving some time and money. 

But it doesn’t stop there. The delegated doorman can start getting lazy or fall asleep on the job, once again becoming an unreliable human. So then we replace the doorman with springs and hydraulic pumps, to not only ensure the door opens and closes, but in such a way that is tailored to the force input by the user. As it becomes increasingly harder to discipline men and women to complete simple tasks, the aligned rows of figurated delegates becomes longer and longer. (is a direct cause-effect relationship, or if this is a positive feedback loop? i.e. Once lazy humans see technology taking care of things for them, they become even more lazy)

One hypothesis claims that by replacing human workers, technologies are deskilling them. However, Latour makes the counterargument that this transition is not purely unidirectional, from soft bodies to hard machines. He points out that drivers pay just as much attention to human traffic directors — if not more — than automated traffic lights. The hypothetical situation in which the absence of the human traffic director results in a car accident is enough to engage the drivers. Even beyond this thought experiment, the physical presence of a human demands greater attention from drivers, since traffic lights can’t actually chase after us and give us tickets if we run a red light. 

In addition to shifting around humans’ roles in the workforce, technology prescribes the way in which users will interact with a product. There are “right” ways to use a given piece of technology (eg. drivers navigate directly in line with traffic lights so they can practice safe driving). Latour even goes as far as to say that technology will discriminate for a certain type of user. Returning to the door example, doors with hydraulic pump mechanisms are quite heavy, making it more difficult for little kids or weaker old people to push. Therefore, they are less likely to use these kinds of doors and effectively biased against.

It is apparent that human and nonhuman actors need to be in constant, dynamic contact. Latour insists that “humans, nonhumans, and even angels are never sufficient in themselves… it is so useless to impose a priori divisions between which skills are human and which ones are not human…” We are so deeply entangled with nonhuman actors through delegation, prescription, substitution (and so on and so forth), it’s bizarre, and almost self-centered, to think that we can cleanly separate the two and just study humans. Technology has developed human-like behaviors (Latour draws a parallel between prescription and “role expectation”), further demanding the attention of sociologists in their study of humans and their social interactions. 


Nice job untangling a challenging essay! I think you also make a good implicit connection to Irani's piece as both she and Latour push back on the simple narrative of technologies as 'deskilling.' 

Peter Downs: 
**SDQ3: How will increasing automation of knowledge work displace humans?**

---

This week’s readings all focused on the idea of displacement – as Latour phrases it, the “transformation of a major effort into a minor one by delegation to technology.” Although he harps on about hinges (and American sociologists), we’ve come a long way since 1988: [research out of Oxford](http://www.oxfordmartin.ox.ac.uk/downloads/academic/The_Future_of_Employment.pdf) estimates (using machine learning, natch) that 47% of American employment is susceptible to full automation in the next two to three decades using only technologies available today. As machines have learned to recognize patterns, jobs traditionally considered “safe” to the perils of automation – largely white collar – have turned out to be on rather shaky ground. The question is, what does this mean for workers?

Lilly Irani and Adrian Chen both paint a rather grim picture of life in an automated world, where humans have been displaced to the “janitorial” or “menial” jobs that computers can’t yet handle: categorizing pornography, filtering beheadings out of your mom’s Facebook feed, transcribing audio, structuring unstructured text, semantically labeling tweets. Adding to the ignominy is an utter lack of recognition in the public eye, because as a culture we are swept up in the dream that technology can work magic without human interruption. This disintermediation dehumanizes, allowing managers to view their employees as data points in a computer business system rather than people; firing, punishing, rewarding them like a video game. These systems are characteristically inflexible, not able to recognize between someone unwilling to carry boxes around a warehouse and someone unable to do so after hours of grueling labor. Not moving fast enough? Click, fired. Or in the case of Uber drivers, as Cheng details, the decision might not even be made by a human – there’s no transparency, so the just-fired “independent contractor” or “entrepreneur” might have no idea if there was a human on the other end, or why they have to find a new way to earn their rent.

Displacement is a function of technology, new or previously-new-and-now-really-old (see: [Luddites.](https://en.wikipedia.org/wiki/Luddite)) The question is, will humans be displaced upwards, sideways, or downwards? Chen and Irani detail the ways humans are currently being displaced downwards. In many cases, the only jobs they can find are in actively displacing themselves further by performing tasks so that computers can learn how to do them as well (or better.) But like all total views, this one isn’t always correct. Chen mentions how little Filipino workers are paid in US dollars – $400 doesn’t seem like a lot of money in the US. But I’ve worked at a company that outsourced “human intelligence tasks” (turning pictures of restaurant menus into machine-searchable, structured, documents) and what seemed like a pittance to us was enough to make our contractors better-paid than even the government employees in their city. Light’s history of the ENIAC machine reveals how the invention of computing machines led to the extinction of the job of human computer, and the total transition of the word’s meaning to refer to a machine (circa 1947; prior, it referred only to a human.) College educated humans no longer had to painstakingly integrate ballistic simulations by hand; now, they could program (“operate”) the computers to do it. Even today, some people still enjoy programming; although there’s probably a few who enjoy numerical integration up-hill both ways in the snow, for the most part we’ve been freed up to work on more interesting problems.

New technologies can also displace upwards, letting humans focus on more interesting, more skill-based work. I spent the last summer working with [B12](https://b12.io/), which was started by an MIT PhD graduate who previously studied computer-human interaction. There, I saw how a [computer business system](https://orchestra.b12.io/) could help make freelancers’ lives easier by letting them focus on the work they loved and at which they excelled, while automating away the more painstaking aspects of working on multiple projects. Coworkers had done research that showed that automation can even improve humans’ skills, or provide opportunities for mentorship. Irani describes task-based microwork platforms like Amazon’s Mechanical Turk as enabling “janitor work” – but the same systems can be used to distribute “macrowork” to freelancers more efficiently than they could find it in other ways. Designers want to design, not sell their design talent. Why should [a lot of humans](https://medium.com/basic-income/self-driving-trucks-are-going-to-hit-us-like-a-human-driven-truck-b8507d9c5961#.6gmmat49d) have to risk their lives for 14 hour-stretches on the highway when robots could do their job instead?

After last week’s readings, the Gray in particular, I found these articles wanting – they analyzed the impacts of the systems, but not the reasons behind them. Why is it that we’re worried about the automation of boring, menial work? Is it because we’re in a society that values work over all else, failing to provide the basic needs of its citizens unless they’re employed? Why should humans have to work in order to survive? Sure, Chen and Irani described real problems with current technological displacements, but they didn’t look harder at the reason behind why someone would actually end up working terrible jobs they hate, and did very little to highlight the positive aspects of technological innovation. As knowledge work become more and more automated, I have hope that we’ll keep creating new and interesting problems to solve. So far that seems to have been the case.

you might also check out the supplemental Irani reading at page 729: http://nms.sagepub.com/content/17/5/720.full.pdf+html

>AMT, then, is not only a means of collaborating, sharing burdens, and pooling cognitive surplus (see Benkler, 2006: 138; Shirky, 2010). Rather, AMT offers a means for new media producers to do boundary work (see Gieryn, 1983), distinguishing innovators from non-innovators in high tech. The boundary work is both rhetorical and organizational, manifested in the actual division of labor AMT enables and the symbolic consequences of those organi- zational acts of purification. One such symbolic consequence is a hierarchy of value recurrent throughout AMT discourse, distinguishing “dull,” “brainless” work from the work of creating systems and building. I take these distinctions as diagnostic – as crea- tive as “menial” workers are in situ (Star and Strauss, 1999; Suchman, 1995: 59; Suchman and Bishop, 2000: 331), these are categories that shape practice in ecologies of AMT. In this hierarchy of value, technological authors (see Philip, 2005) – the appropriators of AMT labor – occupy a high position. This section traces these figures of innovation/creation against routine/service, in historical high-technology discourses through the present moment of high-technology entrepreneurialism and high unemployment.

Hi Peter -- 

I enjoyed your critical take on the readings. You're right that these readings do not take a particularly human-centered approach on the human labor question (although Irani is an anthropologist and her supplemental reading does). The question of why/whether/how much humans should work is probably too big for me to address in this course, although I think I'm going to reread Harvey on Marx's Kapital sometime soon. I am less sanguine than I interpret you to be about the likelihood that many humans will have fulfilling jobs paid for by robots, but I suppose we'll see soon enough. 

As an aside, you may be interested in your classmate /u/estayton's thesis on narratives of the self-driving car: http://cmsw.mit.edu/erik-stayton-driverless-dreams-technological-narratives-the-automated-car/



Sharlene Chiu: 
**DQ6: Compare Cheng and Irani. What do they see as common opportunities or challenges for the peer economy? Where do they differ?**

Both authors acknowledge the tendency for companies to exploit the people who work as providers or data workers. This issue partly lies on the fact that these people work for companies as “independent contractors” instead of employees, so they lack the benefits and pay of official company employees. Cheng discusses liability issues faced by domestic providers in the peer economy. Since these providers are categorized as independent contractors, the associated companies can reroute the blame onto these individuals when unfortunate events such as traffic accidents occur. Companies aren’t legally obligated to protect contractors from discrimination or, in the case of AirBnB, destruction of private property by consumers. Protection was only put into place after widespread media coverage driven by outraged providers.  

Irani, on the other hand, discusses how data workers don’t interact with the consumers at all. One motivation to shift to AI systems is so consumers can avoid the hassle of human interaction when trying to access products. Cheng, by contrast, states that two selling points of the peer economy are that consumers can conduct business directly with the providers of goods and that participants can have positive experiences with strangers. Consumers and providers rate one another to encourage and reward pleasant interactions. However, the companies that hire data workers put in effort to portray their systems as dependent on algorithms instead of on human input. Data workers are essentially swept under the rug. Because consumers aren’t very aware of the role of data workers, the probability of sparking media outrage to influence companies is low.

Though both authors seem to agree that companies distance themselves from their providers, Cheng and Irani provide different opinions on how the government should respond to the rise of the peer economy. Cheng envisions the peer economy as a way to empower individuals by offering them more flexibility in terms of work hours and choice of industry, but she also expands on the idea that the government ought to provide resources to help individuals transition from working under traditional regulations to working in a new peer-sharing system. After all, categorizing these providers as individual contractors allows companies to offer little protection, take less responsibility, and pay fewer wages.

By contrast, Irani focuses more on how the peer economy can disempower individuals by putting more power into the hands of the managers. She agrees that companies can easily exploit their providers, and she also offers examples of how automation can empower lower-level workers in their craft. However, she’s convinced that keeping data workers hidden is the economically better choice for companies. She discusses a solution that involves little government regulation in rewriting wage regulations and worker protections. Instead, Irani considers the idea of basic income guarantee from Brynjolfsson and McAfee’s book. Offering everyone a basic income would empower data workers to refuse companies that operate under unfair conditions. And because many AI systems heavily depend on human input, these companies would be pressured by its contractors, rather than the government, to update its regulations.

Hi Sharlene - 

This was a really, really great comparison of their points, about as well-done as I could have imagined. Nice job! 

Casie Chen: 
**DQ7: Why did Light write this article? How does she think computing was 'feminized' as labor, and when/how did that change? How does she think contemporary accounts of computing erased or minimized the role of women in the functioning of machines? Can you draw any parallels to contemporary computing?**

(This is potentially my favorite thing to talk about omg)

Light wrote this article to highlight and explore the reasons why women's contribution to programming and computing have historically been minimized, and to reappraise their work in a more fair light, in a world where programming and working with computers in general is seen as a masculine occupation. She writes about how nascent technologies opened up new occupations in a time when many men were serving in combat during WWII, and these jobs were feminized, or made to appear domestic, so that it would be appropriate for the consequent surplus of women to fill these positions. In addition, because these fields were so new, the women filling positions like "computer" or "scanning girl" weren't replacing men or competing with them - as a result, their work was considered lesser, and faded from being noteworthy enough to have credit assigned to them in publications, etc.

I think it's interesting (read: kind of funny) that articles quoted on the ENIAC continually refer to the work that it was doing so quickly replaced the work of "many men" when, in a sense, it doesn't seem that it was replacing the work of any men at all. Women had been doing this work, it seems, from the advent of the war onwards, and yet media continued to refer to it as men's work. 

I really enjoyed one quote from this piece: "rather than move up the ladder of success women's work appears to have added more rungs to the bottom" (481). I believe this quote sums up the parallels between women's work and today's "sharing economy" and "data janitor" positions. The people filling these jobs are, in a sense, in surplus, in that there are many people willing to fill empty positions and take little credit for their work in a world where human effort is abstracted away by technology. Portraying these positions as low-skill, simple jobs removes mobility for the demographics taking these jobs, as it puts them in a position of not being able to demonstrate greater skill and advance up the "ladder of success."

Alas, I fear you are correct. 

Kyle Saleeby: 
SDQ3: Is there another method to “clean up” the web?

Lilly Irani presents a brutal view of the work that thousands employees are faced with each day. From employees who work cyclical tasks keeping pace to the rhythm of music, to warehouse employees rushing to make their quota as directed by a computer algorithm, thousands of people toil relentlessly to make our lives comfortable. Although their work is not financially rewarding, Chen’s article in Wired also shows the emotional and mental toll borne by these workers as well. From removing graphic content to crowd sourcing code, internet magicians fill a role that is extremely valuable to the average consumer, even though the consumer may not be aware of them. Although important, these tasks take such a toll on the employees that we must ask if there is a better structure to get to job done?

Irani’s implication that companies favor cheap, controllable labor to increase profit adds complexity to this issue as the largest companies with the power to change the system may not want to agree with an alternative approach. Companies such as Google, Facebook, and Youtube are extremely rooted in the traditional practices of large, employee based moderators. It is understandable that a new system would be acceptable only if it increases profit, efficiency, and accuracy (or at least does not lead to decrease in those aspects.)

To reduce the toll, labor and tedious burden of data janitors, I respectfully propose a system of self-governance, rewarded by social and digital recognition. Many of the tasks described in these articles are ones that can be completed on an impersonal level. Indeed, this may be a cause of the low wages, direct control, or “large army or mindless minions” approach that is described in Irani’s article. However, the risk of impersonalization can in turn be used as an ability to facilitate truly impersonal work. Instead of paying thousands of wage earners to complete very basic and very taxing responsibilities, I propose that these tasks could be opened up to the millions of consumers who use those services. Many digital jobs do not need to be completed by any one particular person, they can be completed by anyone in any location. Facebook users who are 21+ could login in to their account, toggle a switch to become a moderator, and then proceed to moderate content for a spare three minutes of downtime. Content with a threshold of declines would not be displayed.

While there are a number of problems with this system, I believe it could be implemented and iteratively improved until it became comparable to designated moderators. One of the main issues that could inhibit the process is sustaining people’s will to moderate and decision making process used when doing so. To create a sense of ownership of the content, users could moderate the content of their own newsfeed and those of their relatives. If a user chooses not to moderate content and simply ignore the content, they are not penalized. While this choice would only be for users of age, a community of moderators could be incentivized and created such that rewards or internet service discounts could be provided for reasonable amounts of moderation. 

This system of course has many more social, logistical, commercial, and financial implications that would require a much longer approach to address, but a crowd-sourcing approach would be extremely interesting to research and test. I hope it would provide similar results while distributing the burden amongst many shoulders.

Hi Kyle -- 

You raise an interesting prospect! There have been other online communities that have experimented with this model of "many hands make light work": Slashdot, for example, long had a form of meta-moderation that invited frequent readers to moderate the moderation of comments as a form of distributed quality control. 

This could be an interesting research project should you choose to pursue it. There are endless examples of this kind of crowdsourced content. Indeed, one could argue that Facebook's problem is a crowdsourced problem (i.e., making a platform where anyone can publish == lots of stuff that shouldn't have been published), so why not a crowdsourced solution? There may be good political / economic / business / social reasons why the current arrangement exists, but I don't know if they've been well-studied. Nor do I know anyone who has made the specific point that, if you built a force, you might be able to pay content moderators less overall, which seems like it would complicate a lot of arguments coming from traditional places about engagement, exploitation, and moderation. 

Charles Bachmeier: 
DQ4: What kind of work does Irani call "central to the political economy of computing"? What does 'displacement' mean in this context (hint: read the Latour), and what are some kinds of displacement that Chen and Irani describe in their accounts of content moderators and 'data janitors', respectively? What does this displacement do to workers, and what does it do for the companies that employ them?


Throughout Irani’s piece she compares the lofty fantasies of Erik Brynjolfsson and Andrew McAfee in regards to Artificial Intelligence with the reality that a lot of what users views as advanced algorithms that work as AI, for example Google search results, are in fact not solely made by complex algorithms but also combines the work of thousand of unseen, unrecognized, overseas laborers. These worked are contracted by companies like Google, Facebook, and Twitter to handle issues like filtering out gore and porn from a lot of their results which current algorithms are unable to filter out effectively. These ‘data janitors’ are what Irani called “central to the political economy of computing” as they do handle important tasks but are often taken advantage of by big companies allowing them top of companies to maintain a large degree of power.


As contracted laborers, big software companies don’t have to meet many standards in regards to their working conditions or even pay, making pennies on the dollar compared to people with the same level of education working in the United States. It is estimated that there are nearly 100,000 of these behind the scenes workers, which fuels Irani’s argument that “AI” or what software companies try to pass off as AI does not actually eliminate human labor but instead just “displaces” the labor to other countries across the sea. One example of the terrible conditions that these workers has to endure was given in Chen’s article where he describes how workers in the Philippines make sure some of the most gruesome content on the web stays off facebook, but are themselves exposed to hundreds if not thousands of these videos daily causing severe mental problems, problems which the companies fail to fix, opting to replace mentally disturbed workers instead of fixing what they have broken.


Irani’s stance is that AI, in the forms of driverless cars and automated assembly line robots like those seen in the Amazon warehouse will not completely replace human labor, just displace work to countries where work is cheap, keeping power in the hands of top executives. But Irani shows an example of how automation and human labor can work together for the benefit of executives and skilled laborers. This is the Treuhand workshop in Chemnitz, Germany, where skilled workers in a trade are given tasks from their managers and themselves running the complex machinery. With the background in the trade they can maintain a high standard of craftsmanship while keeping labor costs low. Irani describes this a perfect balance and the standard with which other companies should operate.


Hi Charlie -- 

I think you addressed this really well, particularly in observing how the move to independent contracting shifts the mental health cost off of companies that inflict it and onto the government/medical industry books as they try to help workers recover. 

Julia Guo: 
**DQ8: How does Latour define the work that technologies - what he calls nonhuman actors - perform? What does he think these nonhumans do to/for humans, and how can we see it? And why does he think that, from the perspective of the social sciences, splitting the world into 'society' and 'technology' is analytically unhelpful?**

Latour uses the metaphor of a door and its respective “door-closer” to describe the role of nonhuman actors and their deeply intertwined connections to humans in our society. To evaluate the work that a technology performs, Latour writes, we can imagine the work that humans would have to do if that technology didn’t exist. For example, doors substitute the work of people having to break down and reconstruct a wall every time they want to enter a room or building. 

However, it doesn’t just stop there - often humans who use doors leave it open, which leads to cold air flowing into a heated room and other undesirables. We could try to discipline every person to close the door behind them, but that is impractical, and Latour maintains the idea that humans are inherently unreliable; instead, we can delegate the work of opening and closing the door to a single human, and give them the role of a bellboy, but then *they* might also be unreliable at times. So, we again substitute the work done by this human agent with a nonhuman actor, such as a spring or hydraulic piston. And we can continue this chain of substitution with anything and everything else in the world, once we adopt the paradigm that technologies or nonhuman actors serve to substitute the work that humans would otherwise have to do - once we try to imagine our lives without a particular item, that item’s function becomes immediately clear.

Continuing upon this train of thought, Latour argues that the line between nonhumans’ and humans’ effects on society is blurred. It is hard to have one without the other, and they are intrinsically tied - nonhuman actors often prescribe the social relations of humans, and vice versa. For something even as simple as a door, the way the door-closer is designed prescribes the way the door is used and how people interact with the space. If the door-closer is dependent on the amount of force used to open the door, for instance, this would create a bias against the elderly and young people who might not be able to use as much force. Many of Latour’s points remind me of the Winner paper “Do Artifacts Have Politics?” (which he references briefly in his own paper) as they both discuss the implications of technologies on our way of life, whether or not they are intentional. Latour writes that splitting the world into ‘society’ and ‘technology’ is analytically unhelpful because of this unclear divide. If we think of technology as substituting the work that humans would have originally been subject to, then that puts a spotlight on the fact that nonhuman actors are of equal or even more importance compared to humans when studying any aspect of the human experience.

Hi Julia -- 

I think you've read Latour basically right! Or at least, as right as it is possible to read him. Latour is definitely in conversation with Winner, but I agree that he extends the conclusions to complicate the concept of human agency/will as much as Winner had done with technology, and, in the end, why those two things are all mixed up. 

Christina Wang: 
**SDQ3: Why are companies so secretive about the behind-the-scenes manual labor of their content moderation? What does this imply about the relationship between users and how they perceive the internet, or how companies wish to protect this perception?**


In the New Yorker article, Chen briefly mentions his surprise that Whisper allowed him to write his article on their content moderation process, mainly because other larger tech companies such as Mircosoft, Google, and Facebook had declined to release information. As Chen quotes Roberts, “[manual content moderation] goes to our misunderstandings about the Internet and our view of technology as being somehow magically not human.” 

I think this purposeful covering up can be attributed to two main reasons - it serves as both a strategic choice for maintaining a process that has already been implemented and works well enough, and as a form of image preservation, not only for an individual company, but also for user experience with the Internet as a whole. 

In regards to being strategic, I believe that by requiring moderators to sign nondisclosure agreements, companies are quelling any predicted backlash from the public, simply by keeping the industry as hidden as possible. As a result, companies are redirecting unwanted attention that might criticize the nature of the laborious work, both for being arguably inhumane and mentally detrimental to the employees, and for the outsourced first tier of moderation, saving a company millions while depriving Americans of jobs. 

Yet still, I think being strategic for the sake of keeping a questionable process running is only part of the picture. On a grander level, I agree with what both Chen and Irani talk about in their pieces about the preservation of the internet’s “magic.” By acknowledging the human beings who manually sift through content, tech companies put a dent in the outward image of pristine automation manned high powered algorithms or robotics that seamlessly keep everything running. For users (more importantly, costumers), many who either take technology and its services for granted or do not care to understand how the details of computing works, the magic of technology is similar to pulling the wool over their eyes. It’s easier to view a company like Google as a hip group of hardworking software engineers who are frequented with visiting celebrities, rather than foreign laborers filtering through beheadings and porn. 

Hi Christina -- 

I think you're right about the aesthetic of "hip hardworking engineers" as being a key part of this whole story and how it coheres, at least until people like Adrian Chen (who FYI wrote this for Wired, not TNY) start digging at it. 

Nick Gomez: 
DQ6: Compare Cheng and Irani. What do they see as common opportunities or challenges for the peer economy? Where do they differ?

Cheng and Irani don’t seem to disagree in terms of the opportunities and challenges for the peer economy. Instead, Cheng takes us through various experiences of “cultural data workers” – or the people who filter and comb through the mass of social content on the internet to “keep dick pics and beheadings out of your Facebook”. Cheng details the workplace in which these cultural workers work – the ‘sketchy’ make-shift offices in third world countries, like the Philippines – who supposedly better understand American cultural standards. He also follows the experiences of various American workers, similar cultural workers, who tend to be recent college graduates with humanities degrees, that are tasked with more nuanced content that requires a native understanding of American culture. Cheng notes how the outsourced (in terms of nationality) workers are fractionally paid to their American counterparts, and how both are hired as contractors via third-party companies like TaskUs and don’t have any protections or benefits of traditional employees. Moreover, Cheng focuses on the psychological tax that this type of work has on people. Workers have a up close and personal view of the worst of humanity, often looking at sexual abuse of minors, beheadings, animal abuse, and other disturbing actions. Some report a loss of sexual desire, a constant questioning of others, and other PTSD-like symptoms. According to Cheng, most of these workers don’t have true access to medical professionals and proper counseling, and even if they do, the counseling tends to simply cover up the trauma as it’s still there. Due to these factors, this work has a high turnover rate as workers look to find other jobs as quickly as possible.

Irani takes a more comprehensive view of the entirety of the peer economy. Most of her piece works to narrate and describe her disagreements with the silicon-valley-happy Erik Brynjolfsson and Andrew McAfee ‘The Second Machine Age’. She jadedly points out how that ideology of automation and AI as ‘magic’ is false as most automation and AI deeply relies on their human counter parts to supplement the edge cases or, more commonly, to train and provide curated material to the AI and automation processes for them to work or work well. Furthermore, Irani argues, “human labor is necessary to configure, calibrate, and adjust automation technologies to dapt to a changing world.” According to Irani, “Automation doesn’t replace work. It displaces it,” drawing parallels to other technological advancements that have traditionally created new work to replace the work that it overtook, “like how factory automation created text-based labor.” Irani seems to side more with the views of Simon Head, whose ideology is based on observation of the semi-automation that has existed in the last couple decades, specifically – computing business systems (CBSs). Head describes how CBSs have tightened the work place to a very command-and-control relationship between managers and workers. In this dynamic, workers are directed by scripts and automated commands, as well as held accountable by these same systems. Under this environment, Head argues, creativity and problem solving is hindered and the work numbing and mechanic. 

Irani’s main point seems to be that the Brynjolfsson and McAfee ideology, based on a digitalized, resource abundant, minial work-less society is misguided and fails to take into account all the work that goes into creating ‘the magic’ behind these technologies, and consequently prescribes policy and managerial decisions which are too idealistic and reliant on this AI-will-fix-it-all mindset. Instead, Irani sides more with Head’s prescriptions of increasing the quality of life and work and fostering the creation of complex, human-reliant work while at the same time addressing the livelihoods of the people who do work at the backbone of automation in society, for example, by providing proper mental and health counseling to the cultural data workers Cheng talks about.


Hi Nick - 

DQ6 was supposed to compare Denise Cheng to Irani, not Adrian Chen, so I can see why the peer economy thing would seem a non-sequitur if you were comparing Chen/Irani. No worries, though, we can just treat this as a DQ3 or DQ4. In that viewpoint, I think you do a good job of comparing and contrasting Chen/Irani's takes on a related set of issues. 

Erica Yuen: 
**DQ7: Why did Light write this article? How does she think computing was 'feminized' as labor, and when/how did that change? How does she think contemporary accounts of computing erased or minimized the role of women in the functioning of machines? Can you draw any parallels to contemporary computing?**

Personally, I found this article very enlightening to read, because while I knew already knew that most computing jobs were held by women during World War II, I did not realize that women were not given full credit and respect in the field then. My original understanding was that women were respected as those who provided intellectual backup for the country in a time when all of the “fighting power of strong men” was desperately needed, and computing was not considered “masculine” until the personal computer was marketed as a geeky toy for boys in the 1980s. I had believed that the current gender imbalance today in the computer science field was solely due to boys getting encouraged to play around with computers much more than girls from a young age due to social culture. However, reading Light’s article has open my eyes to the fact that the gender imbalance has roots that are much deeper than the effects of today’s current gender cultures. 

Engineering had always been considered a “masculine” occupation, as it was technically challenging and had impactful effects to the development of the United States, and when the industry was forced to include women in the field during WWII, it suddenly became “feminized” into a domestic and menial job.  In her article, Light emphasizes the fact that the women working in computing were portrayed as interchangeable and nameless minions for the brilliant male head engineers, despite possessing degrees in mathematics and full understanding of ins and outs of the systems. These women were picking up jobs that were viewed too tedious and repetitive to be wasted on men with the same background. The growth of “women’s work” can be attributed to the surplus of skilled women and rise of large low budget research projects. Light discusses how despite doing the bulk of the computing work during WWII, the technicians were not publicly credited in papers, and therefore were not given the opportunity to advance in their careers. Furthermore, the portrayal of the roles of the women by the media minimized the technical aspect of their jobs.

The portrayal of these women is similar the way the “data janitors” are portrayed today: unskilled workers doing necessary tedious work that no else wants to do. This portrayal is a result of the surplus of workers in this area, similar to how there was a surplus of women willing to do computing work during WII, which prevents these workers from progressing in their careers. 


Hi Erica - 

Thanks for this thoughtful response. Light's article does indeed go deeper into the representation here, and I always appreciated how she combined analysis of advertisements with historical records and narratives. 

You and /u/rommiec might also want to read this: https://contexts.org/articles/what-gender-is-science/

> In The Science Education of American Girls, Kim Tolley reports that it was girls who were overrepresented among students of physics, astronomy, chemistry, and natural science in 19th century American schools. Middle-class boys dominated the higher-status classical humanities programs thought to require top rational powers and required for university admission. Science education was regarded as excellent preparation for motherhood, social work, and teaching. Sociologist Katharine Donato tells a similar story about the dawn of American computer programming. Considered functionally analogous to clerical work, it was performed mostly by college-educated women with science or math backgrounds. This changed starting in the 1950s, when the occupation became attractive to men as a growing, intellectually demanding, and potentially lucrative field. The sex segregation of American STEM fields—especially engineering, computer science, and the physical sciences—has shown remarkable stability since about 1980.

Kenny (Kenneth) Friedman: 
**SDQ1: profile any of the authors: their academic training, key contributions and conversations in their field(s), basically who they are and why they matter**

Listen to any talk by Alan Kay (inventor of the GUI, the tablet, and object-oriented programming), and you’re bound to hear the name “Latour”. I’ve heard the name dozens of times, often mentioned when technologists discuss the intersection of humans and computers.

So why do technologists care about a french anthropologist? They care because his work investigates the relationship between humans and nonhumans in a way that few before him had considered.

At the age of 69, Latour is still active in field. He is a professor at Cornell, and has previously taught at UCSD, the London School of Economics, and Harvard. But he was born in 1947, so his work as perfectly paralleled the invention and rise of computers.

Latour was 26 when the first computer with a graphical interface was made, and 48 for the beginning of the rise of the world wide web.

He began his career studying how scientists and engineers work, specifically in Africa and California. Later on, he pivoted to focusing on bench scientists. His first major publication, *Laboratory Life*, argued that the standard description of the scientific method is inconsistent with actual practice. Later, he published the provocatively-titled *We Have Never Been Modern*, which argued “much of modernity [the rise of science, etc] is actually a matter of faith” (Note to self: I should probably read this). 

But most famously, Latour was a key developer of the Actor-network theory (ANT). ANT is a model that accounts for the actions and participation of nonhumans in systems that normally put a strong distinction between humans and other artifacts.

It is this theory that makes Latour popular among the great thinkers in computer science. They wonder and debate what the role of the computer is, can be, and should be.

However, Latour must not have developed the term itself. He once said: 
“There are four things that do not work with actor-network theory; the word actor, the word network, the word theory and the hyphen! Four nails in the coffin.“[0]

[0]: https://web.archive.org/web/20140714210351/http://www.lancaster.ac.uk/sociology/research/publications/papers/latour-recalling-ant.pdf

Maria Temming: 
**SDQ3: Where else have you observed Gray’s characterization of queer identity formation as a "highly social” process on the internet? How do these differ for the people you’ve seen in online, as compared to other queer folk?**

Gray characterizes coming out as a social process because although her teenaged subjects viewed their identities as expressions of inherent, biological desires, Gray recognized that their identities had coalesced through highly social processes. That’s not to say that Gray thinks teenagers’ identities are just phases/experimentation. Rather, Gray argues that they’re best understood as “residues of complicated dialogues.” According to Gray, these experiences are different for rural youth than other queer people because in urban scenes, there’s a “critical mass of LGBTQ visibility” that’s taken for granted. Furthermore, fictionalized LGBTQ people are almost exclusively featured in urban settings, effectively teaching rural youth “to look anywhere but homeward for LGBTQ identities.”

I found Gray’s assessment of rural queer youth really fascinating because so much of it reflects what I’ve observed in the asexual community online—particularly on the Asexuality Visibility and Education Network site. For context, the forum side of the AVEN site is pretty much the largest internet hub of ace interaction. (Note: for my analysis below, I would love to provide much more straight-up textual evidence on the AVEN side of things, but you need an AVEN login to view the forums, and I wouldn’t want to, ah, collapse contexts without an OP’s permission by sharing individual posts here.)

To apply Gray’s argument to the ace community, I’ll start with—people imagining their (a)sexual identities as “inherent desires [or lack thereof] buried under the baggage of community norms.” This is a pervasive mindset among asexuals; the definition of asexuality on the AVEN About Asexuality page is “someone who does not experience sexual attraction” (sounds pretty rigidly innate, although if you look under the “identity” section of that page, there’s more flexibility) and the “born this way” adage underpins many posts. Moreover, people frequently bemoan the baggage of cultural norms, stating that they didn’t realize their own asexuality because we all live in such a sexualized culture—particularly where (a) asexuality isn’t covered in most sex ed programs, and (b) usually an “A” doesn’t make it onto the end of the LGBTQIA acronym.

However, the social construction of asexual identities is written between the lines of many posts, along the same vein as Boyd’s quote from Amy: “I’ve always been attracted to both sexes, but I found my true identity on the internet.” Many people say that they didn’t realize they were ace until they read another asexual person’s message/post/etc, or that they gradually came to the conclusion after bits of many posts (or BuzzFeed videos or whatever) resonated with their own experiences. It’s pretty much unheard of for someone to say they realized their asexuality independent of the internet. So, I think asexual identities, as they’re presented on AVEN, could absolutely be described as “cultural assemblages that work with the materials on hand.”

Another commonality between Gray’s observation of queer rural youth and aces on AVEN is that both groups look online for validation/representation/etc, because they lack media representation. As far as I know, there’s never been an explicitly asexual character on television—and the characters lots of people headcanon as ace (Sherlock Holmes, Sheldon Cooper) are always freakishly smart, socially inept, and, quite frankly, kind of assholes. In the same way *rural erasure* in the media perpetuates the idea that LGBTQ identities and urban identities are fundamentally linked, a similar sort of asexual erasure perpetuates the idea that to be ace, you might need to be a high-functioning sociopath. 

To conclude: even though I obviously haven’t done an in-depth ethnographic analysis of AVEN folks, I definitely see Gray’s framework applicable to this other community of people trying to forge their (a)sexual identities online. And now I’m curious about where else you could extend Gray’s framework to describe seemingly intrinsic identity discovery as social identity formation instead, especially on the internet. 

Hi Maria -- 

Thanks for this thoughtful post about ACE communities. 

>However, the social construction of asexual identities is written between the lines of many posts, along the same vein as Boyd’s quote from Amy: “I’ve always been attracted to both sexes, but I found my true identity on the internet.” Many people say that they didn’t realize they were ace until they read another asexual person’s message/post/etc, or that they gradually came to the conclusion after bits of many posts (or BuzzFeed videos or whatever) resonated with their own experiences. It’s pretty much unheard of for someone to say they realized their asexuality independent of the internet. So, I think asexual identities, as they’re presented on AVEN, could absolutely be described as “cultural assemblages that work with the materials on hand.”

When I read about this, I think about how much this complicates either the straightforward technological determinism or social constructivism cases. I see the same phenomena (and it's interesting, as a Somewhat Old, to remember how much the "born this way" debates dominant when boyd wrote this have fallen away) of people making sense of themselves with these concepts they find lying around. 

Erik Stayton: 
SDQ3: What perspective on empirical social science research is implicit in both the boyd and Gray pieces? How does this perspective help us grapple more productively with technological impacts?

It strikes me that the evidence from this week's readings was what I was desperately grappling for last week, to make concrete the division between the utopian rhetoric of the early Internet theorists/proselytizers, and the lived experience of Internet users today. While last week, our readings talked in broad strokes about law, policy, and norms of corporate behavior, the experience of users caught up in these systems was largely lacking. The occasional concrete example does not excuse the lack of a systematic treatment of the full range of "user" experiences.

Gray and boyd have attempted, in their own areas, to provide that sort of deep, systematic, interpretive treatment of networked sociality. Their social science is a nominalist one, engaged in the exploration of a system of shared meanings created by the participants themselves---in the context of broader social forces. They are concerned with the subjective nature of experience, the ways users of networked systems conceive of their own identities, the poignancy and purpose of their own actions, and the ways that they choose to explain those perceived actions and meanings to others. Their methodology is ideographic, requiring the deep study of individual's realities and motivations through observation and interview. In an important way, this kind of study is I think better at getting at the ground truth of what is going on with technology and the social world than a functionalist study of e.g YouTube ContentID takedowns, or, as Gray positions herself in opposition to, a "media effects" study of the impact of LGBTQ portrayals on television. If the question is whether and to what extent the Internet acts as a liberating (P/p)olitical force for content creators, teens, or whomever, that will not happen at the level of demographics, quantitative and measurable bulk properties, but at the level of personal lived-experience. How people feel about media, or how they rationalize and deal with it, is at least as important as whether it has measurable change-making power at a Political level---like whether it shifts the ballot box toward gay-friendly voting. Experiences of personal identity formation are deeply impactful, and cannot be studied at in aggregate.

So what do these authors add to the study of network cultures? Their studies are particularistic, not necessarily generalizable to the whole youth/LGBT population of the United States let alone the world. But they are insightful, instructive, suggestive. And they are broad enough that I recognize aspects of myself in both of their narratives, in various ways. They add necessary depth to the societal narrative of technological impacts. Statistics showing record teen social media use alone tell us little. Deep social research starts to provide the how and the why, and the context that mediates between utopian visions of unproblematic connection, and dystopian visions of dwindling sociality and media "addiction"/obsession.

Julia Guo: 
**DQ6: How does boyd think that socioeconomic factors influence digital culture among her subjects? What distinctions on/offline remain and what change? How do these factors complicate the idea of identity play discussed elsewhere by boyd and/or by other authors we have encountered?**

Contrary to the idealistic view that the internet and technology will resolve all divides, boyd argues that the case is very much the opposite. While teens may all be “friends” with each other on social media sites such as Facebook, the implicit truth is that this does not reflect the offline world, and segregation exists just as much (if not more) online. Racial and socioeconomic divides present themselves in the form of who teens actually choose to connect and interact with on social media; for example, boyd pointed out that very often the comments on a teen’s posts would almost all be from other teens of the same race. What’s more, this even happened in situations when the teen believed that they were part of a diverse network of people -- which is revealing of another layer of unawareness of the issue. In the case of Hunter, the “geeky, black fourteen-year-old,” when he experiences the context collapse of his “ghetto” sister commenting on the same posts as his geeky magnet school friends (of likely a higher socioeconomic status), the result is borderline catastrophic, needless to say unwanted. Yet this is exactly the cause and effect of the problem -- by trying to segregate these groups, we reinforce the divisions that already exist, rather than trying to expand the mindset of both. That isn’t to say the best solution is to have these groups talk over each other on the same thread, but it’s an interesting question to explore.

boyd makes the case that prejudice, racism, and intolerance are very much still pervasive on the internet, and that this is perpetuated by the segregated online communities that reflect the offline world. In other words, the online world is merely a replica or amplified version of the vices of the offline world - it is the product of the offline world, echoing its issues. This is in contrast to the purpose internet optimists originally hoped for, acting as the driving force for change. Because teens have a fairly homogeneous network and tend to connect to people with whom they have the most in common, combined with a very real sense of “stranger danger” preventing them from leveraging new connections, boyd argues that we have not achieved the transformative potential of the internet. 

The Myspace vs. Facebook case is interesting because it also reveals implicit segregation based on preference of social media sites. When teens identify with one site or the other, with the underlying assumption that MySpace is more “ghetto” and Facebook is more “classy,” this reveals a crucial insight about how the issues of race and class are tied to social media and digital cultures. This also lends itself to the question, is there any way to prevent this? Perhaps only in completely anonymized settings can the socioeconomic and racial divides start to fade; otherwise, we can only work on fixing our deep-rooted issues in the offline world, which will hopefully translate into the online world.

These socioeconomic factors complicate the idea of identity in teens when they clash with the online personas teens choose to display. Take the case of the young black man who wrote about leaving the gangs from his hometown behind, while his Myspace profile, filled with gang insignia, contradicted that claim. Most likely, the student assumed that profile would only be viewed by his local network, and thus it is understandable why his online presence is what it is -- attempting to change his socioeconomic standing would risk alienating his home community. And so for many teens in certain socioeconomic conditions, this requirement to maintain one or many online personas that are dissonant with their true motivations and beliefs and even identities presents a formidable and straining challenge. From a teen’s perspective, they will have to consider: What aspect of my identity will I choose to share on this social media? What am I *not* sharing? And how does this affect me in both the online and offline world?

Hi Julia - 

> boyd makes the case that prejudice, racism, and intolerance are very much still pervasive on the internet, and that this is perpetuated by the segregated online communities that reflect the offline world. In other words, the online world is merely a replica or amplified version of the vices of the offline world - it is the product of the offline world, echoing its issues. 

I definitely think you've correctly characterized boyd w/ your first claim. Do you think - or do you think that *she* thinks - that the offline world 'merely replicates' the online world? Or is it somehow different, even as it is influenced by? I'm not sure what the answer is, btw; wondering about your thoughts. 

Jenn Yu: 
DQ5: What are some examples boyd found of teens (re)crafting their identity in social media? How did her subjects repurpose features of the sites to perform different identities? How did these uses differ from what the designers might have expected or intended, and what challenges might they create for other forms of user research?

Boyd cites several different ways in which teens represent (intentionally and unintentionally) themselves in social media: discrete segmentation of their personalities, fake names, creating avatars, interactions with friends, the list goes on and on. The cases she encountered ranged between two extremes: teens setting up online profiles to reflect a direct perception of themselves, and teens creating separate personas that were meant to be the furthest deviation from their real-world self. In the first extreme, teens were probably using the social media sites for the purposes intended by the designers – an online forum to facilitate the connection among peers. You want to provide as much accurate information as possible, so your friends can find you and stay up to date on your latest relationship status or that awesome concert you went to. In the other extreme, teens may be turning to an online community as an escape or a replacement of reality, or sheer entertainment. Boyd also discusses the interesting example of 4chan, an environment in which users can roam around under the blind freedom of anonymity. Yet despite this supposed lack of identity, teens still sought after attention and self-validation when others promoted their posts.   

There are countless factors and situations that must be considered in an ethnographic evaluation of how teenagers interact and craft their online identities. The author proposes that one approach would be to assume the teens are lying. There are multiple accounts in which a user will use a fake last name, age, or home to protect themselves from potential creeps, feel more in control of their identity, or just because they can. Boyd also makes the point that teens maneuver through social media based on their sense of social context – perceived audience, norms, etc. But by tailoring their online identities to these social contexts, teens are inherently changing the contexts. This meta, dynamic flow makes it even more difficult to conduct user research. Not only do teens blatantly lie in social media, but it is also hard to follow which factors caused which effect. 

Another profound point that Boyd makes is that in joining the Internet revolution, people are not free from the limitations of the physical world (despite Barlow’s strong claims in his “A Declaration of the Independence of Cyberspace”). This reminded me of a book I read for Games and Culture — “My Life as a Night Elf Priest” — in which the author reflects on his interactions within his World of Warcraft community. Despite only knowing his fellow comrades by their usernames, he felt a close bond to them as they fought monsters and went on raids together.  Everything about the virtual game was fictional, and yet, everyone took it very seriously and carved time out from their work lives to play WoW. Their virtual identities were still very real in a sense. 

In more recent years, the Internet is becoming less of a space outside of reality, and becoming reality itself. Gaming communities are huge at MIT, and even though I stubbornly resisted for a solid year, I eventually caved my sophomore year and downloaded League of Legends. I used to scoff at how my friends could be in the same room for 8 solid hours and only interact through the game (kind of like how people will text people literally sitting right next to them). However, I immediately felt a deeper bond with people I already had significant friendships with, simply by them coaching me through fighting my first battles. I even realized that I called a few friends by their League usernames instead of their legal names – it just felt more natural. As internet pervades into reality, our identities are no longer defined by legal documents or historical precedents. 


I am definitely calling on your to talk about LoL for the icebreaker :) 

Nick Gomez: 
DQ5: What are some examples boyd found of teens (re)crafting their identity in social media? How did her subjects repurpose features of the sites to perform different identities? How did these uses differ from what the designers might have expected or intended, and what challenges might they create for other forms of user research?

The reading contains descriptions of various ways in which teens alter and shape their identity online. One of these ways is to purposefully limit who sees what post in a single domain, as is often the case on sites, like Facebook, which try to be all encompassing in context. For example, the authors talks about Hunter, a black teen who was forced to balance his online presence between his geeky friends and his ghetto friends. His ghetto sister and friends often ‘didn’t get the hint’ when he posted about nerdy topics like retro-videogames or school; they’d often comment to be funny or simply comment in a way that juxtaposed the ongoing discussion. To prevent this, he created discrete lists to block certain people from certain posts, thereby curating and targeting his posts to specific friend groups. I’ve found this to be a good representation of what is common, many people, including myself, use Facebook multi-user conversations in messenger to target very specific groups of people, especially when dealing with a group of close friends (i.e. “squad”).

Teens also tend to use different social media sites for different audiences and purposes. For example, Boyd describes the situation of a One-Direction crazed teenage girl who uses Twitter specifically to follow and reply to the posts of One-Direction band members and Tumblr to discuss all-things One-Direction with other fans. This segmentation of services for different purposes is an effective way of avoiding clashes of context, and to today this use of each site continues to evolve. For example, Snapchat and Instagram seem to be new apps teens resort to to share snapshots of their lives with their close friends, while Facebook is more commonly used as a form of communication through its messenger application and as a bulletin board for groups via Facebook groups.

Interestingly, one way in which teens often respond to the obtrusiveness of social media is by providing false details when asked. For example, Boyd discusses Allie whose MySpace details give the impression that “she is ninety-five years old, from Christmas Island, and makes $250,000+ per year.” Of course, once viewing her profile, people can quickly discern that she’s a teenage girl from New Jersey. All types of demographic and personal information questions are often exploited for humorous purposes as well; Facebook’s relationship status is often set to “It’s complicated” or “In a relationship with [insert_best_friend]” while its siblings setting is similarly ‘misused’. 

Obviously, the falsification of demographic and personal information is fairly limiting to research; researchers can never take anything at face value. Additionally, and possibly more crucially, they have to (attempt) account for the intended context or use of a specific account - the One-Direction crazed teen’s Twitter or Tumblr profiles alone would provide little insight into any other aspect of her life. This limitation is often what makes online-network research so difficult, people entertain different personas or attempt to curtail certain accounts towards certain audiences. This is part of the reason that social media sites can hold valuable, not-so-obvious information about its users. Even though Allie gives misinformation to Facebook, it, like Boyd could, can programmatically discern certain qualities, attributes, and facts of a person from the content. It can also likely detect the scope of a Facebook profile, and if Facebook works together with other social media or advertising companies (like Google or Amazon), it and those other services can piece together our digital lives to a better extent than maybe even we can. Facebook probably also knows that Allie is a teenage girl from New Jersey, but it can also probably tell which other music bands she likes, what her political orientation is, her socioeconomic status, etc., all without her having to explicitly provide those specific details.

Hi Nick - 

I think you've got the basic angle boyd takes on how teens craft identity, but I'm not sure she would agree w/ your characterization of this data a "falsification" or "misinformation" as much as a way of performing identity in a way that admittedly does make it harder for social media platforms to research their users quantitatively. Then again, that's why we have qualitative methods :) 

Casie Chen: 
**DQ4: How did danah boyd do research for this book? What perceived gap did she seek to address with this work, and what were her strategies for doing so? Why does she think her arguments will outlast the services her subjects use?**

Boyd believed her arguments would outlast the services her subjects use because the anxiety/panic surrounding various social media, from her perspective, only shifted from service to service as they crop up and die out or become more integrated into society outside of just teenagers (e.g., Facebook). Boyd's research was meant to look past this panic and rationalize teenage behavior surrounding Internet presence, which is often considered irrational, addictive behavior, or some other indicator of <s>the impending collapse of societal values</s>. Therefore, her strategies for dismantling this disparity between preconception and reality involved writing a book that is readable for many broad groups of people, talking to teenagers about their experiences and motivations, and in general drawing her information from the source of what she was researching and comparing that to the perspectives and reactions of those one step removed.

I wonder, as Boyd conducted research and collected anecdotes, whether she considered the bias of teenagers talking to an adult (herself). Most significantly, in her discussion of 4chan, I wonder if the context of her conversations with people about their presence on the site is colored with rationalization beyond their own introspection when participating on boards on the site, because presence on the site is (as far as I know) not considered a particularly savory life choice, and therefore requiring defense to an adult like her.

Hi Casie - 

Smart point about the observer effect. It's not something I recall danah directly addressing in the book, although I believe she did in her (more academic) dissertation. 

Sharlene Chiu: 
**DQ9: What does Gray mean when she characterizes the process of 'coming out' as "highly social"? Who/what are some of the social actors in that process, and how does Gray think they differ for her (rural, youthful) actors as compared to other queer folk?**

Gray characterizes the process of “coming out” as “highly social,” but the question that popped into my head was “Highly social as opposed to what?” The phrase “highly social” brings to mind the idea of many different social actors being involved in the process. I personally don’t know much about what coming out entails, so I briefly searched the internet for the exact meaning of “coming out.” 

[Wikipedia](https://en.wikipedia.org/wiki/Coming_out) vaguely explains that those who “already revealed or no longer conceal their sexual orientation and/or gender identity” have *come out of the closet*, which sheds some context on Gray’s argument that one’s queer identity does not strictly unfold from within oneself. A person’s sexual identity is much more difficult to determine based on one’s physical appearance. People at least have an idea of one’s racial or gender identity at first glance, which makes it easier to form communities of these groups. Due to the virtual invisibility of sexual orientation, it makes sense why Gray claims the process of coming out is more nuanced and complicated than its media portrayals.

For instance, her description of Brandon’s dilemma focused on the fact that he belonged to multiple identity groups, but only one, i.e. his African American identity, was visible and acknowledged. Furthermore, his African American identity seemed to conflict with his bisexual identity, both in college and online. His fellow members of the Black Student Caucus appeared less open to the LGBTQ community, while online LGBTQ communities lacked a presence of African Americans. He eventually revealed his bisexuality to his friends, but based on my interpretation of the text, he still concealed his sexual orientation for the most part. The way Brandon came out doesn’t fit with the popular narrative that the media portrays, as illustrated by his inner turmoil regarding his multiple identities and sense of duty to his local community.

In an urban setting, coming out typically involves complete self-acceptance, even in the face of potential backlash. Those who come out in cities have access to a relatively high LGBTQ population, as well as more options for transportation and housing. However, rural youths like Brandon don’t have the benefit of living in an urban environment. A 5% LGBTQ population in the city still equates to a large community, whereas an LGBTQ community that takes up 5% of a rural population is much harder to access. Rural youths are particularly disadvantaged, because not only do they have less access to the resources that lead to self-discovery, but they also live in areas that place high importance on togetherness.

Gray claims that rural communities place more weight on familiarity and maintaining the status quo, which places an even heavier burden on those who consider coming out. In Brandon’s case, the idea of revealing his identity threatened his friendships and family bonds. This differs from coming out dilemmas in cities, because urban residents have the option to, if need be, remove themselves from unaccepting social circles and enter new support networks. However, for young people in rural areas, the consequences of damaging one’s current support network are greater. 

Hi Sharlene -- 

I think you're basically right about the importance of multiple entity groups. What I think Gray means - and we'll discuss this today - is that although 'coming out' has historically been framed as something an individual does (i.e., realize and articulate their gay identity), it is in fact something that is dependent upon communities, not only in the way you describe, but also in the idea of what coming out even means, that it is a thing one can do, etc. Much the way that you relied on Wikipedia -- itself something that is 'social' in the sense of having been built by people' -- to define the process. 

Mike Sun: 
**DQ7: What does boyd think about the concept of Internet addiction among young people? What kinds of historical evidence does she rely on to analyze the idea and make various arguments? What alternative explanations (if any) does she offer for this kind of behavior in the context of contemporary adolescence?**

Boyd views the concept of Internet addiction as a byproduct of media depictions and a generational gap in perception. She states, “teens often use the word addiction in passing reference to their online activities”, but the older generation would utter the same sentence in a much graver tone. She attributes this not just to the ever-growing technology gap between the youth and their parents, but also to “the overarching media narrative…that teens lack the capacity to maintain a healthy relationship with social media”. Given how much time we spend on Facebook, or how difficult it was for people like Andrew to commit “Facebook suicide”, the natural conclusion is to assume that technology is an addictive substance that must be controlled. The media’s portrayal of technological addiction –bootcamps in China and South Korea, pictures of zombified teens who stayed up until 4 am playing League of Legends, articles of [people dying because they couldn’t leave their computers](http://www.deccanchronicle.com/150908/technology-latest/article/side-effects-deaths-due-caused-video-game-addiction) – portray only the extremest of cases and play into the fear of parents. 

In analyzing the origins of Internet addiction, Boyd turned to a close, historical reading of the “addiction narrative”, as she calls it. While originally only used to describe substance abuse such as drugs or alcohol, as the term became more and more integrated into popular speech, it extended to include any behavioral compulsion as well. Nowadays, the media’s pathologizing of any over-regular behavior as an “addiction” has become such an easy and overused trope that it has lost its original meaning. However, it feels as though it has not lost its negative connotation. After all, no one says that the tennis player is addicted to playing tennis, or that the software developer is addicted to coding, even when [there seems to be enough material on the latter to classify it as such](https://www.amazon.com/Death-March-Edition-Edward-Yourdon/dp/013143635X?tag=bisafetynet-20). Boyd offers her own theory – that the entire concept of Internet addiction is a result of the older generations (parents) projecting their priorities onto their children and the entire generation. When something doesn’t work out the way they want it to, they put the blame on the new-fangled thing they neither had nor understood – the Internet.

Boyd's alternative explanation for this pattern of youth behavior claims that “Internet addiction” is much more of a social phenomenon than it is an endemic. Why does the younger generation prefer to spend so much time on Facebook? As Boyd found out through her interviews, young people would much rather spend their time with their friends in person (as opposed to the media’s portrayal that the Internet is killing “real” communication), but when they can’t achieve that, social media offers an avenue where they can always stay connected in an age marked by parental paranoia and increasingly busier schedules. The Internet is their social learning environment – a way to stay connected and experience different kinds of social situations in an extremely short amount of time. I also think that there is another factor playing into this pattern of behavior – the fact that the fast-paced, ever-growing nature of technology and the Internet have redefined socializing – to the point where the Internet has made its way into in-person gatherings. After all, how many times have people bonded with LAN parties, watching funny cat videos or Facebook stalking mutual friends? (Spoilers: I’ve done all three) 


Christine Konicki: 
**DQ5: What are some examples Boyd found of teens (re)crafting their identity in social media? How did her subjects repurpose features of the sites to perform different identities? How did these uses differ from what the designers might have expected or intended, and what challenges might they create for other forms of user research?**

To respond to this question, I'll compare/contrast two examples Boyd mentioned--Facebook and Twitter. I believe the latter can be included with Instagram and Tumblr (even though they were not mentioned as means for teens to craft identities). The focus will be on the way identities are created through Facebook (a social media site focused on connections between people) and Tumblr/Twitter/Instagram (a group of social media sites all focused on posts in various niches by pseudonym profiles). Other identities **were** mentioned in the book excerpts, but I'd like to focus on these two and offer some additional insight into their differences.

One example mentioned by Boyd is Facebook profiles. Facebook was intended to help people stay connected online, much like on MySpace. A Facebook profile today goes beyond the basics of staying in touch with people; because of the "collision of friend groups," according to Boyd, it has become a constant battle for teens to understand and handle context. They can share links, post updates, and add photos, but because teens stay connected to so many friend groups, they need to find a happy medium for presenting themselves to all the groups. A post about "bitches and weed at a club" would probably not sit well if your parents, teachers, or potential employers came across it. At the time it was created, Facebook probably did not intend for potential employers (or even college admissions officers) to use the site to cross-check the character of an applicant or the information provided by the applicant. But now this paranoid feeling that "anyone could find/share something that's supposed to be private" plays a part in how some teens present themselves.

Some teens less concerned about this disregard the information requested by Facebook for their profile. Instead of providing accurate information, they write things that are intended to be inside jokes (e.g. saying that your best friend is your sister, saying that you're married to a dog, stating that you're 88 years old and live on Mars). Again, Facebook probably did not foresee that users would do this, and this kind of inaccurate information would definitely make it harder to judge trends amongst specific populations whenever a code change/update to the site is tested.
Another example that allows teens much more freedom to express themselves are sites like Twitter, Tumblr and Instagram. Unlike Facebook, these sites are intended to focus less on who the users really are and more on the snippets of information they post. Twitter was designed to let users post short bursts of inconsequential information (i.e. "tweets" from birds). Instagram was designed to let users post (mostly high-quality) images. Tumblr was designed to let users post various multimedia (stories, images, videos, gifs, etc.) to an informal blog. Teens ultimately forge their identities on these sites not through their interpersonal relationships in the real world but rather through the many things they like and the information other people post that appeals to them. People follow communities based around things like sports, fashion, yoga, veganism, various social issues, movies, books, music, celebrities, etc. A teen who wouldn't want to spam their friends' news feeds on Facebook with posts about food porn would instead post photos on Instagram or scroll through/post/reblog various images/gifs of food on Tumblr.

However, one thing that these companies likely did not expect from their sites was the way that the lack of humanity/profile and focus only on posts/photos objectifies users. This is especially the case when teens follow celebrities; they tend to look past the "ongoing scrutiny and lack of privacy" and focus only on the benefits of being rich and famous that are being showcased on these sites. Even teens who are lucky enough to be popular figures amongst the various specific communities they interact with can find themselves objectified because of "onslaught of attention." Nasty comments and disagreements about certain posts on, say, Tumblr are common. Spammy "lol kill yourself" comments can rear their ugly heads on Instagram without cause. And people can argue back and forth over nothing on Twitter in short spurts for what seems like an eternity. All of this comes from the fact that, for the most part, the focus is around posts made by a pseudonym account and not by the person behind it. Teens can follow whomever and post whatever they please without worrying about their parents finding out (depending on the handle they choose). Whether these unpleasantries were foreseen or not by the people who built the websites is not clear. However, they do make it more difficult to track user behavior for the purposes of research because it's more difficult to understand what the person who made the posts was thinking (and therefore much easier to take a shitty comment or a battle over a particular topic out of context).

To explain this better, remember that teens on Facebook are building up a profile based on who they are as people and what they want people to see of their story online. On sites like Tumblr/Twitter/Instagram, the focus is on posts with no sense of linearity or organization. It's easy to see a user change over time and track behavior through data stored by Facebook because the focus is on a user's character and relationships with other people. However, a user on Tumblr/Twitter/Instagram is tracked according to who they follow and what they post with little connection to how they think or who they really are. You might be able to see what they like and which posts they're most likely to enjoy, but ultimately the identity of a user on these sites is much more inconsistent and harder to map with logic for the purposes of research. Boyd discusses the idea of "context" with Facebook and how it might mold what a user posts; there is no context within a profile on Tumblr/Twitter/Instagram other than "someone from community X would really like/hate this post." Users just spam-scroll through everything they like and spam-post whatever they feel like with the appropriate hashtags to indicate their audience. When you take the aforementioned unpleasantries (i.e. nasty comments, arguments, spammy comments, etc.) into account as well, this makes a user's behavior even harder to read.

Ultimately, Facebook allows teens to present the person that they want people they're in contact with to see while Twitter/Tumblr/Instagram allow teens to present the interests and opinions that they want people who like the same things to see without worrying about what people in the real world might say. In both cases, the true user is never completely revealed. Most people avoid posting too much on Facebook about the boring moments or the meltdowns they go through and filter their lives as they see fit, and Twitter/Tumblr/Instagram showcase a person's likes while completely leaving out a person's character. But as Boyd said, neither is meant to completely represent a user. All of these social media represent different environments, and it's up to the users to forge their own contextually appropriate identities depending on the environment, just like in real life.

Hi Christine - 

You make a fascinating argument about how the difficult technical affordances of different systems allow people to construct their identities in different ways! And it's interesting to me how you setup the binary btwn Facebook and everything else: I wonder if that's coincidence or not? i.e., do other sites exist in the negative-space of what Facebook isn't? 

Christine Konicki: 
Oh there's definitely other sites in that negative-space such as 4chan and even Reddit. I set up the binary between FB and the sites I mentioned in my response mainly because I'd never thought of that distinction before. I know a lot of people who suggest people follow them not only on Facebook but also on Twitter, Tumblr, etc. Some people even set Facebook to automatically link to their posts on Instagram or set Twitter to automatically link to their Instagram posts, etc. The perspective where Facebook is meant to be a separate social media circle from those sites is very different from that.

Frankie Schembri: 
**DQ9: What is media effects research, and why is Gray skeptical of it? What does she propose as an alternative for understanding the role of media in constituting queerness?**

Gray defines media effects research as the kind of studies that examine media’s power and influence by attempting to quantify its direct social impact. In this kind of research, media is itself is treated as though it contains inherent power through its intrinsic properties. By this logic, the medium itself is the main agent of change, and not the actors that actually use it for online and offline experiences. 

A media effects study of queer rural youth might give credit to online sites as allowing them to leave their offline lives behind and find acceptance of their sexuality online. Gray sees this kind of study as myopic, ignoring the fact that the relationship people have in using online media is much more complicated than any one “effect” it might have on their online or offline lives. 

Gray proposes that researchers focus instead on looking at media “in situ,” the archaeological term of examining an artifact where it was found to better understand its cultural context. Therefore, an “in situ” study of media does not isolate media use from its actors and communities of use to examine any one “effect” or use. “In situ” studies focus on how media use is part of a larger experience, online, offline, cultural, geographic, and deeply interwoven with individual and collective human work – in the case of rural teenagers, the work of developing an identity and sexuality by engaging with queer realness on and offline.

It seems like Gray tries to situate her study of rural youth developing queer identities by understanding both the politics of rural youth culture, and the politics of queer media available online for identity work. All of her descriptions of rural youth’s media use suggest that identities are composite in nature and that media use is simply one facet of a larger whole. Similarly, in boyd’s studies of how teenagers use social media as a part of their lives, boyd does work to situate the use of media by interviewing the teens in person, visiting their communities, staying up-to-date on their cultural trends, and approaching teen’s use of media as meaning many different things depending on the context.

One interesting motif that I picked up in both boyd and Gray’s pieces is the ideal of scholarly study as validation for a person, group, or practice. One of the teens boyd interviewed wanted her to explain to his parents that his use of social media wasn’t a bad thing or a waste of time. It seemed like the teens who were initially guarded in speaking with either of the researchers about their media use gradually opened up as they felt their responses were taken seriously. So when one finds oneself in a group or community of practice deemed worthy of academic study and research, is that necessarily a positive thing? Does this mean the group or practice is inherently more culturally valuable, real, good, or important? Or when something is worthy of study does that make the practice more marginalized, as it is exotic, other, uncommon, or a phenomena in need of correction? Is there a power imbalance between the older researchers and the teens? Do the teens feel scrutinized or as if their safe spaces have been invaded when researchers like boyd or Gray log in and observe them? 

Hi Frankie -- 

I think you've got a basic read on the situation right. When I think of media effects research, I think of claims that certain media 'do' certain things, e.g. watching Will & Grace makes people more comfortable with gay characters through [blackboxed explanation, just look at the data]. I think what Gray is arguing here, as you point out, is that while media do give things to users (like access to ideas or concepts or communities), those users do complicated things with them, that are often best studied not by beginning from the vantage point of the technology (i.e. "this is the effect tumblr has on youth") but from the POV of the people (i.e. "this is how queer rural youth located in this specific community use a variety of media for this specific context")..

Christina Wang: 
**DQ4: How did danah boyd do research for this book? What perceived gap did she seek to address with this work, and what were her strategies for doing so? Why does she think her arguments will outlast the services her subjects use?**

Through her research, Danah Boyd hopes to close the gap between the public and how it tends to perceive or misconstrue teens’ relationships to the internet and social networks, and the actual motivations, reasons, or habits of how and why teens engage with technology. As she elaborates in her methodological research process, “It is easy to look at Facebook profiles and judge people’s decisions; it is a lot harder to understand and respect why.” 

Boyd conducts her research by undergoing an extensive ethnographic study across multiple diverse communities. She categorizes her approach in two steps; the first is a series of “semi-structured” interviews where she tries to gain a better understanding of a teen’s life and values, and how technology fits into that. Boyd finds that without ever directing asking about technology, the teens always mention its presence when asked to describe their daily life. Her second approach is what she calls “deep hanging out,” where she immerses herself directly into the teens’ lives and their communities by reading the local paper, talking to friends and school administrators, and even sitting around at bars. By taking the time to immerse herself into the real life community of her subjects, she emphasizes the importance of understanding teen culture and values in order to fully understand teen interaction with technology and their online lives. 

A common theme of high school English classes is reading and analyzing “coming of age” short stories. All of them involve characters at the cusp of adulthood facing some difficulty where their decisions shed light upon the values they hold and they growth they have experienced. I find it really fascinating that the modern ‘coming of age story’ cannot be told without mentioning the influence technology has on the lives of teens and their journeys toward adulthood. Talking to kids in middle school and high school, I realized that this younger generation is exposed to a lot more (ie drugs, alcohol, sex etc. [DansGuardian where you at]) than I was at that age. Hence I can understand why parents and older generations that didn’t grow up in conjunction with technology view social media and online networks as a threat. This is precisely the disparity that Boyd seeks to remedy through her research. And while no one uses Myspace anymore, I believe Boyd’s findings of teens using social media to grow, foster communities, find a sense of self, and channel frustrations of society will be a lasting motif as technology continues to develop. 

Hi Christina -- 

I think you're right about boyd's methods, and although I might quibble with the claim about whether 'kids today' are 'exposed' to more than in past generations (i.e., I think it's more complicated than that in several dimensions), you're dead-on in talking about this as coming-of-age stories and how technology 'naturally' emerges in the retelling of them. 

Kenny (Kenneth) Friedman: 
**DQ7: What does boyd think about the concept of Internet addiction among young people? What kinds of historical evidence does she rely on to analyze the idea and make various arguments? What alternative explanations (if any) does she offer for this kind of behavior in the context of contemporary adolescence?**

The concept of internet addiction is widely misunderstood, boyd claims. She doesn’t buy the standard narrative of internet addiction in it’s current form. danah boyd cites three main points as the basis of her hypothesis.

First, the mass media sensationalizes addition. A comedic example: because online news is driven by clicks, and fear mongering stories are more likely to be viewed, the media is portraying social networking as an addition in an attempt to make their media outlet more addicting.

Second, using the terminology of “internet addiction” pushes the blame on the technology. In reality, boyd suggests that “social, cultural, and personal factors” have an unmentioned impact on the extensive use of the internet. It’s likely not the internet, but problems with impulse control in general, that are causing the effect.

Finally, teens increase their social activity on the internet, which is the opposite change in social activity as all other “addictions”. Therefore the teens are actually addicted to each other, more than they are to the technology.

Historically, she points to complaints from decades past about teenagers watching too much TV, or spending too much time talking on the phone, or spending too much time hanging out with friends. The cycle repeats: the older generation doesn’t understand, and won’t accept the next generation’s activities.

Later, boyd goes on to explain that adults might not have a perfect sense of what is “good” for children. The idea that the internet is an addiction inherently implies that the internet is a bad thing. No one has ever been described as addicted to homework, or addicted to broccoli. 

Her main alternative explanation was the limited freedom that teenagers have in their life. Based on interviews with subjects, boyd learned that some teens use social networking on the internet as the only available alternative to face-to-face interaction. The internet is an escape from not only the limited mobility, but an escape from the structured life of modern teenagers.

-----

Personally, I have never agreed more with written commentary on the state of the internet and social media. I think boyd hits the nail on the head. The teenage lack of freedom, combined with a new medium of interaction causes older generations to criticize the usage of the new medium. This occurs, almost completely, without questioning whether or not this new medium is beneficial — there is an implicitly assumption of harm. 

Hi Kenny - 

I think you've read boyd right on all of these points. Nice job! 

Charles Bachmeier: 
DQ5: What are some examples boyd found of teens (re)crafting their identity in social media? How did her subjects repurpose features of the sites to perform different identities? How did these uses differ from what the designers might have expected or intended, and what challenges might they create for other forms of user research?


On the internet nobody knows you’re a dog. This is the idea that on the internet you are anonymous and you can portray yourself as anyone or anything you want. danah boyd herself used the internet when she was a child to escape her dull middle and high school life. This idea still remains on sites like Tumblr, 4chan, and reddit, but a growing trend with social media especially is connecting your real life and online persona for sites like Facebook, Twitter, and Instagram.


One teen boyd described was Hunter who is a geeky, black, fourteen-year-old living in the inner-city in DC. Online Hunter wants to talk about all the nerdy thing he’s passionate about like Legend of Zelda and Pokemon with his fellow internet geeks, but people the status wasn’t intended for, such as his sister, will also see it and often make fun of it. Hunter doesn’t want to simply ban people like his sister as that would be rude, he does care about his family. Instead he’s forced to use the sites filters to selectively choose who on his friend list sees what he posts, effectively living two lives on the internet.


Another teen whose name was left out was applying to an Ivy League School. He wrote an amazing essay about escaping the gangs of his home and the workers in the admissions department were moved by his essay. The department then went to check his Facebook page and found it completely covered in gang signs and cursing. The department felt lied to but boyd countered with the fact that maybe he had to post those images to maintain an image back home. If the other members of the gang saw how he was trying to escape by posting it on his Facebook account, it might have caused him harm. boyd believed that the boy may have put on a facade, an identity that would protect him in the real world.


And in terms of user research, studying social media is difficult because of the fact that often times users will be posting false information. Not to deceive anybody but to maintain a persona, either a persona they want to show others for their own happiness or even safety. Another example brought up was how teens will post that they live on the Moon, or post under a fake name, or that they’re 69 years old. Again not to deceive, maybe that’s what’s popular to do in school and the kid just wants to be funny. This however makes researching people on social media hard when they’re all named XxSWAG6969xX.


Hi Charles - 

I *think* boyd's point would be that the 'dog' joke is, at best, pretty outdated and misleading as a heuristic for understanding the Internet. I'm also not sure she would characterize any of these things as 'facades' or 'false' information that hid a 'real' identity, but rather contend that our 'real' identities are in fact always contextual and performed differently for different people at different times. 

Peter Downs: 
**DQ9: What is media effects research, and why is Gray skeptical of it? What does she propose as an alternative for understanding the role of media in constituting queerness?**

It's hard to believe, but media effects research is the study of the effects of using media on those who use it. Gray is not skeptical of the concept as a whole; rather, she's critical of a particular mindset that she sees as being both incorrect and popular among other researchers in the field: that it is sufficient to study the technological aspects of a media and the immediate reception of the messages it carries. In contrast, Gray proposes an "in situ" approach grounded in ethnography, as done in the related field of New Childhood Studies.

This approach is informed by her 19 months of study of rural young people and their use of "new media" (somehow "the internet" doesn't seem as scholastic) while navigating and exploring their identities, particularly their ideas of queer identity. In particular, her work contrasts rural youth and their context with urban and suburban youth, whose communities tend to already have high levels of visibility for queer members. It turns out, the context in which people live greatly informs their needs and lives. Rather than viewing media as something that happens to people, Gray encourages an approach that frames media of all sorts "as part, rather than the center, of sociality."

Gray's approach is a superset of the approach she critiques – the technologies at hand and their impacts are still part of her analysis. But her work leans towards ethnography; although she details how Amy, Brandon, Josh, and John W. relied on the internet to help discover their queer identities, as she tries to answer *why* and *how* these youth might *need* to rely on the internet, she inevitably details their social, economic, racial, and cultural contexts. In a sense this is critical to understanding the impact that the internet has had on the youth.  As Gray puts it, an "in situ" approach is *required* to understand the effect that media may have or not have on an individual. The alternative view that "communication technologies \[are\] things that produce effects" is far too coarse, far too simple, to capture the complexities of our modern day youth's relationship with technology.


Erica Yuen: 
**DQ7: What does boyd think about the concept of Internet addiction among young people? What kinds of historical evidence does she rely on to analyze the idea and make various arguments? What alternative explanations (if any) does she offer for this kind of behavior in the context of contemporary adolescence?**

Boyd argues that while teenagers appear to be unhealthily addicted to social media and related technologies, their behavior is just a natural response to the human need for unstructured social interaction to grow and develop. The parents of teenagers make up the most concerned demographic of this phenomenon because they believe that social media distract their children from the more important responsibilities, such as school and other structured activities.  To them, social media seems to be a new type of modern drug, as teenagers simply cannot get enough of it. However, they do not fully understand social media as they did not grow up with it, and the conditions of their childhoods were much different.
	
Boyd attributes “Internet addiction” to the reduced in-person socialization that teenagers get nowadays due to stricter parents who want their children to succeed academically, stay safe, and avoid bad influences. She analyzes the various trends and changes over the past few decades that influence the social lives of children. For example, during the Progressive Era, psychologists like Hall redefined adolescence as the time in which children transform into adults. As a result, the general population today views teenagers as “a vulnerable population that needed protection and as potentially delinquent population that had not yet matured.” Teenagers today have much less independence and more structured activities in their lives as a result of this perspective. In addition, there is a lot more concern regarding safety outside of the home. According to specific examples by Boyd, many parents would not leave free time for teenagers to interact with their friends outside of school and other extracurricular activities. To many parents, structure and protection is the best way to develop their child for the real world. However, collaborative environments and independence are extremely important for teenagers to mature, as it allows them to see the world in other perspectives and learn from others. For many teenagers, online social media is the only way they can get that social interaction that they need to develop.

Restrictive parenting styles contribute heavily to the reason why teenagers seek social interaction through online platforms. However, many parents do not realize that they are causing the problem of Internet addiction that they themselves are so frustrated about. Their experiences with social media are different from teenagers, so they do not understand the root causes of the “addiction.” First, they have the freedom to socialize with whomever they want whenever they want, simply because they are adults in control of their own lives. They are able to socialize in person, and do not need to find outlets such as Facebook or MySpace. In addition, when they were growing up, the general public treated being outside alone as much safer, and they most likely did not have to go to as many extracurricular programs, as the stress on competing for college is much higher today. 

This analysis of teenagers’ interaction of the Internet highlights the fact that different users of the Internet have different experiences based on their needs and real world conditions. 


Hi Erica - 

 I'm not sure if she would say parents are 'causing' internet addiction or if she would reject the category altogether (i.e., that they're 'imagining' or 'projecting' addiction). But overall, I think you've read boyd right as she tries to historicize certain conceptions of adolescence and why teens do what they do. 

Kyle Saleeby: 
DQ7: What does boyd think about the concept of Internet addiction among young people? What kinds of historical evidence does she rely on to analyze the idea and make various arguments? What alternative explanations (if any) does she offer for this kind of behavior in the context of contemporary adolescence?

Boyd presents a very interesting and compelling argument that teens are not necessarily addicted to the internet, as many “adults” or older generations claim, but they are rather filling an innate need for social interaction in an increasingly dangerous world. 

While Boyd undertakes a great effort to explain the history and usage of the term addiction throughout the past two centuries, her more powerful argument is one of understanding. By stating that teens are using the internet more as a tool for interaction with others, she implicitly argues that parents are struggling to grasp the real reason that kids seem to be glued to their phones, computers, and tablets. To make her case, Boyd compares a teenager’s level of interaction to that of an adult’s. In today’s day and age, adults likely have far more interaction with their colleagues at work than they realize. Many companies employ a team based framework to assign tasks and manage projects. By nature, adults interact with their peers frequently throughout the day. It could be argued that some parents who do not like interaction would prefer to work individually, but on the whole many adults have become accustomed to a great deal of interaction in the workplace. Teenagers, on the other hand, are not that different from adults. They crave the same interaction that many adults experience. 

If you look at today’s school’s, I would argue that many upper level public education institutions (middle and high schools) work on a lecture/homework model. While teenagers are at school, they do not interact with their peers. Instead, they listen to lectures, quickly shuffle from class to class, and get to interact with friends at end of the day through sports and activities. So while adults have the opportunity to interact for a large part of their time away from home, students are likely to sit and listen for a majority of the day. 

It is not hard to understand that students are looking for more interaction with their peers. There are few people whom society values because they worked independently, without any connection to others. Instead, society seems to value those who are socially mature. Boyd makes the point that while many parents see the internet as a culprit for lower grades and less academics (and those are very important), interaction with others is equally valuable to learn social skills and live in the grown up world. The internet may not itself be an addiction, but rather a tool to alleviate the need to have social interaction with others.

Returning to the education system, a flipped model of teaching has recently gained popularity. In a traditional model, students listen to lecture in class and complete homework and readings at home. Appropriately named, the flipped model of teaching suggests that students watch lectures and read material outside of class while spending traditional lecture time to collaboratively solve problems and practice applying new concepts. In this method, students may have far more interaction with their peers while at school. This would help adults to monitor and indirectly teach social interaction skills and reduce the need for so much interaction outside of class. It would be interesting to study the social effects of this model of teaching over the course of the year. 

Boyd even suggests that some students do not prefer to use the internet for social interaction, even though they use it heavily. These students seem to prefer face to face conversations, but must resort to communicating online due to outside factors. In a way, students agree with parents that they do not necessarily want to be spending a large amount of their time online, but rather face to face with their peers.


Hi Kyle - 

I think you read this well. And I recall once, upon hearing someone from ODL complain that no one in HASS wanted to experiment with flipped classrooms, that, given educational arrangements like ones in this class (i.e., readings and responses are done at home, and discussions done in class assuming reading and responses have been done already) is *already* flipped :) 

Jonathan Sun: 
**Q3: What about Schmidle’s piece on the Syrian refugees -- specifically, the piece's narrative approach to social media -- makes it feel so real and contemporary? (ie. why did I cry while reading it?)**

I want to admit that I, like probably most of us, have not invested enough time into understanding the Syrian refugee crisis as we would like. Although I know of a lot of the “high-level” information about it, and a lot of the viral sentiment around the now-famous (infamous?) photographs of the crisis, this piece was the first to really connect on a very personal, human level. Obviously, this is what a good human story does, and Schmidle is an excellent storyteller, and the events that unfold are absolutely monumental enough that simply recounting them would make for a fascinating and heartbreaking tale.

As a storyteller, I do want to focus on one aspect of the piece – and of the Syrian refugee situation in general – that caught me off guard. I thought that the way apps and social media were presented as so integral to and integrated in the movement made for a deeply humanizing and compelling narrative. So many of the attitudes of the Syrian refugees here in the Western world are disturbingly dismissive – that they are Others, and therefore can be ignored. The matter-of-fact integration of social media and communication apps in the piece affected me deeply, and did a great job of collapsing distance between the figures in the story and our Western world. It may seem silly or glib to discuss social media in the face of such a horrifying event, but I do believe that it may represent a key in making the crisis seem contemporary, close, and immediate. All the geographic and physical aspects of the piece create such distance, but the details (not ever focused on, but rendered simply as a matter-of-fact part of life) of the closed Facebook groups, and communicating on WhatsApp, did a great deal of work in contextualizing the crisis as affecting people who are just like us.

I am always fascinated by danah boyd’s book because, to my understanding, it was groundbreaking at the time – it was one of the first books to really discuss social media (and true social media – not alarmist propaganda) in an honest way, and its integration into the lives of youth. I love reading it because so much of it “just makes sense” – and I remember that times have already changed in the years since it was published – and the years since the interviews within it were conducted. I do think the different today is that social media has reached a greater penetration in most of the world, and across more age groups (after all, the teens in boyd’s work are now adults).

We still see [alarmist stories about social media!](https://twitter.com/nytimes/status/747465734905806848) (and my retort to that [here!](https://twitter.com/jonnysun/status/747493795537821696)). But I believe that once the first generation of digital natives are those in charge, and become the primary audience of the world, that these narratives will change (hopefully). At the very least, I hope we stop seeing social media as some strange, alien, immoral thing and see it the way boyd largely paints it – as a medium that allows people to do what they have always done: connect with people. I think we are slowly reaching this level of penetration.

This all links back to how storytellers – like Schmidle – talk about social media. I think we are all aware of cringe-worthy TV episodes or films which try to deal with social media and technology use in incredibly clunky, misinformed, alarmist ways. Unfortunately, TV and film by and large are lagging behind truly representing our engagement with social media. What I find astounding about Schmidle’s piece regarding social media is its matter-of-factness. It is completely integrated into the story, and it reflects an understanding of social media on Schmidle’s part and the importance of it for the subjects in the piece.

I’ve been fascinated with Donald Glover’s new show Atlanta. Last week’s episode, “The Streisand Effect,” tackled social media directly, and specifically addressed social media “stars”, and the disconnect between those trying to represent their “real” lives on social media, and those creating some sort of performative persona online. Vulture published a [good summary of it!](http://www.vulture.com/2016/09/fx-atlanta-zan-and-the-social-media-star.html) for those who haven’t seen it. Though obviously wildly different, I saw a connection in narrative intent regarding social media in both pieces – Schmidle’s and Glover’s. Donald Glover is a master of social media – he is absolutely a native of the space – and I believe that complex understanding of the mediated world is what makes Atlanta’s episode feel so honest and true in ways that most media about social media do not. Glover approaches the issue with complexity, not alarmist black-and-white-ness, and also avoids presenting it as an “after-school special” topic contained in one episode. Rather, social media is simply a part of life, present in the background of every episode (the main premise of the show centers around dealing with the unexpected, burgeoning rap career of Paper Boi due to a video that went viral on YouTube). Social media isn’t a unique object of focus anymore – it is a part of life. This too does narrative work in collapsing distance. Atlanta is praised as being a singular vision of what it is like to be black in America. Much has been made about the fact that Atlanta has an all-black writing staff. It is a show about the black experience, is very specific and unapologetic to that vision, and yet, does not alienate non-black viewers. I believe that part of that has to do with the matter-of-fact presence of social media.

Social media, because it is so ubiquitous in all of our lives today, becomes a common language with which we can all speak and relate to.

This is the kind of work we are seeing emerge now, as digital natives grow up and become the ones who are telling the stories. I think it’s refreshing and honest. Social media is being portrayed as simply part of daily life, which has the power to collapse distance and humanize, as seen in both Schmidle and Glover’s narratives. 

If boyd claims in her preface that “by and large, the kids are all right,” I want to follow up by saying, “soon, the kids will be in charge.”


Hi Jonny - 

First of all, sorry for making you cry. 

> The matter-of-fact integration of social media and communication apps in the piece affected me deeply, and did a great job of collapsing distance between the figures in the story and our Western world. It may seem silly or glib to discuss social media in the face of such a horrifying event, but I do believe that it may represent a key in making the crisis seem contemporary, close, and immediate. All the geographic and physical aspects of the piece create such distance, but the details (not ever focused on, but rendered simply as a matter-of-fact part of life) of the closed Facebook groups, and communicating on WhatsApp, did a great deal of work in contextualizing the crisis as affecting people who are just like us.

I am reminded of Bruno Latour's aphoristic explanation of what his (weird, powerful, hard-to-understand) method of actor-network theory is and how it works: 

>Just describe the state of affairs at hand... For every hundred books of commentaries, arguments, glosses, there is only one of description. To describe, to be attentive to the concrete states of affairs, to find the uniquely adequate account of a given situation-- I have, myself, always found this incredibly demanding.

I wouldn't call Schmidle's work a work of actor-network theory, but I do think it succeeds for the same reasons, and arrives at many of the same insights: that the very matter-of-factness of social media reveals something more fundamental about its role in society than many academic inquiries of same have tried to do by making it the topic of study. 

Daniela Morin: 
Danah Boyd, a principal researcher at Microsoft and a research assistant professor at New York University, and previous researcher at MIT, brings a closer lens to the lived experiences of teens and the  digital networks they inhabit and sometimes embody.
“What does social media add to the quality of teens social lives and what does it take away? And what can we as a society do when we don’t like the outcomes of the technology, how can we change the equation constructively, while still taking advantage of the features of social media while limiting potential abuse? 

Facebook users were found to be more socio economically ( white, educated well off suburbanites ) as opposed to other platform users such as myspace who were considered subpar and even “ghetto.” This kind of mindset can definitely breed a sort of superiority complex that can exclude the narratives and subsequently perhaps subconsciously  invalidate the digital presence, identity  and experiences of less privileged users of the web and social media platforms. The rise of the “digital tech snob”( usually condescending SES privileged  college educated progressive millennials  who communicate in jargon specific to their particular exclusive tech culture)  can accentuate the proficiency, access and influence people can have with certain affiliations and uses of gadgets and networks especially those who can afford the newest technology and have the resources to become proficient with these gadgets adding to the “us” and “them” those who are worthy of the access and advantages that new technology and networks can give and those who are not. This perpetuates certain levels of prejudices and opinions that can affect how others are perceived as more or less educated, deserving and respected which in turn can affect how they relate to the others in both the digital and physical world and their self esteem. 
In order to maintain a good screen/life balance and healthy self esteem today’s youth should acclimate to the social digital environment that permeates our everyday lives but still remain aware and engaged in the realities of their local community environment. I too believe that Boyd's piece gave qualitative substance to some of our preconceived notions that did not agree with Barlow’s more naïveté  piece which was analogous to a “color-blind” egalitarian society blissfully ignoring the structural hierarchies embedded in our society founded on imperialist white supremacist capitalist patriarchy principles. The research showed that socioeconomic factors still permeate and divide groups of people in the digital world as much as in the stratified physical world. 


The topic of people having multiple planes of existence via aliases and pseudonyms use in different online communities made me think of my own analogous experience as a student from a low SES at a highly prestigious and privileged institution. Cognitive dissonance is described as the “mental stress or discomfort experienced by an individual who holds two or more contradictory beliefs, ideas, or values at the same time; performs an action that is contradictory to one or more beliefs, ideas, or values; or is confronted by new information that conflicts with existing beliefs, ideas, or values.” Double consciousness  is described as the internal conflict experienced by subordinated groups in an oppressive society. It was coined by W.E. B. Du Bois with reference to African American "double consciousness," including his own. These terms adequately describe the lived experience of simultaneous dual identities that online personas can trigger. 


The Grey piece discussed ideas of lgbtq identified youth (and I’m sure this would apply to other marginalized communities) almost “learning” into being, and how to articulate and conceptualize an idealized version of their identity before they are aware they embodied it a language they otherwise would not have available to them to describe themselves and come to find comfort in a label or identity to claim as their own and simultaneously feel part of a community. 

Daniela Morin: 
The visibility of intersectionality and multidimensional personas in the media  adds validity to the experiences and identities of young people who may not see their own identities or the likes of their environment portrayed in the media.(such as rural lgbtq youth not feeling included in the narrative of the lgbtq community often in an urban setting.)

Boyd makes a point of conveying that today’s youth must not be reduced to passive consumers of IT and network tech. when they are in actuality active contributing cultural actors who gain credibility and agency as members of the online community. 

Social media studies grounded in ethnography research becomes a more powerful vehicle for understanding the implications that social networks have on the lived realities and relationship people forge with those in their peer group and their own self perception.


One of our last discussions brought up the topic of hiring more socially/online proficient people to create a dating profile in order to better advertise yourself to potential romantic partners. And this weeks readings made me think of  how people's identities are shaped and sometimes limited by the mediums we use to communicate. Ex. the more visual social media platforms such as snapchat and instagram set a certain aesthetic standard that is too often unattainable and impractical (we can’t all travel the world and leave a conventional lifestyle behind for the sake of a few good instagram pictures)
So I have to ask myself do people’s personal narratives become sensationalized vehicles  for commercial purposes?  
ex. BLM advocacy resulted in apparel being sold to supporters of the cause
Im sure it can become increasingly difficult to gather and correctly interpret data on users when they use the features very features aimed at factually identifying them built into the profiles, as ways to circumvent their real identities and construct their own. (Ex. saying that you’re  67 year old woman who lives in Norway when you are actually a 16 year old teen who lives in oklahoma) 

In my home town a lot of Facebook users would list nordic countries or mythical places ( e.x. hogwarts), perhaps because these places more closely resembled their ideal society as opposed to the reality of living in one of the most impoverished areas in the country with not a lot for young people to do other than join a gang or partake in recreational drug use etc. 

The expression of self on social platforms can have liberating consequences and result in changing power structures -such as access to free quality education online, the ability to call an uber as opposed to paying high taxi rates etc.

Institutions of  power and “concerned adults” often blame technology and use it  as a scapegoat for the real underlying societal structures and issues that cause such phenomena as “youth internet addiction” in the first place. Local governments can work to make more recreational safe parks and encourage young people to become more active, host community fairs for young people to become civically engaged in their communities and likewise parents can make a greater effort to engage with their kids with topics that are relevant to them  

Misunderstanding and ignorance often breeds fear of the unknown so perhaps integrating social media proficiency into education curriculum to make students and parents aware of the benefits as well as the potential overexposures  online presence and usage brings. Social media can be seen as a medium to channel societal and personal frustrations and feel a sense of virtual solidarity with others experiencing similar issues/ circumstance. 
The shift toward visual data i.e.-  Instagram and snapchat, more specialized platform mediums creates a value hierarchy perhaps as we are flooded with more and more information the ease of scrolling and clicking to “like” something is a more convenient  way to forge an identity image as opposed to creating a complete factually accurate biographic profile.
The rise of the meme,how incorporating humor breeds exclusivity to relevant friend groups and issues that are important to the poster. This is a new way for young people to communicate without necessarily using text making it more difficult for adults and people outside their social realm to decipher what they truly mean.
I also thought of the structure of workdays and labor practices in America and how they too shape the way we interact with our online networks. Since Americans working more and longer hours than any other country, leisure time is often spent on social media  because it is an easily accessible digital escape of the hustle and bustle of work and responsibilities.  Perhaps there is a balancing act playing out between recreational use of online platforms vs. taking on more important roles such as online collaboration with co- workers, taking online classes, and  raising awareness of a social justice issues. Its interesting to evaluate the effects of outside factors such as demanding structured schedules ( workdays / curfews) on unstructured absent minded “screen time.”
People become more desensitized to viral videos of injustice or people “coming out” it becomes more commonplace to be indifferent and increasingly difficult to be empathetic so it is interesting to note how the spread of and overabundance stream of  information could affect our emotional sensitivity. 
Perhaps these are a few reasons why it is imperative that research exposes underlying subconscious bias embedded in societal power structures to go beyond surface level knowledge of networked life and help us gain qualitative foundational social context and insight. 

This weeks readings touched upon the themes of rural erasure, perceiving sexuality as a social experience and policing boundaries of labels.  Grey presents queer identities as something that comes into being through the aggregation of doing and participating in certain behaviors and communities  as opposed to something that is innate.

The Syrian refugee piece, “Ten borders” brought up themes that reminded me of the use of the role of social media in the Arab spring uprising the ability of communicative technologies to be used collectively by communities uniting for a socio-political cause allowing regular citizens to circumvent state operated media channels in oppressive regime governments in order to organize activist riots and protests as a means to escape a lived reality through a digital network.
The  Boyd piece ethnographically illustrated the holistic experiences of youth use of social media as a means to communicate with friends they wouldn’t otherwise have the opportunity to see in person. Conveying online communities as a release valve for youth and created  opportunities to share and exchange ideas with only a few keystrokes.

Charles Bachmeier: 
On a side note, Barlow has an adorable [cat](https://en.wikipedia.org/wiki/File:Buck,_sweet_Avatar_Cat_Buckynanda_Ji.jpg) 

Erik Stayton: 
SDQ3: Whatever happened to "cyberspace" between 1996 and 2016? What factors outside the law changed the way we look at freedom on the Internet/WWW?

Cyberspace just isn't what it used to be. Or so it seems when you read John Perry Barlow's "Declaration of the Independence of Cyberspace." It is difficult to imagine a moment when this would have been anything but a series of tired tropes: 
-Cyberspace "is an act of nature" he proclaims, but it is not and never was natural. It was a social, political, and economic phenomenon, and necessarily governed by other kinds of rule.
-Cyberspace is "a world that all may enter without privilege or prejudice," easily proclaimed by a white man who toured with the Grateful Dead. But of course, as we have discovered, prejudice and exclusion does not disappear so easily online.
-Cyberspace is a place where "anyone, anywhere may express his or her beliefs" in this 1996 vision, but of course it is not. Many people remain on censored networks. And many others use this expressive power to bully, harass, and threaten (like Elodis). 
-In Cyberspace "there is no matter here" to regulate, but the infrastructure that makes cyberspace possible is made of ordinary, regulatable matter, as Goldsmith and Wu are right to point out.

There seems to be a general trend in Internet-related scholarship that has relented on the utopian visions of the early 90s. Comparing, for example, Sherry Turkle's 1995 _Life on the Screen_ or even her 2005 _The Second Self_ with her latest books, her point of view has changed considerably. While in her earlier books, the computer was a realm of promise for new types of identity and interaction, it has become something limiting to be pushed back against. Cyberspace may not be the same as regular space, but its differences are no longer so clearly revolutionary. It strikes me that while these shifts from liberation to confinement and control may be different across the legal and cultural realms, they are not entirely independent. Along with new perversions to the cyberspace dream---like #gamergate harassment---come corresponding challenges to the meatspace-independence of cyberspace---the need for some sort of response in law and in code. Cyberspace, at least in the US, might have managed to preserve the fiction of independence had everyone on it behaved well within the law and cultural expectations. But when online infractions also have real costs, it should be no wonder that governments step in to clamp down. 

But there is something else going on here that strikes me as important, and is just hinted at in Goldsmith and Wu's fifth chapter:  that there is a gulf between what the law says, and what those potentially exposed to legal liability actually do. While Dibbel's "A Rape in Cyberspace" hints at one kind of governance, community self-policing, more prominently today we find corporate self-policing, in which large private companies restrict the content they index or serve beyond what the law requires. This can be deeply problematic, as the recent Facebook issues with the Terror of War photograph dramatize. As another example, Youtube's Content ID takedown process (see https://www.eff.org/issues/intellectual-property/guide-to-YouTube-removals) is more favorable to rightsholders than the DMCA itself, and the presumption of guilt stacks things against users. The other side of the Internet's mixed relationship to the law causes a problem when it is in the interests of the policed to be stricter than the law itself. To my mind, and in the eyes of the EFF whose blog I read regularly, these issues challenge the liberalness of the Internet more deeply than most explicitly legal claims. There is always the threat that a little legal liability will produce a draconian response, and it is important to try to think about both the law itself and the likely impacts of doing at least what the law requires.


Hi Erik

> Cyberspace, at least in the US, might have managed to preserve the fiction of independence had everyone on it behaved well within the law and cultural expectations. 

I think this is a good point, and one the readings do not sufficiently address. It was easy for JPB to address Davos as "we"; just being there says something about who is the "we" in the declaration, and implies a certain commonality that makes it easier to imagine a libertarian (or anarchic) yet orderly world. But one of the reasons we have the institutions you identify is precisely to mediate the conflicts of a pluralistic democracy, which, as the Internet extended beyond Davos-we, seem to have moved from unimaginable to inevitable. 

Maria Temming: 
**DQ4**
The founders of HavenCo fancied themselves internet pirates who existed “off-government” and catered to clients who also wanted to circumvent traditional legal regimes. At face value, HavenCo’s founders were totally tongue-in-cheek about bucking against government regulation—they talked a big game about telling “the rest of the world to shove it” for, oh, 80% of Garfinkel’s article. But their actions often contradicted that flippant stance: they assumed the defensive by hiring armed security guards because nation-states had no power in Sealand! No way! But, like, just in case… Another tell of HavenCo’s trepidation in the face of The Man was their policy that clients couldn’t “do anything that would inspire law enforcement…to shut down HavenCo’s mainland internet connections.” Of course, meddling nation-states aside, HavenCo was never truly off-government because they had to obey the laws of Seland. And “particularly lax” as those laws may have seemed, failing to conceptualize how they were beholden to Sealand’s government was the crux of HavenCo’s downfall. 

Before all that, though, HavenCo saw Sealand as a veritable oil well of opportunity—a “safe, secure shelter” from The Powers That Be, where corporations and individuals had “the freedom to store and move data without answering to anybody.” Lackey and his colleagues had a pretty slick operation in mind, one that would make them “completely broke or…fantastically wealthy in five years.” Obviously, they were banking on the latter. 

So, compared to Yahoo. For one thing, HavenCo was intended as a middle finger to the establishment right from the start, whereas Yahoo never set out to intentionally defy the French government. It’s also worth noting that HavenCo was just a small start-up, while Yahoo was the most important internet entrance point when it got caught up in French anti-Nazi law. However, Yahoo’s blasé attitude toward the French government was absolutely reminiscent of HavenCo’s “bugger off” motto. Yahoo was “a product of Silicon Valley’s 1990s bubble culture,” Goldsmith and Wu write, not as susceptible to political pressure as AOL. And Yang definitely shared Lackey’s sense of superiority, claiming it was “very naïve” of the French government to think it could bring Yahoo under its thumb. 

HavenCo crumbled because of (a) government intervention in the form of Prince Michael, who ironically insisted HavenCo adhere to “the norms of international practice and custom,” and then nationalizing HavenCo and ultimately single-handedly voting its founders off the island, and (b) other governments putting pressure on crucial intermediaries (read: banks) not to associate with HavenCo. Similarly, the French government bent Yahoo to its will by coming down on them directly (with $13,000/day fines). After they did battle with traditional legal regimes, both HavenCo and Yahoo declined/shed customers/lost money. But the most significant change in either case was probably the disillusionment of the company founders. Lackey later admitted that sovereignty is nothing without financial backing (apparently forgetting the fact that he didn’t have sovereignty, either). Along the same vein, Yahoo eventually did a total 180, signing The Public Pledge on Self-Discipline for the Chinese Internet Industry, with Yang wearily admitting, ““To be doing business in china, or anywhere else in the world, we have to comply with local law.” *sad trombone noise*

Maria Temming: 
Sorry, I’m gonna throw a little SDQ3 business in here, talking about HavenCo and EFF because (a) I feel like EFF's much more similar to HavenCo than Yahoo, and (b) both the aforementioned groups had such bummer endings to their stories, and EFF has a happier one (at least in the case of the CDA). Okay. EFF reminds me of HavenCo because, unlike Yahoo, EFF wanted internet activity to be totally unmoored from traditional legal regimes. As “internet libertarians,” John Barlow and his comrades thought the internet was threatened by government—much like Lackey with his posse of armed guards. What’s more, much like HavenCo, John Barlow found some backers with deep pockets to support his cause. Goldsmith and Wu admit that EFF “sounded...a bit crazy at first,” and I think it’s fair to say that Garfinkel crafted the dek of his story to make the readers think HavenCo sounded (more than) a little crazy at first. But it quickly becomes apparent that the founders of both HavenCo and EFF took themselves quite seriously, and to anyone who thought them crazy, they adopted the attitude of Barlow’s email: “Let us show them how cunning baffling, and powerful we can be in our own defense.” The major difference between HavenCo and EFF is that EFF worked inside the system of traditional legal regimes by fighting the CDA in court, and when the law ultimately asserted itself, it came down on EFF’s side. *triumphant trumpet noise*
Tl;dr: Barlow’s Declaration of Cyberspace Independence totally could have been renamed, “Welcome to the Internet. Now Bugger Off.”

Hi Maria -- 

First off, I'm glad that now know triumphant trumpet is the opposite of sad trombone. 

You bring up an interesting point about the EFF as comparator. The EFF has indeed shifted over time from 'thoughtleader' in an abstract-philosophical sense to very active legal and tech development that works with (even as it resists) other forms of law. Good read on Garfinkel's craft as a journalist too -- that's a nice GPSW angle I hadn't considered before. 

Jenn Yu: 
DQ4: How did the founders of HavenCo conceptualize their relationship to traditional legal regimes? What did they see as the points of failure and/or opportunity? Compare their experience with the case of Yahoo! described by Goldsmith and Wu. How did traditional legal regimes reassert itself in each case? What changed?

The founders of HavenCo envisioned their startup as being offshore and off-government. HavenCo would be a safe haven, out of reach from the “lawyers, government snoops, and assorted busybodies” of traditional legal regimes. This model had the potential for some mischievous pranks, but as the startup gained increasing funding and growing attention from bigger names, its implications were far greater. Avi Freedman, an Internet billionaire, is excited for HavenCo to “force governments and other organizations to look at issues surrounding the regulation of commerce and the Internet.” Cyberspace defies the traditional concept of “place” as being a physical location, so it’s been largely perceived as a world separate from the our real, industrial one. But when real people start conducting real transactions in it, the government needs to pay greater attention to establishing a legal infrastructure for how we interact within it.   

Despite the relatively smooth process toward establishing Sealand’s sovereignty, there is still potential failure down the road. Previously, the tiny island seemed too petty of a concern for the UK to put forth the effort to pull Sealand back into its reign. But with the growth of HavenCo –  envisioned to be a place with no laws regulating the Internet, cryptography, finance, or labor – the founders are bound to run into trouble with greater legal forces. Bates and Hastings seem unconcerned, maintaining that Britain’s overlooking of Sealand’s weapon violations effectively acknowledges that the country does not have jurisdiction over the island. Worst case, Sealand can fall back to being a first-rate colocation facility. Freedman touts, “Even if you factor out all the questions about jurisdiction and history, you still have a damn fine, secure colocation business with a good economic model.”

Legal and business concerns aside, Sealand’s physical infrastructure is a risk for failure. The forts cylinders are narrow and steep, making it dangerous for setting up and replacing expensive electronic hardware. Although Sealand isn’t meant to become a bustling community of people, its current building arrangement is prohibitive to productivity. 

Jerry Yang had a similar confident, invincible mentality when establishing Yahoo! as a space that couldn’t be regulated by traditional legal regimes. The difference was that Yahoo! was established in countries that did have traditional legal regimes: its servers were based in the US, and it had financial assets in France. Therefore, when Marc Knobel sued Yahoo! for allowing Nazi memorabilia, the French court had a more direct channel for engaging the Internet company and coercing them into filtering out the Nazi content for French users. It also didn’t help that they were hiding a “mirror” site in Sweden, meaning that they couldn’t play the 1st Amendment card.

Yahoo!’s ultimate demise was caused by a rising competitor: Google. It’s ironic that the only way for the company to remain afloat was to sell out and become a vehicle for controlling user content. 

It’s too soon to tell if HavenCo will end with a similar fate. If anything, it’s looking to be more promising than Yahoo!’s experience, for two reasons. 1) All of HavenCo’s user content will be housed on Sealand, which is more or less its own land with its own rules. 2) This is the first data safe-haven of its kind, so there isn’t a foreseeable risk in another company edging them out. Nevertheless, Internet and politics will always be entangled so long as humans are involved. Even if the traditional, territorial government becomes obsolete, a new form will evolve.

*Edit: I just realized the last couple of pages of the Goldsmith & Wu reading got cut off and never printed for me. It turns out that HavenCo did fail and become obsolete, but for factors that were not as traditional as Yahoo!'s case. HavenCo struggled to find banks and financial intermediates that were willing to facilitate their business, proving that commerce over the Internet is still inherently tied to commerce in the real world. Additionally, Prince Michael came into direct conflict with HavenCo when he insisted that all content in his sovereign nation be "appropriate". Unlike Yahoo!'s experience with the French courts, HavenCo was kicked out by its own country - a country whose founding principles were initially what attracted the startup in the first place.

From these cases, it doesn't seem as if the boundaries of traditional legal regimes are changing with respect to the rise of cyberspace; rather, new attempts to resist or revolutionize these relationships are being overpowered by the customs and values that have been long established throughout history. It is true that the Internet was built without geography or matter in mind, but as long as people are the ones using it, the Internet will be yet another artifact of humankind, susceptible to the influence of other artifacts that we have developed.


Hi Jenn -- 

I think you make a good point about the similarities and differences between Yahoo and HavenCo. One interesting note is that both companies were undone by international corporate webs: Yahoo by the advertising regime which belied their claims they couldn't geotarget, and HavenCo by financial intermediaries that mediated between nations as well as companies. And your last point I read as consistent with Star's argument from last week's readings that 'new' infrastructures always grow out of / atop / atwixt older ones. 

Christine Konicki: 
SDQ3: The Internet is described in the readings as a phenomenon with an "open, minimalist and neutral" design that "by nature distrusted centralized control." This description is associated with the idealism surrounding the freedom of cyberspace. How might the freedom and connectedness of the Internet ironically lead to a need for more control? Has the original idealism come to fruition at all?

Men like John Perry Barlow saw the autonomy and vibrance of cyberspace as the beginnings of a society that could transcend physical space and the laws of nation-states; in fact, Barlow advocated for cyberspace to have its own sovereign legal regime. Although Barlow experienced some victories (such as his lofty call to action in his "Declaration," as well as the SCOTUS striking down the CDA as a violation of the 1st Amendment), his vision ultimately never really came to be. Companies like Yahoo agreed to the demands of countries like France and China to filter out certain content from the nations' users and to cooperate with them and their requests. There are now government regulators for different countries/regions. Just a few years ago, a series of malignant, violent Facebook posts landed the poster in a lawsuit (Elonis v US) that made it to the SCOTUS. How did all of these checks come into play?

Recall the parable described in "A Rape in Cyberspace." Recall Mr. Bungle, whose dastardly antics on the fictional cyberspace world of LambdaMOO hurt others but were still allowed to occur at first because the world was so free and open. Ultimately, Mr. Bungle was kicked out of LambdaMOO, and the cyberspace community came together to create a government based around consensus and keeping disruptive guests out. Users like Mr. Bungle are part of why the Internet is no longer the shiny new toy and bringer of hope that it was the in the 1990s; today, we see the Internet as a ubiquitous infrastructure that's built on cooperation. Of course, we don't see the cooperation that goes on between companies and government to keep it safe from Mr. Bungle-like users, but we seem to have accepted that the Internet needs to be regulated to an extent to keep these people from causing mayhem. After all, there's a large magnitude of difference between letting a small group of people live above the law in cyberspace and letting hundreds of millions of people do so.

However, cases like Elonis v US demonstrate a different kind of control and censorship that works separately from the governments and companies and technology that make up the guts of the Internet architecture: filtering on the user's end. The Internet is a place where "physical qualities are irrelevant" and people can present themselves however they choose to. These days, people often note the way that people filter their lives on social media, sometimes to the point where the person in cyberspace and the person in the physical world are completely different. The Internet may thrive on cooperation and freedom of speech, but this is still a funny trend to see when you realize that the Internet was championed as a cradle of freedom and a place where all may enter and express their beliefs.

Moreover, my generation was not introduced to the Internet this way; I never grew up feeling like I could express myself or say whatever I wanted online without consequence. In fact, I remember being told by my parents to "always be careful of what [I] say online" and to remember that anything you post somewhere will be there forever, even if it's not visible to the public eye. Some database somewhere will record it, including what was deleted, what was edited out of an old comment, etc. To quote "The Social Network": "The Internet's not written in pencil; it's written in ink" (see https://www.youtube.com/watch?v=6HbrQMgOUFw). I imagine that most people--even in 1996 when the freedom of the Internet was championed loudly--wouldn't post what Anthony Elonis did in a public forum, let alone say it aloud. Ironically, the openness of the Internet makes us just as eager to share our opinions and express ourselves as we are to keep our darkest thoughts hidden and become paranoid about who might be watching our actions on the Internet. It's like seeing a huge empty ocean with no one visible around and trying to decide whether or not to go for a swim. You may have the ocean all to yourself and be able to do whatever you want while swimming, but there's always a chance that someone else could appear and either watch what you're doing or attempt to kick you out.

Ultimately, this paradox of cyberspace has led to some realization of Barlow's vision. Although the Internet is regulated to varying degrees in different countries and under different companies, people always judge a post/photo/article differently because it appeared online, whether they realize it or not. Elonis's FB posts lacked the intent required for the SCOTUS to uphold his conviction because they were posted on Facebook instead of being written by hand and sent to the people he was posting about. People don't automatically assume that something written in ink online is insincere, but they do have to look at it more carefully and consider its context and its ramifications. The land of cyberspace, in a way, has become its own land where a new set of judgments and expectations come into play. The Internet is not free from physical law as Barlow originally intended, but it has forced physical law to rise to the level of the Internet, adapt to this new world. In a way, even the SCOTUS has essentially conferred a special legal status on cyberspace in order to include it in physical law. When you look at it that way, why would the Internet (an invention based on cooperation) need to be above a society that's constantly adapting in order to include it and cooperate with it?

Hi Christine - 

> The Internet is described in the readings as a phenomenon with an "open, minimalist and neutral" design that "by nature distrusted centralized control."

This made me realize I wanted to ask a question about these readings and Winner but forgot, d'oh. So thanks for invoking a similar subject on your own. 

> Moreover, my generation was not introduced to the Internet this way; I never grew up feeling like I could express myself or say whatever I wanted online without consequence.

Thanks for reminding me that I Am An Old. 

> The Internet is not free from physical law as Barlow originally intended, but it has forced physical law to rise to the level of the Internet, adapt to this new world. In a way, even the SCOTUS has essentially conferred a special legal status on cyberspace in order to include it in physical law. 

I was talking with Erik offline about this point, and it's something I want to discuss in class: for all the JPB-bashing, it is worth noting that SCOTUS basically conferred some special status on his IDEA of the Internet, and if it weren't for that rhetoric, I think we might likely have ended up with a much more limited and worse version. 



Mike Sun: 
**SDQ3: How well do the self-proclaimed ideals of the HavenCo founders align with those put forth by John Perry Barlow in his “Declaration of the Independence of Cyberspace”? Looking back, just how effective were these ideas when put into practice?**

When Ryan Lackey proclaimed that freedom was going to be the next killer app, he may have been thinking explicitly of the freedom for corporations and to store and move data, but he primarily envisioned himself as a champion of off-government—which, to him meant “without answering to anybody, including competitors, regulators, and lawyers”.  HavenCo was specifically founded to be a data haven for unpopular, unconventional data—a place where companies and individual seeking to avoid the annoyances of the law could operate “without answering to anybody, including competitors, regulators, and lawyers”. In many ways, I feel as though the end goal of HavenCo was to become a self-proclaimed defender of the “virus of liberty” that Barlow claimed the United States (among other nations) was trying to eradicate. Though HavenCo chose to oppose government by providing their own cyber-sanctuary, there are still some striking similarities between their ideals and Barlow’s (somewhat utopian) ideals of cyberspace. For one, as Maria (/u/SETIfangirl) pointed out before, they showed they were willing to go to great, shotgun-ridden lengths in defense of their idea.

Unfortunately, as I somewhat hinted at, the ideals of Barlow were nothing more than just ideals—more utopian than practical. In 2008, HavenCo operations on Sealand suddenly halted with no further explanation given to the public. In 2012, James Grimmelmann published his law thesis titled “Sealand, HavenCo, and the Rule of Law”, which detailed his two-year long historical research into the rise and fall of HavenCo. The primary reason for its fall, Grimmelmann notes, was because there was no real such thing as being “off-government”. HavenCo’s perceived immunity was built on two premises: the first was that Sealand was its own sovereign state under international law, detached from British law. The second was that the Sealand royal family would continue to allow their actions and not seize control of the company. However, given the circumstances (Sealand being a small, remote island off the British shore with a population of about 20) and the nature of HavenCo’s operation (basically opposing every form of government imaginable), it was hard to imagine that either of these premises would hold for very long. And of course, they didn’t. Ironically, in 2002, two years after HavenCo’s inception, Sealand’s government nationalized the company after the technical and physical infrastructure began to crumble due to lack of funding, and then proceeded to make HavenCo abide by their own international rules and practices. So where were all the investors? Where were the Avi Freedmans and Joi Itos of the world, the Internet rights millionaires who backed HavenCo from the start? At its inception, I think that many people bought on to “MacroMaxx scenario”, as I will call it. They probably believed in the freedom to say, “"Gee, we don't have that [data] here"” and go about with their lives. Unfortunately, that’s not how government and legal battles always go about in real life, and sometimes just hiding your cyber footprint in some faraway server isn’t enough when the government can follow your physical ones and just show up at your door.

Grimmelmann’s paper that I reference can be found [here](http://poseidon01.ssrn.com/delivery.php?ID=568002118065023079070002127087002066118047006051032007118024119118017127026102069004017058006012005023096083086064119004007083055058054000080076087010124028024074048084016066124116015089018004114104026067030011118110088009011075099070119096079020082&EXT=pdf)

Mike Sun: 
Edit: A little off topic, but after reading over Erik’s (/u/estayton) response, I’m starting to wonder if Barlow’s view of cyberspace liberty is even a liberty in itself. The virtual “Social Contract” he speaks of seems to be a contract for those who share his view of what cyberspace “should be like”. As Erik mentions, cyberspace is not and never will be a place where "anyone, anywhere may express his or her beliefs", and those who claim this is what cyberspace is or should be can often be those who wish to use it to harass or threaten others. HavenCo provided its own service, allowing those who don’t mind government regulations on their cyber-activity to remain under those regulations, but Barlow seems to call for a complete overhaul of the system, advocating for a cyberspace that only supports his ideals and the ideals of those who think like him. What different is this from the government policies he seeks to fight?

Right -- as I also responded to /u/estayton, it's worth thinking about Barlow's audience here. One good move, when analyzing any persuasive speech, is to perk your ears up whenever anyone says "we" and ask who they think they "we" is and how that is shaping their own vision and the argument they're trying to make. 

Maria Temming: 
Oh man, in comparing HavenCo/EFF, I hadn't even considered the difference between Lackey/Barlow's visions for who should be totally detached from from traditional legal regimes--whether it should just be anyone who's willing to pay for that freedom, or everyone using the internet ever. That's such a good point. 

Peter Downs: 
**DQ6: Pick a Supreme Court case - past or present - that has to do with 'the Internet' and summarize what the arguments were, which theory of the Internet prevailed, what the court did, and what impact it's had.**

----

The Communications Decency Act (CDA) started out in 1994 as Senator Jim Exon's personal favor to an old friend, Tom Osborn, who found his children looking at porn on the internet. The general goal, as you might expect, was to limit access to such "indecent" and "patently offensive" material. ISPS, tech companies, the ACLU, the EFF, and other free-speech advocates like librarians (yes, really) immediately fought back – they believed that the internet should not be subjected to the regulations of older broadcast media like radio and television, but instead be treated as speech between individuals.

By the time it reached the Supreme Court, *Reno v. ACLU* had gone through several layers of lower courts. Immediately prior, a 3-judge district court found that two parts of the CDA – §223(a)(1)(B) as related to “indecent” communications and §223(d) – were overly broad (in violation of the First Amendment) and vague (in violation of the Fifth Amendment). So it reached the Supreme Court on appeal from the government, hoping to overturn the lower court's findings.

The question asked of the Supreme court was related just to two sections of the TCA: 223(a)(1)(b) and 223(d). Heard in Philadelphia, this case was the first time the internet was used in a court room (according to Daniel Weitzner, who worked with the EFF on the case). The case was largely decided by the facts of the situation:

* Once content is postend on the internet, it is ubiquitously available in every community.
* There is no effective way to determine the identity or age of any internet user.
* It would be impossible to block access to just "indecent" content.
* Because of its open nature, the Internet is an incredibly democratic technology.
* At that point in time, the internet was a still new and growing technology; strict regulations might hurt its adoption.
* The CDA (the two sections focused on by this court case) had been added on to the TCA through amendment, not through detailed congressional findings or hearings.
* Unlike obscenity, indency does not exclude works of serious literary, artistic, political, or scientific value.
    * Also, "indecency" has no legal definition.
    * Although "patently offensive" was defined in a legal context by *Miller v. California*, this act does not include the qualifiers that *Miller* includes to allow the publication of some "patently offensive" content with redeemable qualities.

The judges held in favor of the ACLU: the "indecent transmission" and "patently offensive display" provisions abridge "the freedom of speech" protected by the First Amendment. In essence, they agreed that the internet should not be regulated like traditional broadcast media – a critical ruling that allowed the internet to continue to grow rapidly. The decision focused on the internet's potential as a democratic medium, and on the overly broad terms of the CDA. In particular, the government did not show that more narrowly targeted regulations (like requiring content to be tagged as "porn" or "not porn") would not work as effectively. As held in *Sable Communications v. FCC*, regulation restricting free speech must be as narrowly tailored as possible to be effective.

As an interesting aside, the TCA also included another critically important change to the way the internet was regulated: exonerating ISPs from liability for the content they transferred. Just one year earlier, the judge's ruling in *Stratton Oakmont v. Prodigy Services* had held an ISP liable as the publisher of defamatory material. That ruling had hinged on the fact that Prodigy filtered some content on its message boards, so by allowing this defamatory material, the court reasoned that it had explicitly participated in its publishing. The TCA's section 230 addressed this exact issue by exempting intermediaries from such liability even when they make best-effort attempts to restrict illegal content. An interesting side effect of Section 230 is the widespread availability of open wi-fi access points – by offering access, you aren't accepting any liability for the behavior of people who use your network. This stands in contrast to Germany, where they have no such protections for intermediaries, and open wi-fi access points are nearly non-existent (although this is set to change as of this year.)


> An interesting side effect of Section 230 is the widespread availability of open wi-fi access points – by offering access, you aren't accepting any liability for the behavior of people who use your network. 

TIL! Nice history. 

Charles Bachmeier: 
DQ4: How did the founders of HavenCo conceptualize their relationship to traditional legal regimes? What did they see as the points of failure and/or opportunity? Compare their experience with the case of Yahoo! described by Goldsmith and Wu. How did traditional legal regimes reassert itself in each case? What changed?


By locating themselves in the legal grey area that is Sealand, the founders believed they could skirt around the laws of nations, creating a perfect data haven for companies. Traditional data havens still have to adhere to local jurisdictions, like the example in the article where Church of Scientology made the Finnish government raid the home of an anonymous remail service and get the name of the user who was posting Scientology documents. But on Sealand, HavenCo would not have to answer to such authorities, making that feature one of their key selling points/opportunities.


Although they are not completely free, to not face regulation from the nearby UK, HavenCo needs to stay under the radar. They need to be so isignificant that the British government won't desire to try and impose their laws. This will limit them as a "haven" as the founders have stated that they will maintain the right to not accept the business of a company wishing to enter in activities that would enrage local governments, such as the distribution of child pornography. 


Sealand itself also has some natural protection from being "invaded" as the only way to get up the pillars is by winch or by helicopter, discouraging a group angry with HavenCo's customer's activities from getting to their servers. Though if such an invasion were to occur the founders said they would burn and run Sealand keeping their customer's information safe but destroying their business in the process, which probably isn't the best self defense plan. 


Yahoo had a similar experience when a French Court demanded that they remove all Nazi propaganda and merchandise from their site as it is illegal to sell racist items in France. Even though Yahoo's site was located in the US, the French court stated that because French citizens could access it, Yahoo had to obey French laws. Yahoo originally held the same mentality that the founders of HavenCo had, which was that this foreign court couldn't control my website and they would just ignore the ruling. But Yahoo had assets in France that could be seized and wished to do business in France which would be difficult if one of the workers were arrested if they stepped foot on French soil. So Yahoo buckled and complied to France's wishes, which out them on a downward slope eventually leading them to censor more and more content to appease government, even becoming one of the major censors in China.


HavenCo has already stated that they would refuse business to particularly shady organizations, which could be the first step in leading HavenCo down the same slippery slope as Yahoo. But if the mentality of the founders stays the same and if they can maintain being only a nuisance that is too insignificant to cause governments to intervene, they could potentially stay a data haven. 


But by looking on the wiki it seems like infighting tore up the company.

Hi Charles - 

Infighting was part of it. Also, financial intermediaries basically refused to do business with them. I think this was at the end of the G&W reading, but per Jenn above, that seemed to be getting cut off for some people. 

Joel Gustafson: 
**DQ4: How did the founders of HavenCo conceptualize their relationship to traditional legal regimes? What did they see as the points of failure and/or opportunity? Compare their experience with the case of Yahoo! described by Goldsmith and Wu. How did traditional legal regimes reassert itself in each case? What changed?**

Reading Garfinkel and Goldsmith side-by-side highlights the cultural differences between Yahoo! and HavenCo. Yahoo! was Silicon Valley hotshot, born from the same culture that gave us Soylent. They were buoyed by hype and obsessed with their users, but as much as Jerry Yang seemed to want to disregard the French government, he ultimately answered to his investors and, indirectly, their governments (French or otherwise). Yang just wasn’t in a position to completely disregard their authority; his only hope was to establish friendly precedents from the relative inside.

This is in stark contrast to HavenCo, whose cypherpunk associations recall anarchy rather than capitalism. Lackey’s motives (despite his history in the gambling industry) seem to be more rooted in ideals than profits: he genuinely wanted to establish a Switzerland of cyberspace, outside both the political and abstract jurisdiction of nation-states (“abstract jurisdiction” here meaning something like scope, domain, or raison d'être). The grey markets, the gambling, the pornography, and the venture capital were, in Lackey’s eyes, just a means to a philoso-political end whose value was its uniqueness, not its money-making capacity. HavenCo was positioned to work outside the system in every way that Yahoo! was an insider: I’m surprised that Lackey styled HavenCo as a company in the first place instead of some cyber-prefixed term for an autonomous unit.

However, despite their positional differences, I think the biggest “change” between the cases is the relatively unexciting matter of size: France had to address Yahoo!, while the UK could afford to let Sealand be. It could well have been the case that if HavenCo grew to the size of 2001 Yahoo! the UK would have intervened, but so long as they stayed below the radar and didn’t make any waves, it wasn’t worth the trouble. Additionally, the UK seems to have been historically cautious when dealing with Sealand, guarding against it “blowing up” (their Sealand problem could only get worse) while in the other case it was the French government that had nothing to lose (their Yahoo! problem was already as bad as it could get).

Hi Joel - 

> he genuinely wanted to establish a Switzerland of cyberspace, 

interesting comparison. Why isn't Switzerland the Switzerland of cyberspace? Or is Switzerland even the Switzerland of ~*~meatspace~*~? 

>I’m surprised that Lackey styled HavenCo as a company in the first place instead of some cyber-prefixed term for an autonomous unit.

It was the 90s. I don't know if that makes it better or worse. 

> Additionally, the UK seems to have been historically cautious when dealing with Sealand, guarding against it “blowing up” (their Sealand problem could only get worse) while in the other case it was the French government that had nothing to lose (their Yahoo! problem was already as bad as it could get).

A smart, pragmatic point. 


Casie Chen: 
DQ4: How did the founders of HavenCo conceptualize their relationship to traditional legal regimes? What did they see as the points of failure and/or opportunity? Compare their experience with the case of Yahoo! described by Goldsmith and Wu. How did traditional legal regimes reassert itself in each case? What changed?

While HavenCo was repeatedly described as cyber-anarchist, and intentionally placed themselves outside of traditional legal regimes in order to maintain largely unmoderated traffic, the case of Yahoo! specifically seems to highlight an unintentional freedom granted by the laws surrounding Internet traffic. It's interesting, in my opinion, that in one case (Yahoo!'s), the argument appears to have been over the scope of French law, and reasonable or unreasonable expectations of its enforcement, but in the other (HavenCo), there are uses for equipment that are explicitly disallowed by HavenCo, such as child pornography, even though child pornography might be legal in some countries (childhood is not a well defined bound - however, the most prominent example that comes to mind for me is that Japan's age of consent is 13). It seems to me that HavenCo preempted outrage from a set of nations numerous and/or sizable *enough* and for whom this would be legally reprehensible *enough* to enforce consequences to the company, which seems an interesting way to highlight societal values. 

As an aside, both of these companies scream of the legally-flippant Silicon Valley startup culture. Yahoo just had the size and manpower to be more loud and explicit about not moderating their traffic in an established (sorry, Sealand) government setting. 

I'm not sure I've sufficiently outlined my thoughts, but in summary, it feels to me like even though HavenCo was built on an aggressive business model of pseudo-anarchy, Yahoo! has actually taken that attitude much farther by establishing greater "freedoms" in an established court rather than simply imposing a smaller set of rules than is usual, as HavenCo did.

Hi Casie - 

> It seems to me that HavenCo preempted outrage from a set of nations numerous and/or sizable enough and for whom this would be legally reprehensible enough to enforce consequences to the company, which seems an interesting way to highlight societal values.

I agree; the story, at least so far as I know it, is basically that HavenCo sought out the lowest-common-denominator set of international legal customs to avoid abrogating as a risk-management strategy. Although it's not clear that it worked. 

> Yahoo! has actually taken that attitude much farther by establishing greater "freedoms" in an established court 

Or advocating for them (unsuccessfully), at least. 



Nick Gomez: 
DQ6 - Quill Corp. v. North Dakota

Quill Corp v. North Dakota was a supreme-court case whose decision established that a business must have a physical presence in a state for that state to be able to require the  business to collect sales taxes for that state. The original situation had nothing to do with the internet; it was 1992 and Quill Corp was selling office supplies via computer software which customers in North Dakota used to order supplies directly, an early mirror of what would become known as ecommerce. North Dakota attempted to argue that the floppy disks that contained the software established a physical presence in North Dakota, enough to create a “substantial nexus” between the state and the customer. Under “Complete Auto Transit, Inc v. Brady,” which dealt with a General Motors vehicle transporter that used Mississippi interstates, that physical presence would have been enough to allow North Dakota to levy taxes on Quill Corp. The supreme court held that that the “Complete Auto Transit, Inc v. Brady” did not nullify the “National Bellas Hess, Inc. v. Depart. of Revenue of Illinois,” which had established that a seller whose only connection with the state is mail cannot be forced to collect taxes, and that the floppy disks were not enough to justify the presence of a “substantial nexus”.

This supreme-court case is especially interested because the effects it had expanded to exponential magnitudes beyond what the supreme court could have foreseen, and while not directly having anything to do with “the internet” at the time, set the precedent for ecommerce. It has allowed online businesses to not charge sales tax in states in which they don’t have a physical presence, giving them an inherent competitive advantage over brick-and-mortar stores which do have to collect sales tax on every item sold. For example, electronics stores like Adorama, B&H, and BuyDig are all based in New York and therefore they don’t collect sales tax on any of their products when bought anywhere but New York. For this reason, these online sellers have become very popular not because of their customer service or other positive attributes, but also due to their lower prices post-tax, especially for big-ticket items. This supreme court ruling has allowed these online stores to flourish while brick-and-mortar stores continue to struggle. Additionally, this means that state governments have a huge decline in the sales tax they collect, causing many political after-effects and rigorous debate about whether the lack of online sales tax is “fair” towards the states and local commerce. This case also serves to show how laws and court decisions that predated the popularization of the internet can have large effects on how the internet works.

Hi /u/nickgofly - 

Interesting example! And you're right, of course, for the immediate decades following 1992. However, I observe that I am now charged MA sales tax for things I buy on Amazon. What do you think changed? 

Nick Gomez: 
I experienced the same thing in Florida. Amazon has a warehouse/office in MA, I think Amazon has been forced to start paying taxes in states in which it has warehouses, which falls inline with the Supreme Court decision. I forgot to mention that in Quill Corp vs. ND, the court said congress still has the power to instill regulations to regulate online sales tax, so theoretically congress can change how sales taxes work online if they wanted to.

Julia Guo: 
**DQ4: How did the founders of HavenCo conceptualize their relationship to traditional legal regimes? What did they see as the points of failure and/or opportunity? Compare their experience with the case of Yahoo! described by Goldsmith and Wu. How did traditional legal regimes reassert itself in each case? What changed?**

From the beginning, the founders of HavenCo envisioned their startup to stand defiant against traditional legal regimes. HavenCo’s main advantage and foundation of opportunity comes from its geographical location -- intentionally offshore in the land of Sealand, about six miles off the English coast, technically declared independent from the UK. The founders used this aspect to form the basic premise of HavenCo: its physical location and constraints allow it to stand in a legal gray zone, a gray zone the founders interpret to mean that rather than having an ambiguous set of laws and rules, HavenCo instead could offer complete evasion from almost all legal rules and restrictions (besides what they consider to be too-risky flagrant wrongdoings that put their entire operation in danger). Lackey, one of the founders, even states that the general idea is “to allow a little naughtiness,” or in other words, giving its clients a physical and geographical shelter and leeway from the traditional forms of legal policing, such as lawyers and government snoops that usually cause headaches when trying to run sketchy-but-not-explicitly-harmful operations like anonymous, untraceable payment systems and adult-only pornography. Another point of opportunity for HavenCo was its physical protection from the attacks of the outside world, in a very literal sense. Their argument was that their clients’ data was securely protected because HavenCo would stand tall against all opposing forces and attackers demanding data, even going so far as to literally “power off the machine, optionally destroy it, [and] possibly turn over the smoking wreck to the attacker.” However, HavenCo as an experiment ended up failing for two main reasons. First, its rise and downfall was based on its belief that it could essentially operate in a vacuum without having to cooperate with the regulations and desires of the rest of the world. However, this led to a lack of intermediaries (especially financial support from places such as banks and credit card companies) which destroyed the ultimate link to the customer. Second, ironically the ruler of Sealand began imposing his own restrictions on the startup as he wanted Sealand to receive legitimacy and recognition as an actual country, which was at odds with the “offensive” and evasive operations of HavenCo.

The case with Yahoo is a little different. First off, Yahoo didn’t set off explicitly trying to defy any set of traditional legal regimes, unlike the case with HavenCo. Also, Yahoo was an established, well-known Internet giant, acting as the largest Internet entrance point for users compared to other websites. When the French court case arose suing Yahoo for its Nazi-related web pages violating French law, however, Yahoo was steadfast in its stance not to censor any of its content, with the same “sovereign Internet” mentality and attitude as the founders of HavenCo. If national governments could control content on the Internet, the future of the sovereign Internet looked grim. With the philosophical slippery slope argument combined with the practical argument that geographically censoring content was impossible to fully implement, Yahoo at first seemed to stand strong. Yet, the “impossibility” defense was weak in that it didn’t demonstrate what was actually troubling about the French government’s request (the slippery slope of censorship on the web) and instead shifted the focus to a less idealistic point. One could argue from the other side that even though it may be impossible to stop all cases of a criminal activity, laws are still needed. Similarly, just as how Yahoo might not be able to properly filter every single user, it could still screen out most of them to follow French law, which is exactly what the court ordered. Over time, Yahoo’s stance started to weaken and contradict itself as the company began complying to other national governments’ censorship requests. Yahoo’s large celebrity status meant that it was also subjected to many business ties and external pressures, such as assets at risk in other countries and the competition from Google. In the end, Yahoo was caught in a balancing act of trying to please and sustain as much business as possible while standing true to its original principles, and it fell short in the process.

Hi /u/julesjoulez - 

I have nothing to add; this is a pretty good summary response! 

Kyle Saleeby: 
DQ6: Pick a Supreme Court case - past or present - that has to do with 'the Internet' and summarize what the arguments were, which theory of the Internet prevailed, what the court did, and what impact it's had.

The Seriously Trifling Nature of the Internet

*“Don't believe anything you read on the net. 
Except this. 
Well, including this, I suppose.” 
– Douglas Adams*

If the internet and all inside were to be rolled into one gigantic bale of hay from which a thinly sliced cross-section would be examined and averaged, what would a litmus test of seriousness and frivolousness show?

Douglas Adams not only gave readers a way to approach the internet with his cheeky quote, but he also captured and framed a surprisingly important question that permeates every form of communication. The question is simple in phrase, but deep in consequence. “How seriously should we take the internet?”

One might nonchalantly fire back that the internet and everything in it is to be taken seriously (except Wikipedia, of course) and that one should browse with a critical eye. A more careful answer might include that everything in the internet should be browsed in context while considering the environment, bias, and audience of any particular webpage. But even then, context is particularly hard to discern in a place where websites can be a digital and virtual expression of someone’s very real reality. How would we understand the context of a single (and maybe very quickly written) post given that we only see the expression, and not the events surrounding it? 

The internet frequently pits communication against purpose, leaving humor and harm to duke it out in the next round. The Supreme Court (SC) approached this question in *Elonis vs. United States* where Anthony Elonis was convicted under 18 U.S.C. 875 that makes it a federal crime to transmit in interstate commerce “any communication containing any threat… to injure the person of another.” Elonis had posted violent and graphic threats to multiple parties. He appealed to the SC on grounds that he did not intend to harm anyone with these posts, but rather posted them as rap lyrics. The SC ruled (very narrowly) that Elonis could not be convicted on the grounds of negligence in his posts. Although the ruling is limited to this case, my understanding of the ruling is that it is not enough to convict a user based on a post, but rather the intent of the post. Even though the SC issued a ruling for this case, the opinion left out what is in fact needed to convict a user. In essence, the SC made a ruling for this case, but left the larger question untouched. Legally, it remains up for debate how seriously the internet and its content should be taken.

A secondary Supreme Court case, *Spokeo, Inc. vs. Robins*, similarly dances on the question but leaves a more concrete and actionable item for internet users to cite. Spokeo, a website that aggregates user information, created an incorrect profile for Thomas Robins. Robins claimed that this incorrect profile had harmed him based on incorrect “fair and accurate credit reporting” as defined by the Fair Credit Reporting Act of 1970. 

The SC remanded the case back to the Ninth Circuit to reconsider both aspects of the injury-in-fact argument. In essence, the SC specified that the individual must show harm from the incorrect information posted online and that Robins’ harm was not fully examined in the previous court. The question of seriousness was more solidified by the fact that injury can occur as a result of the internet, but harm to an individual must be evident. 

In a way, the Supreme Court seems to be piecing together the seriousness of the internet and its content case by case. The SC does not seem eager to issue general or far reaching opinions in cases where they have had the opportunity, but rather to begin building case law literature one brick at a time. While this cautious approach is probably wise, it leaves a multitude of questions open to discussion. For example, the SC may be considering a case arguing net neutrality in the 2016-2017 term. It will be interesting to see if they continue issuing specific interpretations or if they adopt a more general opinion in the ruling.

How seriously we should take the internet is without doubt a significant beast to challenge. But while we consider a question that will without doubt permeate our use of the internet in the decades to come, it may be wise to act with Good morals in all that we do online, trusting that good intentions will prevent later harm. And then of course, to take things with a grain (or more) of salt. 

Sources: https://www.supremecourt.gov/opinions/15pdf/13-1339_f2q3.pdf
https://www.supremecourt.gov/opinions/14pdf/13-983_7l48.pdf
https://www.oyez.org/cases/2014/13-983
https://www.oyez.org/cases/2015/13-1339


Hi Kyle - 

Very interesting. I agree fully that SCOTUS is clearly moving cautiously on the question of how it regulates the Internet, with perhaps a general strategy, post _Reno_ at least, of avoiding the question until it becomes no longer worth asking except for trivial jurisdictional claims. 

But I'm not quite sure I understand what you mean by SCOTUS not taking the Internet 'seriously.' I mean, it's a great Adams quote, but a quip doesn't support a claim. Do you actually think that SCOTUS doesn't consider 'Internet' cases to have the same, like, ontological or moral weight as other kinds of cases?  If so, I think I need more convincing w/r/t that particular point. 

Christina Wang: 
DQ4: How did the founders of HavenCo conceptualize their relationship to traditional legal regimes? What did they see as the points of failure and/or opportunity? Compare their experience with the case of Yahoo! described by Goldsmith and Wu. How did traditional legal regimes reassert itself in each case? What changed?

The values and motivations of HavenCo were founded on the idea of a free internet that was off-government, well-guarded, and powerful enough to attract the diverse business of many clients. However, within this framework, customers still had to abide by the laws set by HavenCo, which were still much less strict relative to laws and regulations of nation states and their governments. Such laws included banning uses for child pornography and drug money laundering, which implies that HavenCo drew a threshold for what they deem as universally moral, at least for as far as the bare minimum goes (which opens a whole other can of worms on morality within markets). By implementing these laws, HavenCo could ensure their customers that minimal meddling would take place as long as they abided by the basic rules. 

All of this, of course, was the vision of HavenCo. The reality was more complicated given that the company and all their servers were housed on Sealand, which soiled the idealistic goal of a (mostly) anti-government establishment once Michael Bates (Prince Michael..) became more involved after seeing the growth of HavenCo, and then everything got messy, especially as the UK government got involved. What was originally set out as good location precisely because of its lax ruling, Sealand became the downfall of HavenCo. 

In relation to Yahoo! and the French government, I agree with what Maria says above that while yes, the French government pulls in its reigns on the company, Yahoo’s original intentions were never anarchist by any means. However, by rejecting Yahoo!’s argument, which essentially sought freedom of speech, the French government enforced their stance that business done in their country must abide by their traditional legal regimes. Obviously, when compared to a place like Sealand, the France is a much more established government that holds greater power and authority on the business in their country, which ultimately has a direct influence on entities that strive for business models of lawlessness. 


Hi Christina - 

> However, within this framework, customers still had to abide by the laws set by HavenCo, which were still much less strict relative to laws and regulations of nation states and their governments.

Were these laws set by HavenCo, terms set by HavenCo, or laws set by Sealand? A bit technical, I know, but specificity is important, particularly when trying to untangle the really complex web of state and nonstate actors in this space. 

> pulls in its reigns on the company,

idiomatically "reins," like on a horse, FYI (unless you're making a metaphysical metaphor for exercising some right of kings, but I suspect you're not) 

> However, by rejecting Yahoo!’s argument, which essentially sought freedom of speech, 
> which ultimately has a direct influence on entities that strive for business models of lawlessness.

curious: do you think "freedom of speech" and "lawlessness" are the same thing? I read this last graf as conflating the two, analytically, which can be an interesting argument, but I'm wondering if it's the one you intend to make. Or do I misread you? 

Kenny (Kenneth) Friedman: 
**Standing DQ1: profile any of the authors: their academic training, key contributions and conversations in their field(s), basically who they are and why they matter: John Perry Barlow**

Steve Jobs, in 1996, said that one reason the original Mac was so great was that it was made by “musicians and poets and artists and zoologists and historians, who also happened to be the best computer scientists in the world”. 

Then in 2011, months before his death, Jobs said “Technology alone is not enough. It’s it’s technology married with liberal arts, married with the humanities, that yields us the results that make our heart sing.”

Looking back at the beginning of the technology revolution, it felt like technologists were working towards a grand vision of humanity, and that technology like computers and the internet would lead the world to a utopia. However, in my lifetime, that doesn’t feel nearly as true. I believe Job in his 1996 quote, but I’m less sure about his 2011 quote.

I don’t know the exact year that the split occurs, but I think people in the technology world can be grouped into two categories: the people who care about the humanities (and see technology as a new “artistic” medium that can enlighten the world) and the people who care about technology only for technology sake (who care more about the technology itself than how it shapes society). To me, if feels like there are an ever increasing number of people in the latter category, and a diminishing number in the former. Maybe it’s because there more people in technology now, maybe it’s because the humanities-focused leaders grew up in the 60s, or maybe it’s because they weren’t born into a world where computers and the internet already existed.

If there was ever a ideal example of the first category of people, it would be John Perry Barlow. 

Barlow co-founded the Electronic Frontier Foundation, and penned “A Declaration of the Independence of Cyberspace”. But if you were to read the first sentence of his Wikipedia article, you may think you’ve clicked the wrong link[1]. An American poet and essayist? It might seem like a far cry from technology — but it’s clear Barlow’s impact on technology comes from the humanities side, not the technical side.

At the start of his career, he graduated from College (Wesleyan) not as a programmer or an electrical engineer, but as a comparative religion major. And he went on to be a cattle rancher in Wyoming as well as a Grateful dead lyricist.

His network of friends is as diverse as his interests. He has been roommates (somehow, with a 32 year age difference), with Napster founder Sean Parker, double dated with John F. Kennedy Jr., and has been friends with Bob Weiner of the Grateful Dead since he was 15.

So his contributions to internet stem from principles, not breakthroughs. He sees the internet as a new location in the world (as he popularized the use of term “cyberspace” to continue the idea that the internet is a separate space). His manifesto was to meant to declare the internet a utopia that could not be interfered with by the old guard governments.

In the decades since he wrote it, the struggle and tension between the integration of the real and cyber world has continued, and he remains at the EFF: fighting for those same original ideals along with the other humanities-focused technologists. 

—
Personally, I believe he is right in the long run. Eventually the world will be fully digitally connected, and the concepts of current governments and geographic based divisions will go away. But I think he’s wrong in the short run. At least, the goals aren’t feasible in the short run. It’s impossible to decouple the internet from the world around us, and the general trend seems to be a melding of the two worlds, not a separate distinct place.

[0]: https://www.youtube.com/watch?v=sUCpuaqlISQ
[1]: https://en.wikipedia.org/wiki/John_Perry_Barlow
[2]: http://gawker.com/302715/john-perry-barlows-bacchanal-on-clayton-street

A response to SDQ1, as I live and breathe *fans self like a proper southern women.* 

I think you're on to something in the split between the two Jobs quotes inasmuch as the former imagines a unified poet/technologist and the latter splits the world into CP Snow's 'two cultures' of humanities & STEM (and never the twain shall meet). 

> Maybe it’s because there more people in technology now, maybe it’s because the humanities-focused leaders grew up in the 60s, or maybe it’s because they weren’t born into a world where computers and the internet already existed.

I think the canonical book here is: http://press.uchicago.edu/ucp/books/book/chicago/F/bo3773600.html, should you be interested in exploring this question further. 

> Eventually the world will be fully digitally connected, and the concepts of current governments and geographic based divisions will go away. 

Curious: why do you think that digital connection will undermine current governments/geographies, when other IT technologies (e.g., telephone / telegraph) didn't (indeed, if anything, arose simultaneously with the contemporary nation-state in its strongest and most discrete form)? 


Frankie Schembri: 
**SDQ1 + SDQ2ish: Profiling John Perry Barlow + A Declaration of the Independence of Cyberspace**

As an aspiring writer, one of the most fascinating characters, in my opinion, mentioned in this week’s readings is John Perry Barlow, the retired cattle rancher and former Grateful Dead lyricist whose writings helped shape the public discourse around the Internet in the early 1990s and have taken on a new life since then. 
I’ve always been fascinated by Gonzo journalism, the type of reporting that does not make claims of objectivity and instead uses first-person narrative from the author as a key component of its structure, popularized by Hunter S. Thompson in the 1970s, or, even earlier, the New Journalism of the 1960s which prioritized “truth” over “facts.” However, it is my belief that when objectivity in journalism is sidelined in favor of accurately reporting on individual experience with all its feelings, biases, and personality, transparency becomes the most important tenant of journalistic integrity. Transparency must often be sought out by the reader, as is the case with John Perry Barlow.
Barlow’s writings for Wired magazine, among other publications, in the early 1990s revealed the mysteries of the Internet to average reader, and are credited with popularizing the notion of “cyberspace,” a virtual universe beyond the realm of real-space. Barlow’s writings were arguably so successful at communicating the possibilities afforded by the Internet because they were written as a user, not an engineer or computer scientists. Barlow stumbled upon the Internet in 1986 when he joined the WELL online community in search of other Deadheads. As a result, his writings on the Internet are based on his experience as a user, and are inherently colored by his values, experiences, and biases in exploring cyberspace. 
This brings up an interesting point about whether or not reporting on the culture and operations Internet from an user perspective can ever be an objective endeavor (or as close to objectivity as a human journalist can get), or whether it will always be Gonzo journalism simply because the action of using the Internet is an experience affected by one’s identity. 
Regardless, Barlow did not purport to be an objective observer of the Internet, in fact he went in the opposite direction and crossed quickly into advocacy journalism, as well as pure advocacy when he founded the Electronic Frontier Foundation (EFF) in 1990, a group designed to media issues between cyberspace and the physical world. 
In 1996, following the U.S. government’s passing of the Communications Decency Act, which punished all transmission of indecent sexual communication or images over the Internet in ways that could be available to those younger than 18 years of age, Barlow published a 16-paragraph manifesto titled “A Declaration of the Independence of Cyberspace.” 
The document states that the United States did not have the consent of the governed to apply laws to the Internet, and that the Internet was outside any country's borders. Instead, the Internet was developing its own social contracts to determine how to handle its problems. 
In writing this manifesto, Barlow was not purporting be a journalist, but his background as a reporter did color the way in which individuals responded to the document at the time and in later years. [A recent Wired article](https://www.wired.com/2016/02/its-been-20-years-since-this-man-declared-cyberspace-independence/) describes how the document has been referenced over the last 20 years as a rhetorical punching bag for those discussing the merits of Internet regulation.
Much as it is inaccurate and irresponsible to read “A Declaration” as if Barlow were an objective journalist instead of an impassioned advocate, it is also inaccurate to read the document without putting it into the context of its moment in the history of the Internet. Barlow was writing in a period of technological utopianism, where the possibilities of the Internet, as well as its relationship with real-space, were viewed in a largely positive light and were believed to hold the key to a better world. The threat of regulation from such a powerful body as the U.S. government worried and angered techno-libertarians such as Barlow, as the implications of such regulation were also widely unknown. “A Declaration,” therefore, is a product of an emotional, uncertain moment in one man’s life, while reflecting the feelings of many other users, and should be read as an artifact of its time and place. This is not to say it does not hold some truths about the difficulty of regulating the Internet and the Internet’s inherently multinational nature, just that it does not seem like an appropriate punching bag for those advocating today for more government regulation of the Internet.
I also find it particularly interesting how seamlessly Barlow blends American folklore with the Internet narrative, from his Frontier imagery of exploring cyberspace to his allusions to the “Declaration of Independence” in his “A Declaration.” This makes me wonder about how users insert their national narrative into the Internet and vice versa. Has the American narrative shaped the Internet more than the Internet has shaped the American narrative (at least in the 21st century)? 

Hi Frankie - 

> Barlow’s writings were arguably so successful at communicating the possibilities afforded by the Internet because they were written as a user, not an engineer or computer scientists.

Interesting point given our discussion of standpoint feminism / situated knowledges last week! 

>  Much as it is inaccurate and irresponsible to read “A Declaration” as if Barlow were an objective journalist instead of an impassioned advocate,

indeed, since I don't think he wrote it as a journalist! 

> Has the American narrative shaped the Internet more than the Internet has shaped the American narrative (at least in the 21st century)?

Good observation. Worth thinking about how the Internet is made sense of in other cultures with other folklores and fables. One good criticism of this course, btw, is it has a very American-centric view on the Internet. One paper idea to consider: correcting that! 

Sharlene Chiu: 
The authors and figures mentioned in the readings can be categorized into two groups. Early users of the Internet commonly believed that cyberspace was a separate realm from the physical world, and thus couldn’t be regulated by any government that presided in the physical world. Supporters of this belief envisioned a future in which individuals could participate in communities without authoritative interference. In particular, Barlow imagined a “civilization of the Mind” into which people may enter “without privilege or… station of birth.” Dibbell’s account of the Mr. Bungle incident seemed to reinforce the idea that the cyberspace could govern itself. And even if a government found the Internet to be a problem, incomplete understandings of the Internet implied that regulating online for each user was impossible to achieve, as initially believed by Yahoo’s first leaders.

Internationalists, by contrast, deviated from the vision of the Internet as a separate world and untouchable world. They anticipated that national governments would be pressured to cooperate with each other in response to the Internet’s ability to cut through borders to connect people, content, and ideas. The Internet would reshape government, rather than the other way around.

Eventually, governments realized they could indirectly regulate online content outside its jurisdiction, i.e. foreign content, by regulating local intermediaries such as ISPs. The ability to identify and act upon users based on geographical location allowed governments to influence the flow of online information. Today’s Internet is no longer a separate realm, but rather an extension of the physical world through which local laws still hold.

The ideal of an interconnected community is undermined by government censorship and, less explicitly, information silos through self-selected membership and social media’s content filtering algorithms. National governments have the power to block undesirable websites and search results, which is difficult for individuals to combat. Users tend to view ideologically similar content and gravitate toward likeminded communities, thus hindering one from interacting with people who hold opposing beliefs.

At first glance, censorship is obviously a loss, but one could argue it also encourages people to question what is morally right or wrong, if anything is. This parallels the reasoning to Joichi Ito’s belief that HavenCo would pressure governments to better analyze their stances on the regulation of commerce and the Internet. A government must first decide something is morally wrong before deciding to censor it. Unfortunately, one cannot argue the morality of content if those arguments are also being censored by the government. At lower levels, however, such as moderating YouTube comments or Facebook newsfeeds, arguments over censored content can better refine one’s idea of what is acceptable to share. If censorship was forbidden, then arguments over inappropriate or dangerous content would be useless, since one could not act upon conclusions of those arguments.

In terms of interconnectedness within online communities, I argue that government regulations haven’t really changed how online communities interact. Barlow claimed that original anonymous, online communities allowed members to redefine their own backgrounds and identities. He viewed this property of the Internet as a gain, as one could not be excluded from interactions based on morally irrelevant traits. 

However, I argue that complete anonymity dehumanizes other members of a community and allows users to detach themselves from relevant problems. Members of early online communities could feel connected through the sharing of ideas, but sharing personal issues required a user to peel off a layer of anonymity. A “civilization of the Mind” can’t be treated separately from civilizations of physical bodies, as ideas, however fluid, will still depend on physical factors beyond one’s control. 

Hi Sharlene -- 

Interesting: I don't think I've seen the 'internationalist'/JPB framing before to delineate those views. 

> Internet is no longer a separate realm,

was it ever? 

>Barlow claimed that original anonymous, online communities allowed members to redefine their own backgrounds and identities.
> complete anonymity dehumanizes other members of a community and allows users to detach themselves from relevant problems. 

What do you mean by 'completely anonymous' in this context? It seems to me that Barlow and Dibbell are arguing for something closer to pseudonymity, which is pretty different. 

Daniela Morin: 
SDQ1: profile any of the authors: their academic training, key contributions and conversations in their field(s), basically who they are and why they matter

John Perry Barlow, who by the way bares a strong resemblance to Robert Reich, is the author of  the manifesto" A declaration of the independence of cyberspace" and co founder of the Electronic frontier Foundation. The work is a written statement publicly declaring the intentions and views Barlow held toward cyberspace and government interference.  The EFF is "is the leading nonprofit organization defending civil liberties in the digital world. The organization proclaims to  champion user privacy, free expression, and innovation through "impact litigation, policy analysis, grassroots activism, and technology development. We work to ensure that rights and freedoms are enhanced and protected as our use of technology grows. Hew was a fellow at Harvard's Law School's berkham Center for internet and society. Barlow Was born in in Wyoming in 1947 and later attended Wesleyan University in Connecticut with an Honors degree in Comparative religion in 1969. In 1990 he along with Mitchell Kapor, an entrepreneur and tech.philanthropist, formed the EFF, for promoting the freedom of expression in digital media. Barlow popularized the term cyberspace that prior to this was only a science fiction oddity, but came to represent a tangible space in the mind of masses via pop culture. As a result of his controversial manifesto he came to be regarded as "the Thomas Jefferson of Cyberspace" by a Yahoo magazine, upon the works publication in 1996. He has other notable works such as " The Economy of Ideas" which is highly regarded and taught nationwide in academic spheres. He is a consultant for major corporations, is a public speaker and writer as well. His area of expertise are centered around "information economics, digitized intellectual goods, cyber liberties, virtual community, electronic cash, cryptography policy, privacy" and the social, cultural, and legal conditions forming in Cyberspace. I believe that the work generated discussion of the implication of cyber regulation and security, but may have also been scrutinized for its idealistic and perhaps naive dystopian interpretation of government imposition upon internet use and practices. Perhaps a more practical analysis of the real world scenarios and processes that occur in mundane life would have rooted the work in a more agreeable light. Barlow makes the argument that governments around the world are attempting to stifle internet communication in an unjust manner "without the consent of the governed" and thsi should not be allowed since "cyberspace" exists on a new different almost elevated realm of its own with out borders or restrictions. This utopian view can be perceived as simplistic and uncritical of the realities concerning  jurisdiction of the government and other influential entities and financial forces equipped with the socioeconomic capabilities, to subject internet usage and data structures to restraint and modification in the interest of the government that must ensure the well being and function of the public. Barlow's work definitely created a sense of urgency and raised awareness of the power of autonomy and subservience in cyberspace, but paradoxically also revealed that, pragmatically speaking, it is easier declared than done.

Hi Dani - 

> by the way bares a strong resemblance to Robert Reich

FYI: the idiom is 'bears,' as a synonym for 'carries,' unless you mean, when he is bare (as in naked), he resembles Robert Reich, who presumably is also naked, but at this point, I think we're in a crypto-Sandernista dreamscape and not the conventional reality we mostly agree to live in. 

More substantively: I think you've got basically an accurate historical read on who JPB was and his contributions to this debate, including how he himself may be basically a punching bag at this point. 

Daniela Morin: 
Yes, I realized my spelling error after I hit submit, sorry about that, but thank you for your response. 

No worries - just joking :) 

Jonathan Sun: 
**DQ5: Consider the contrasting visions of what the Internet could/should be held by the authors of these texts, as well as the authors (e.g. John Paul Stevens on the Supreme Court) within the text. How have these different ideas of how / if the Internet should be regulated changed over time? What has been gained/lost by that change? Are there ways that the Internet still resists traditional legality? Be specific.**

*"Because the Internet is a global network of voluntarily interconnected networks, there is no organization that can force it to adopt a new standard or technical protocol." - McLaughlin & Zuckerman, 2003*

I’ve found it incredibly enlightening to read about the views and opinions on the internet from just over a decade ago – what amounts to millennia in “internet time”. The internet has evolved so much, and in my opinion, what is most notable to the internet of now and the internet of then is the prevalence of social media platforms – privately owned and operated, as a staple of everyday life for the general public.
What characterizes these earlier opinions of the internet is the insistence or declaration that the internet should be independent and free from government regulation. Indeed, Barlow’s “Declaration” (1996) explicitly states this, and Lackey’s Sealand (2000) also holds this belief. Even in McLaughlin & Zuckerman’s “Internet Architecture”, a more neutral document, holds firm this belief that there is *“there is no organization that can force it to adopt a new standard or technical protocol”.* 

I find these so interesting because to me, today in 2016, this is the commonly accepted norm – that the internet is not regulated. However, the difference to me is not that the internet should not be controlled, but that it cannot be controlled.

While these earlier documents and beliefs fight for independence, I think what we see now is that the internet is too big, too wild, too unwieldy, too murky, to be properly regulated by any government body. Instead, we are regulated by the platforms themselves. It seems that the common behavior of internet policy is – outside of the obviously illegal, which all platforms must be responsible for – what is deemed right or wrong is determined by each platform, of its own will, applied only to its own users. That means that (examples from within the last few months):

* Facebook decrees what can or cannot be posted on Facebook (see: http://www.nytimes.com/2016/09/10/technology/facebook-vietnam-war-photo-nudity.html)
* Youtube (or rather, its advertisers) control their own content (see: http://variety.com/2016/digital/opinion/youtube-ad-policy-censorship-1201851198/)
* Twitter decides what counts as abuse and harassment on its own platform (see: https://www.buzzfeed.com/charliewarzel/twitter-just-permanently-suspended-conservative-writer-milo; and https://www.washingtonpost.com/news/the-intersect/wp/2016/07/21/what-it-takes-to-get-banned-from-twitter/)
* Instagram allows users to filter their own photos’ comments sections (see: https://www.washingtonpost.com/news/the-switch/wp/2016/09/12/instagram-rolls-out-its-comment-filter-to-everyone/) while still universally regulating photo content (see: #freethenipple)
* Even NPR chooses to shut down its comments section across their entire site (see: http://www.npr.org/sections/ombudsman/2016/08/17/489516952/npr-website-to-get-rid-of-comments)

I believe what we are seeing is a move away from a government regulated internet – as predicted or declared by early internet voices – but towards a more insidious system: a privately-regulated, platform-regulated internet. What this means is that there is no universal regulation, and if this regulation is not in the hands of established government, it is less transparent, and functions for the good of the platform, not necessarily for its peoples.

This is clear with the Elison legal case. I looked up the ruling, and the result of the case was that the court ruled in Elison’s favor, essentially stating that threatening content cannot be deemed legally actionable without *intent* to threaten (see: www.nytimes.com/2015/06/02/us/supreme-court-rules-in-anthony-elonis-online-threats-case.html). Although perceived as threatening, because Elison did not display the intent to actually cause harm, the court was unable to deem the content as actionable threat. 

Above all else, within the longer narrative of all these readings, I see this as a shift: from the internet wanting to declare itself free from any government, to governments wanting to declare themselves free from the internet. With the Elison case, the court's ruling basically leaves the decision of what constitutes harassment or abuse to the hands of the platforms themselves, leaving us with, ultimately, a more splintered, less transparent regulation of the online world.


Hi Jonny -- 

> I believe what we are seeing is a move away from a government regulated internet – as predicted or declared by early internet voices – but towards a more insidious system: a privately-regulated, platform-regulated internet. 

it's a good point, and one that a lot of people in this community (i.e., BKC, EFF, etc) have been struggling against for a long time. We have a lot of well-developed concepts, policies, institutions, and norms for peacefully and productively interacting with state actors, but non-state actors, particularly those so entrenched in state-like activities (authorizing identities, constituting publics, etc) are not amenable to these. I read one provocative form of your conclusion as basically being that JPB was right, but for the wrong reasons: 'free people' didn't win, but terrestrial governments lost (or are losing), because corporations, in the avatar of their platforms, are achieving statelike power in their own right. 

Erica Yuen: 
**DQ4: How did the founders of HavenCo conceptualize their relationship to traditional legal regimes? What did they see as the points of failure and/or opportunity? Compare their experience with the case of Yahoo! described by Goldsmith and Wu. How did traditional legal regimes reassert itself in each case? What changed?**

	
With any new technology, there is always a question of its boundaries regarding ethics. New technologies transcend the infrastructures that are already in place, which causes conflicts of interest. In 2000, both HavenCo and Yahoo! take advantage of the ambiguity of legal infrastructures regarding the Internet and the information it delivers. Both were pushing for more freedom in content delivery, but Yahoo! believed that governments had no technological or legal control of what kind of information could be delivered to its citizens, while HavenCo recognized that there were already legal boundaries regarding the Internet and was attempting to bypass these boundaries. 

HavenCo’s main premise in locating itself in Sealand was so that it could be “untouchable” in the eyes of traditional legal regimes, since its legal system was technically independent of those of other nations. HavenCo’s vision was to create a world in which people could use the Internet an anonymous, untraceable way to create operations that were possibly not allowed in their respective nations. HavenCo’s founders believed that the fact that they were both legally isolated and physically isolated from other nations gave it the power utilize a loophole in the ambiguous laws of the Internet. It’s geographical isolation would supposedly prevent civil suits from discovering evidence, and it’s legal isolation would make it easy for clients to do whatever they wanted, as long as it followed Sealand’s relatively lax code of ethics. 
	
While on paper legally, it appeared that HavenCo was very hard to take down, Sealand’s independence was also a point of weakness for the startup. While it had the freedom to do almost whatever it wanted legally, Sealand did not have any strong allies. With its business mission consisting of promoting operations that were deemed problematic or unethical in many other nations, all more powerful than Sealand, what was stopping those nations from ganging up and destroying Sealand and everything related to HavenCo? For a business that has such a large emphasis on security and cryptography, Sealand’s security appears to be questionable, as its passports could be duplicated easily. Its founders also argued that Sealand was safe from most natural disasters, but with its tiny size and security consisting of inconvenience and a few armed men, it seems like an enraged, powerful country could simply just nuke it and destroy everything it promised to keep safe.  Furthermore, such a small team working on such a risky business requires complete cooperation, and any major disagreements would be disastrous for the venture. Finally, its physical infrastructure is unfit for the transportation and development for the expensive computer hardware needed. HavenCo mostly avoided traditional legal regimes with its independence, but it had many other weaknesses.

On the other hand, in the case of LICRA vs. Yahoo!, the French government took direct action against Yahoo!, and Yahoo! depended on the traditional legal regime of the United States’ freedom of speech and information to protect its contents. Since Yahoo!’s contents were legal in the United States, and since contents of the Internet were not be easily restricted at the time, Yahoo! argued that by a general rule of the Internet, the content could not be restricted from France. Unlike HavenCo, Yahoo! could base its arguments off of an established legal system. 
	
As the Internet continues to develop, it will continually face legal debates as it crosses ambiguous lines of ethics and questions the power of the government in controlling and accessing the contents. Examples of current issues include violating privacy for the sake of counteracting terrorism and restricting content in order to maintain copyright laws. 


Hi Erica - 

>  HavenCo’s founders believed that the fact that they were both legally isolated and physically isolated from other nations gave it the power utilize a loophole in the ambiguous laws of the Internet. It’s geographical isolation would supposedly prevent civil suits from discovering evidence, and it’s legal isolation would make it easy for clients to do whatever they wanted, as long as it followed Sealand’s relatively lax code of ethics.

I think you've made an important point as well or better than anyone: that, far from Sealand being the conceit of a 'cyber' nation, it was from the beginning imagined as a place where its geographic aspects (i.e., position in sea) was part of the plan and appeal. It's an important observation missed in many of the simpler retrospective dismissals of the vision. 




Maria Temming: 
**SDQ3: “How do the self-tracking apps that Eveleth discusses fit into Winner’s framework for thinking about the political properties of technologies?”**

Winner delineates two ways that technologies can have political qualities. In one case, a technology’s design serves as “a way of settling an issue in a particular community” (123). Here, the technology has a built-in propensity to produce a particular social outcome, like Moses’s anti-bus bridges. The second class comprises “inherently political technologies,” which seem to require (or at least be compatible with) particular social/political structures (128). These technologies need political/social climates to work like a car needs wheels to run—not because of any logical imperative, but for practicality’s sake. For example, Plato pointed out that sailors must adhere to a strict hierarchy because a ship only has one wheel. 

So, where do self-tracking apps that exclude women fit into all this? We can probably say these apps aren’t in Winner’s latter class of technologies because inherently political devices have intractable features that link them unavoidably to particular patterns of power/authority. Applied to Eveleth’s piece, this would mean self-tracking apps, by their very nature, favor men. On the contrary, self-tracking apps would seem most compatible with systems that favor women, who—at least in Western society—appear to have more reason to self-track than men. At the very least, Eveleth says these apps lend themselves to some “element of democratization,” because “there is no universal set of variables that would be meaningful…for everyone to track.” Self-tracking apps might not need feminism like a car needs wheels, but catering to women’s needs is at least compatible with the purpose of the app (to be as popular as possible).

Moreover, Winner says the tech in his first category could have slightly different features and produce vastly different social outcomes. In the same way, equipped with features to accommodate women (i.e., menstrual tracking), self-tracking apps would embody feminist, rather than patriarchal values. Thus, Winner would probably classify self-tracking apps among “technical arrangements as forms of order” (123).  

Winner further sorts this first category of technologies according to the intent behind their design. Is the tech purposely crafted to oppress a certain group (à la McCormick’s molding machines)? Or is the technology oppressive merely because surrounding social structures neglect a minority’s needs (i.e., infrastructure unsuited to handicapped people that went largely unnoticed until the 1970s)? Self-tracking apps don’t appear to fit either category. On the one hand, as Lupton says, “None of this is malicious.” On the other hand, feminism has been prominent in Western society long enough that we probably can’t excuse self-tracking apps that exclude women as products of unawareness. 

Instead, self-tracking apps that favor men probably fall into the gray area Winner alludes to at the bottom of pg. 25. In these cases, technical development is so skewed in one direction that it “produces results counted as wonderful breakthroughs by some…and crushing setbacks by others” (125). Eveleth’s article demonstrates that the process of app development is biased toward men. A “parade of men marched across the stage” in the first sentence, and all the named Apple execs are male. This gender disparity produces results counted as breakthroughs by men (“Monitor all of the metrics that you’re most interested in,” boasts Federighi) but setbacks by women (Erin Boesel claims there’s “little-to-no emphasis on women’s issues” in self-tracking). 

Similar to the tomato harvester that Winner puts in this category, there’s probably no St.-Augustine-esque plot afoot when it comes to self-tracking apps that don’t permit menstrual monitoring. Rather, “The technological deck has [simply] been stacked long in advance to favor certain social interest” (125-6). In a world where everything from phones to artificial hearts are tailor-made to fit men’s bodies, this seems the most reasonable explanation for non-female-friendly self-tracking apps. Lupton summarizes it nicely in her statement: “The designers, who are mostly men are…just taking up norms and assumptions that are embedded in our society.”

**Tl;dr**: Winner would probably categorize self-tracking apps that exclude women as “technical arrangements as forms of order,” and say their consequences “transcend the simple categories of ‘intended’ and ‘unintended’” (123, 125). 


Thanks for this thoughtful response to an original question, Maria! I too highlighted the deck-stacking line in Winner while thinking about these two pieces, and my guess is both Winner and Evelyth would agree with your tl;dr. 

Miao Xu: 
DQ4: Why/how does Evelyth think self-tracking apps exclude women? What design methodologies or strategic approached would you use to be less exclusive?

In the passage “How Self-Tracking Apps Exclude Women”, Evelyth raised the example of Apple’s Health app to illustrate how those self-tracking apps exclude female. The app Apple Health which was released in 2014 was described by its designers to be a “comprehensive” app in tracking its users’ information. However, many tech writers as well as Evelyth himself soon found it ridiculous, since such a so-called “ comprehensive” tracking app even cannot track menstruation, which has long been regarded as one of the earliest types of quantified-self tracking.

Apart from the lack of function in tracking menstruation, another embodiment of self-tracking apps’ excluding women is that many apps which are guessed be used by equal number of women and men are actually men-centered, such as many sex-tracking apps on the market. It seems that this kind of apps apply to both women and men, however, after a closer observation, it is easy to find that many of the metrics employed in these apps are designed from the perspective of men.

These are both obvious examples of gender bias in self-tracking apps. Some internal design may be even harder to be noticed. For example, said by Evelyth, “ Drop-down menus show ‘male’ over ‘female’ even when the rest of the menus are alphabetical.” This kind of bias in the designing of infrastructure is normally much obscurer than the lack of function.

Then how could such a disappointing situation be improved? I think there are such three following suggestions.

First, tracing back to the root of this problem, more females should be staffed in the tech companies. Evelyth has clearly pointed out in his passage that “ The vast majority of tech companies are staffed by men, especially on the development side.” However, a design or idea is normally generated on the basis of one’s own experience. Then how could those male designers know clearly about what on earth the women need? So, the fundamental method of solving this problem is to put more women in the designing position. Only by doing so, can they put forward some ideas that benefit themselves more.

However, in spite of the effort to put more women in the development post, it is true that female staff are still the minority owing to many social reasons. Thus, by merely enrolling more female staff is far away from enough. Another way to reduce gender bias is to enlarge the proportion of women in testers. After testing original versions of self-tracking apps in a group where women are the majority, feedback may be more helpful than just testing them in a randomly selected group.

Moreover, in the passage, Evelyth has also posed another problem which obstructs women in owning their self-tracking apps, and this problem was encountered by Ida Tin. It is that the male investors are usually unwilling to invest in female apps. This is because they don’t understand such product and they tend not to invest in products they can’t try themselves. ( from this passage) Thus, in order to solve the problem, I suggest a specific fund should be set up separately for female investment. By doing so, women designers can get rid of the situationin which they have to depend on male investors. 

All the above is how Evelyth thinks self-tracking apps exclude women, and the approaches that I come up with to improve the situation.

Hi Miao - 

Thanks for this thoughtful response. I think your reading of Evelyth is largely consistent with the argument she makes, but some of your claims are a bit strong. Evelyth is definitely implying that, if more women were staffed in design positions, they would be more capable of spotting certain potential deficiencies; however, it is not necessarily true that "only by doing so" can such problems be avoided (i.e., there are other design methodologies that could help too). You sort of make this point in the next graf, but it might be more persuasive to have made a more limited claim in the first instance; same goes for the claim that men are "usually" unwilling to invest in such apps ("sometimes" or "often" would be more supported by the reading). 

Your suggestion is intriguing. Do you mean the investors, or the people-being-invested-in, are female? Both? 



Erik Stayton: 
SDQ5: In the 26 years since Winner's piece, it has become, at least in the contexts of my graduate programs, so assumed that artifacts do indeed have politics that to even ask the question is painfully passé. That's lower-case-p-politics, like the gendered and therefore exclusionary quantified self tracking apps that Eveleth critiques. But the question of capital-P-Politics is less settled. While it is perhaps clear that nuclear weapons have such Politics, favoring authoritarian control (Winner, 131), it is by no means clear that my toaster is a Political object in this more restricted Mumfordian sense. It could be claimed---as one of my former professors, who refuses to use tracking apps that upload data off of his local storage, probably would---that tracking apps have a Politics: specifically, that they too favor authoritarian control, and a dystopian future of pervasive surveillance.

What about the increasingly automated vehicle. What are its politics? And what are its Politics? Are devices of this kind merely "highly compatible with centralized, hierarchical managerial control"? Is it possible to design democratic systems around such core technologies? As these questions are too large for this forum, let's consider the automatic transmission alone.

Is automating inherently a political act? Certainly it would seem to be, in the broad sense. Automation takes a political position on the role and value of human labor:  "You don't have to do / aren't allowed to do X any more. You should do something else." Anything that makes demands on what people do is political. The automatic transmission is designed to be convenient, to be "more efficient," to allow you to be lazy. It structures your driving practice in particular ways, through the furnishing of particular new affordances (e.g. an algorithm that selects the "best" gear by some criteria, plus a kick-down switch that triggers a shift if you depress the pedal far enough) and the elimination of others (e.g. complete manual control of the vehicle's gear at all times, and a clutch to remove it from gear at any time). Is this also a Political position? By the standards of David Noble, Marxist historian of technology, this kind of disciplining of the human---a de-skilling, removal of certain capacities and acclimation to a reduced level of control---might well be considered a Political act as well. It is an example of the sort of "atrophy of many human capacities" that Mumford and Noble are concerned about (Noble, America by Design, xxi). And what this atrophy does, in the language of Marcuse, is perpetuate and intensify "unfreedom" (Noble, America by Design, xxi). It seems a little absurd at first glance to make the automated tranmission a Political object that supports unfreedom, but there is a link, however tenuous, between even relatively tame automation and a very Political authoritarianism. Automated systems are effective levers for the design decisions of closed groups to reduce the autonomy of remote subjects. Seaver's piece attempts to deal with the consequences of this same characteristic.

But there is a countervailing Political trend here too. Arguably, increasingly automated systems (including the automatic transmission) may provide increasing mobility to an increasing number of people for whom old models were restrictive. This has a democratic Politics. While I would consider the possibility that automation is inherently authoritarian, it may be possible to use the technologies for democratic ends at the same time. The balance seems to operate at a higher level than the base technologies. Rather, it lies in the designs of the systems themselves, and may vary across different groups of users. Perhaps new systems can be added to old ones, and choice preserved. Perhaps joint human-machine systems can preserve human autonomy while allowing new modes of transport (as the joint driver-automatic-transmission system has arguably done). Perhaps the sacrifice of certain freedoms by a restricted group of people may be necessary to grant greater freedoms to a greater number. The issue is to ensure that the design of the entire system does not allow for a centralized managerial control that tips the scales too far in the other direction.

Hi Erik - 

I like the subtle distinction between big-P and little-p here, which is something I struggle with myself in these readings. FYI, Chelsea has been writing about some of the stuff in your last graf lately; you might want to talk to her if you haven't recently! 

Mike Sun: 
**DQ9: Why does Seaver oppose a 'reveal'/'transparency' model of understanding the cultural work of computation? What alternative approach(es) does he propose?**

According to Seaver, proponents of the ‘transparency model’ for understanding algorithms operate under a very binary notion of transparency: if users want to engage in more effective discussion and critique of a system, then, the argument goes, they should be given the same sort of information as a design engineer – full disclosure of information including user test groups, architectural differences, and tested variables. However, understanding the underlying details of an algorithm are significantly more complex than asking “Are you being transparent right now?”

The first reason Seaver opposes this transparency model is that information is not a binary, and thus simple requests for information, especially in an age where intellectual property is guarded like gold, leave no promises that the output will be thorough or even accurate. Furthermore, the lack of information can also contain information within itself – and can sometimes be necessary. Ask anyone who has conducted medical research what happens when you tell the control group that their pills are just sugar, and it should be clear why Seaver opposes the idea of full transparency. Intended system behavior and full transparency can be mutually exclusive at times.

However, at its core, the biggest detractor to having a fully transparent model of algorithmic design is inherent in the algorithms themselves. In a world dominated by the rise of “big data” and deep learning algorithms, computations that store and analyze millions if not trillions of data points are becoming the standard rather than the exception. In these examples, it is often the case that the creator of the algorithm cannot explain the decisions that are being returned. This goes back to Seaver’s statement that these calls for transparency, at their core, are rooted in the incorrect belief that somebody out there working for Google or Facebook has the knowledge they seek. These aforementioned people may be able to correct some embarrassing results, such as the association of gay men with sex offenders or the mislabeling of black men as gorillas (Barr, WSJ 2015), but they cannot offer any other form of transparency. If anything, both situations received immediate attention and corrections, which further highlights that even the creators of the algorithm could not perfectly predict its behavior.

A secondary consequence of the rise of big data and deep learning is that much of what the design engineer knows about the system – the architecture, the underlying algorithm; information that calls for transparency are seeking – is already out there. As an example, Facebook had made public the main variables used in their old EdgeRank algorithm to determine news feed content. Taking this one step further, it would not have been unreasonable to assume that the architecture of the algorithm was some form of neural network. Facebook could have then made every detail of its algorithm public, from the input data to the weights of each edge in the neural net, but what good would that have done the average person? Would it have helped the user to know that “user affinity score” – whatever that might actually have meant – was weighted by a factor of 10? As Seaver states, the “how”s and “why”s of algorithmic inclusion are much more important than simply “what” is being tested. Perhaps it should be important for a user to understand why Facebook weighs one variable over the other in determining content, but this is not what Seaver believes calls for transparency are asking for.

So what is Seaver’s alternative? Instead of focusing solely on trying to understand the technical details of algorithms, Seaver argues that users should expand their search radius and include cultural details – details about the decisions made by the hundreds or thousands of hands that go into building and refining any algorithm or system. After all, if the “why”s are much more important than the “what”s, then it is imperative to analyze the cultural circumstances under which an algorithm is developed along with the algorithm itself. Why does Facebook weigh one type of content higher than another, and what does that say about the social and cultural context the developers are working with? 


Hi Mike -- 

I think this is a pretty good reading of Seaver's point re: transparency and how it might not be as analytically helpful as many proponents seem to think. In the last graf, it would be interesting to talk to Nick (as I hope we will do later in the semester) about the cultural role of users vs engineers, and how someone like him thinks about separating the two (if indeed he does, which he may not, or at least as such). 

Jenn Yu: 
DQ9: Why does Seaver oppose a 'reveal'/'transparency' model of understanding the cultural work of computation? What alternative approach(es) does he propose?

Seaver opposes a “transparency” model because it operates on a couple of potentially flawed assumptions: the engineers have a comprehensive understanding of the algorithms, and the building blocks of the algorithms themselves are directly representative of their users. Achieving transparency between engineers and social scientists actually falls short of completely covering the technical, cultural, and social aspects of an algorithm. 
 	
As Seaver points out, an engineer may not even be aware of the full behavior of an algorithm. Time, multiple team members, and iterative designs all add to the complexity that defines computational software. An engineer can probably identify the direct function of each line of code, but when the algorithm is released “into the wild”, he/she may not understand, and therefore be unable to predict, the behavior of that algorithm (Seaver 8). This issue is magnified for larger companies that reach wider audiences.  

The actual variables and code included in algorithms aren’t purely technical either. Seaver makes the important distinction between “what” is included in an algorithm’s content and “how” it is achieved. There are several ways to define a single “what” variable (ex. the affinity score in Facebook’s newsfeed algorithm), and these definitions are based on assumptions made about the users (Seaver 8). A transparency model merely skims the surface and takes the code at face-value. In order to truly understand its cultural implications, we need to challenge the relationship between algorithms and its users and apply a more elaborate method of questioning how the software was built. 

Seaver mentions another interesting flaw of the transparency model: how can we trust that the engineers will be completely honest? Algorithms attempt to predict its users’ natural behavior and cater to it, so if some of the users are exposed to the “insider” information, then the software is essentially useless (Seaver 7). Additionally, engineers could withhold information and we would never know, since we don’t have the same technical background. This could be intentional (engineers are humans too, with pride and other selfish emotions) or unintentional (if we don’t ask the right questions, important details could easily slip through). It seems that the curtain between engineers and social scientists can only be waived if the engineers choose to completely drop it. 

It’s apparent that gaining an accurate understanding of the cultural implications of algorithms isn’t as simple as opening the lid of the black box that houses them. Even if engineers are completely transparent regarding the technical functions of their software, they are not factoring in the context of which that software was built. Algorithms were intended for human use, which means they themselves have human qualities. Instead of a transparency model, Seaver proposes an ethnographic approach. We need to examine algorithms as systems: networks of logic and the people who built them, almost as if the software has a culture of its own.  This approach breaks down the discrete distinction between the technical details and the broader contextualization of an algorithm, requiring both to be examined on equal grounds. 

While I agree that this redefined perspective is a step in the right direction of resolving the transparency model’s issues of complexity and inclusion, I think there are still concerns that the ethnographic approach doesn’t address. Seaver suggests that if we (the social scientists) are willing to “muddy the waters a little”, by studying the behaviors of the engineers, then we’re bridging the gap between the insiders and the outsiders. However, the engineers should be equally as accountable for understanding the social implications of their technology, as we are for understanding the people behind the code. Engineers could contribute much more insight if they know the context of the social scientists’ target of study. Additionally, there is still the risk of engineers withholding information to preserve the technical integrity of their algorithm and other barriers that arise from the different backgrounds of the two sides. An ethnographic approach should involve a mutual collaboration. 


Hi Jenn -- 

Excellent username. Strong point too. I think you've read Seaver right, and I don't think he would disagree with your call to train engineers to build ethically (just that it is outside the scope of this article). Curious: what do you think an ethnographic approach means in this context? 

Jenn Yu: 
Hey Chris,

Normally an ethnographic approach would attempt to record all possible observations from the the viewpoint of the subject of the study, but here we have the interesting risk of the observations being an inaccurate reflection of the cultural impact. Additionally, there are disparities between the viewpoints of a social scientist vs. an engineer (both of whom are "subjects" of algorithms), which could contribute further to this oversight of information. I think the highest priority in tackling this is maintaining a systematic evaluation of the assumptions made when initially setting up the algorithms, instead of just observing the impact of them after they are implemented. This would make for a more balanced collaboration: social scientists would be able to apply their expertise in evaluating these initial assumptions, and engineers would then exercise their technical knowledge of how the algorithms work.



I think you're right, particularly for a product-focused approach (as opposed to academic/critical, which wouldn't care some much about collaboration as much as understanding from their own perspective). It's interesting to note the different ways that corporations have handled this. Microsoft is one of the biggest employers of anthropologists in the United States, but I believe they largely exist in Microsoft Research, which is somewhat firewalled from the product teams. My friends who are user researchers at Facebook, by contrast, are embedded in (and subject to) specific product teams, which has a very different dynamic. 

Veronica Valencia : 
Knowing algorithms

Everything we do on our phones and computers is constantly being recorded. The algorithms used help create a better internet experience for the user by recommending certain sites based on user history. But as Seaver states, although algorithms help create an enjoyable internet experience, algorithms are also “hides divergent viewpoints, inhibiting debate and the establishment of a public sphere” (3).  At the cost of a more enjoyable internet experience we sacrifice the ability to see material that has been pre-categorized to disappear from our feeds. Eli Pariser TED talk discusses the phenomenon everyone has experience with Facebook. Like most people, Pariser kept in touch with different friends on Facebook’s platform and clicks and views articles found on his news feed. When Facebook realized that Pariser “was clicking more on [his] liberal friends’ links than on [his] conservative friends’ links,” they edited his conservative friends out of his feed (3). This makes it difficult to “get an unfiltered perspective” and as Seaver suggests can create a one dimensional internet experience for users (5). I would go further to argue that the algorithms used to suggest articles, music, and web pages create a divide in politics and social issues. With the upcoming elections it is important that voters are exposed to information regarding on both parties, but with Facebook preferences it is nearly impossible to provide the user with equal amount of content from both parties. This also leads to a great divide in opposing opinions. People’s feeds are already altered to only display content that the user is more likely to agree with. This inhibits change viewpoints and provide users with new information regarding controversial topics. 
Understanding that the internet is constantly changing, that “systems…[are] made, maintained, and revised by many people with different goals at different times” is important in approaching social sites such as Facebook (8). Becoming aware and proactive in looking at different sites that display different information is important. Algorithms should be created to focus on making the interaction between the user one that more user based then regulated by the algorithms. Users should have the ability to filter for themselves. The use of algorithms for websites like Facebook, Google, and Bing only limit and hinder our scope of information. 
* Something else I though about after reading the articles was the addition made to the Maps app on the iPhone to include transit information instead of only driving directions. After reading both the Eveleth and Winner articles I understood the connection behind the creation and development of many apps. The exclusion to take into consideration the many people that commute using the transit relates to the exclusion to not include a monthly period tracker on the health app for the iPhone. I am sure the people behind the Maps app aren't taking transit and don't have a need to know when the next train is scheduled to depart. Apps like Maps and the health app also cater to the middle class and excludes the needs of lower socioeconomic users. Further questions I would like to pursue is the exclusion of low socioeconomic users in apps, and the ways they are excluded. 


Hi Veronica -- 

Thanks for this thoughtful response. Do you think Seaver agrees or disagrees with Pariser? I read him as saying that Pariser's account was too simple - a fiction - but it seems like you read him as sympathetic. 

I think you're right to draw an analogy between transit directions and health modeling, inasmuch as gender and socioeconomic status are complicated, intersecting things and benefit from a particular vision of the world. 

Kathleen Chen: 
DQ9: Why does Seaver oppose a 'reveal'/'transparency' model of understanding the cultural work of computation? What alternative approach(es) does he propose?

Intuitively, it makes sense that when the basic facts of a function are revealed, then the function can be openly critiqued and the function can be better designed. This assumes that those who create the function do not have the critical perspective to better the function. However, in the case of algorithmic systems, simply revealing its details may not provide those expected benefits. Nick Seaver states that “transparency in practice is complicated and by no means a guarantee that the information provided will be complete, accurate or understandable” (7). Additionally, “revealing the details would render their algorithms useless, enabling bad-faith actors to game the system (not to mention aiding corporate competitors)” (7). In short, revealing the details of an algorithm does not necessarily mean that it will be more understandable and it may be detrimental to the originator of the algorithm. Seaver states that the complex nature of algorithms and what is included in the algorithm are pose problems when being transparent. 

Seaver opposes the ‘reveal’/’transparency’ model of understanding the cultural work of computation because this model assumes that someone on the “inside” already knows what we want to know. However, algorithms are not as simple as its definition of “a sequence of computational steps that transform the input into the output” (1). Because of the complex nature of algorithms, even those to create the algorithm may not know what the output will be. At one point, Google’s Android Marketplace’s recommendation system suggested an application for locating sex offenders after a user looks at an app targeted at gay men. While this is clearly not a connection that the computer scientists intended, the algorithm unexplainably connected the two applications. Additionally, several people collectively work to make an algorithmic system, making it harder for a specific engineer to have complete understanding of the entire algorithmic system. 

Seaver also raises a point in stating that while the decision-making criteria of an algorithm is helpful to know, “the “what” of algorithmic inclusion is often less significant than the “how”” (8). Seaver uses the Facebook EdgeRank algorithm as an example. While the main variables of the algorithm are well known, how each of these variables is calculated remains unknown. In other words, even though the public knows what the algorithm is made up of, we do not know how the “what” came to be. Simply knowing what the algorithm is made of does not help the users understand how the algorithm actually works.

Algorithmic systems are extremely fluid—culture inherently plays a part in its development. Seaver suggests that users should approach understanding algorithmic systems by including its cultural context. These systems depend on cultural details just as much as technicalities. Culture must play in a role in how significant a variable is in an algorithm. Understanding cultural context may help both engineers and users better understand the output of an algorithm—it will explain the “how”. In other words, exploring cultural context will help users better understand the complexity behind algorithmic systems. 



Hi Kathleen -- 

Thanks for the response. I think you're basically right w/r/t why he opposes the transparency model, and why culture is important to understand. Do you have a sense of *how* Seaver would go about understanding the culture of technical context? 

Kathleen Chen: 
Hi Chris,

To understand the culture of technical context, I believe Seaver would go about learning how the engineers, as people, approach algorithms, a technical tool. The behavior and habits of those who create the algorithms must affect how the algorithms are created.  

Kyle Saleeby: 
DQ7: Using Star's approach, identify and describe an infrastructure that you use every day at MIT. Who maintains it? Who inscribed their assumptions, and how? What other things that you do depend on it? In what precursor systems is it rooted?

Infrastructure, as described by Susan Starr, could be envisioned as a system of substrates where objects, processes, and tools exist to facilitate other tasks. By definition, Star argues that infrastructure is invisible as part of the background that helps in the execution of other more visible tasks. However, Star also agrees that the invisibility of infrastructure is greatly affected by the viewpoint of the observer. To use her example, rail lines along a railroad may be largely disregarded in most commuters’ minds as an existing and consistent aspect of travel. One does not question whether or not the railroad will break as some may question their car engine. But to a railroad engineer rail lines may be a system very similar to a car engine, where both need careful consideration, maintenance, and inspection. 

A similar infrastructure that permeates the lives of students at MIT is the Stellar course website system. Nearly all students constantly use Stellar to access information, assignments, and grades as part of their regular day to day activities. Professor in turn keep their Stellar sites updated weekly with upcoming information, assignments, and readings. Even though still widely used, the stellar site does have a visual feel of an older or less modern system. It is continually maintained by MIT’s IS&T (and frequently improved as indicated by posted regular outages for IS&T modifications) but it is rarely updated as one would update the visual interface when releasing a new operating system for a computer. For example, the vast majority of Stellar appears to use HTML for visual design and object placement whereas many modern websites would use a combination of JavaScript and CSS to make the user interface with the website interactive and implement its graphic design. 

Stellar’s early website feel may trace back to its original implementation. Stellar may have been introduced in the early days of websites before modern graphic design capabilities and user interface practices were developed. It may have been envisioned as a one stop shop for all professors and students to use. However in the past few years, Stellar has been used by some professors only as a site that redirects to their own webpage where class material is posted. For example, Professors can post their materials and .pdf documents on stellar but some choose to post student’s grades and assignments on a different site. Instead of using Stellar’s own assignment and grade viewing system, they redirect from Stellar to a different infrastructure. To explain the current state and possibly declining usage of Stellar, we could speculate that its lack of modern updates may lead some professors to use it in name, only to point to their own modern version of a course website. IS&T may also be hesitant to change the format of Stellar in order to keep the methodology consistent for professors who learned to use Stellar once becoming a member of MIT and have been using it for years. This conflicting cycle of interests may prevent Stellar from being updated and in turn convince more users to use it as a redirecting page.

Similar to Star’s findings, the Stellar infrastructure is an extremely complex system that is hard to fully understand without careful analysis and information from a variety of users. While I can only speculate on Stellar’s usage and updates from my viewpoint, Star was able to study infrastructures from a variety of users. Stellar may in fact be constantly updated without dramatic visual changes, unbeknownst to many users. Unlike Star’s in-depth analysis, I cannot truthfully claim to know how Stellar is updated or maintained. While some aspects of Stellar may indicate that the infrastructure needs repair, it may be a very viable system once updated. Stellar may be weaker in some areas, but it is an infrastructure that is central to education at MIT and it may continue to be used as base on which more modern structure is built.

Hi Kyle - 

I, too, am frustrated by Stellar (as you can probably tell because literally no part of the course touches it, making this an alternate infrastructure entirely). I think your thought experiments are good ones, and it would be interesting to write a history of stellar and track how it came to be and whether it was ever more or less of a kludge. 

Sharlene Chiu: 
**DQ5: How does Winner think technologies can have political properties? Can you think of any technologies you've encountered in your own life that seem to you to have political properties or effects -- or conversely, where an effect was widely believed, but you found the opposite?**

Winner claims technology, like legislative acts, can create virtually irreversible impacts on social order. Political decisions are often made with particular goals in mind. These goals can be malicious toward groups of people, one example being the goals of the Jim Crow laws. But oftentimes political decision-makers pass laws with the intent to improve overall public wellbeing, only to witness unforeseen consequences arise.

For instance, China’s one-child policy was passed with the intent to curb the nation’s population boom. However, cultural factors, such as preference toward male children, led to widespread abortions of female fetuses and consequently an imbalanced sex ratio among the younger population. I doubt the lawmakers wanted such an imbalance, so I can imagine the outcome being a result of either outright negligence or, perhaps more likely, underestimation of cultural and social factors. Regardless of the decision-making process, the nation will require much time and many resources to mitigate the policy’s effects.

Paralleling this concept of unintended consequences, members of the tech industry tend to crank out products that are expected to solve numbers-based problems e.g. increase factory output, optimize energy levels, redistribute resources. Unfortunately, these drivers often fail to consider how these technologies will fit into current and future social settings, thus producing unforeseen consequences that have long-lasting effects. Winner summarizes this concept with the statement that adopting certain technologies is choosing “a particular form of political life.”

An immediate example that comes to mind is Facebook, a platform many of my peers and I use almost every day. The original premise of Facebook was a social networking website to better connect users with familiar people. My classmates originally interacted with one another as if Facebook was an extension of the physical world, with inside jokes posted as statuses and arguments made in comments sections. This is still the case for many users today. 

People use Facebook to look at other people’s lives and their own relationships with those other people. This is highlighted by Facebook’s default start page, which is the newsfeed instead of the user’s personal timeline. The decision to first show the newsfeed encourages users to view others’ content and discourages users to view their own profile. As a result, people can easily forget about personal information they’ve shared in the past, especially with obstacles such as loading time for older content.

Furthermore, until a few years ago, the default privacy setting was public, meaning all content on a user’s profile was made available for anyone to see. These default settings seem innocuous at first, but there are consequences to neglecting to review one’s timeline and behaving in a public space as if one were in a private setting among friends.

Rumors circulated about employers and college admissions officers using Facebook to learn about candidates’ personalities. Prior to social media, personal activities and preferences were not so readily available, so people had more control over how they presented themselves to employers and admissions officers. Before the default setting was changed to “Friends Only,” those who forgot to change their privacy settings were at a disadvantage compared to those who took the initiative to change, even if their personal lives were similar.

What’s more alarming is the fact that information from social media has been used as evidence in court. Lawyers using public profile content sounds reasonable, as anyone can access that information. However, there are instances when courts found good enough reasons to [allow lawyers access to private Facebook content.](http://www.courts.state.va.us/opinions/opnscvwp/1120074.pdf)

I doubt the creators of Facebook expected their product to become a tool to access and influence people’s lives. I can imagine in the eyes of developers hoping to improve user experience, public content can encourage users to add more friends or post more content themselves. Since the website focuses on relationships and social networks, pulling the focus away from the user’s own timeline and toward others’ is a reasonable decision. An unintended but ingrained consequence is these choices also create opportunities for figures of authority to view and take advantage of information that wasn’t originally posted for their eyes. 

Hi Sharlene - 

> Unfortunately, these drivers often fail to consider how these technologies will fit into current and future social settings, thus producing unforeseen consequences that have long-lasting effects. Winner summarizes this concept with the statement that adopting certain technologies is choosing “a particular form of political life.”

Do you think Winner sees the results of such choices as intended consequences or unintended consequences? Or does it depend? Is it still a 'choice' if the outcomes are unforeseen? I don't mean that as a leading question; genuinely interested in your thoughts. 

The example of Facebook is an interesting one. I might argue about whether a surveillant gaze has been part of Facebook all along, but probably fair to say that when Zuck started it he wasn't anticipating the degree to which the website would become bound up in authority and governance. 

Christine Konicki: 
DQ9: "Why does Seaver oppose a 'reveal'/'transparency' model of understanding the cultural work of computation? What alternative approach(es) does he propose?"

In the essay, Seaver opposes a “transparency” model of understanding the cultural work of computation because it only functions as a starting point for fully knowing algorithms. He mentions four issues with transparency that expand on this statement: assumption of knowledge, competition, complexity and inclusion.

First, asking a company to make its algorithm (or, more appropriately in the context of the essay, algorithmic system) transparent for to solve the kinds of problems discussed in the essay carries an assumption that all of the knowledge needed for a solution will be revealed that way. Most people would think that all of the answers will be written in the code, in a paper discussing the algorithm, or known collectively by the people behind it. However, there’s two problems with this. On one hand, the algorithms people have the most questions about are more complicated than something universally known than quicksort or Bellman-Ford. On the other hand, a lot of decisions made when developing software come from different biases toward certain ways of performing computation, from adding little nick nacks just to pass unit/integration tests, and from the company’s best interpretation of what would satisfy customers. Documenting all of this information is both impractical and unlikely to happen.

This bring us to the second issue discussed: competition. Competing companies are not going to want to let all of this information be known because their ideas are precious and likely to be stolen by competitors. Furthermore, there is a risk that customers might try to “game the system” using the released knowledge.

The third issue mentioned is complexity. An algorithm has so many steps, branches, checks and connections to other pieces of the same system that it ceases to become a simple algorithm developed by one person and turns into an epic network developed over a period of time by dozens of people. This level of complexity makes it notably harder to determine exactly what piece of the algorithm caused a particular result to happen. Thus, requesting transparency assumes that the guts of the algorithmic system will actually offer clarity in how it operates instead of revealing what a hot mess it is.

The fourth and final issue discussed is inclusion. A complex algorithm may use some quantification (i.e. weights, scores, etc.) to make decisions about what to do/show to a customer on the site. According to Seaver, it’s not enough to just know that a formula exists to compute something like “affinity” or to know what variables are taken into account. If we want to answer questions about an algorithm’s cultural effects, its interpretation and cultural significance will not be included when it is made transparent. We would only be able to suppose “in broad strokes” how the algorithm might handle certain cases instead of fully understanding the effects.

After outlining these issues, Seaver proposes that we treat algorithms not as formulas but as complicated “algorithmic systems” and examine the relationship they perpetrate between technology and culture. This can be done when the technically oriented brains of engineers collaborate with the culturally acute brains of social scientists throughout the developmental process of an algorithmic system. For example, the tendencies and critical thinking of a team of coders can be noticed (and perhaps quantified) while the algorithm is being written. If Seaver’s idea is feasible, algorithms can evolve from impersonal, functional IO machines to intelligent, contextually aware thinking machines.

Hi Christine - 

I think you've read Seaver right - at least, consistent with his own terms - in why transparency is insufficient. In the last graf, though: can you tell me more about what you think Seaver's "idea" is? I'm not sure his goal is to create contextually aware thinking machines, nor to pair engineers and social scientists together in a collaborative effort to design them. Such a goal isn't necessarily incompatible with his approach but I'm not sure his is. Do you disagree? 

Joel Gustafson: 
**DQ9: Why does Seaver oppose a 'reveal'/'transparency' model of understanding the cultural work of computation? What alternative approach(es) does he propose?**

Aside from the commercial arguments against it (competition, security, etc), Seaver argues that calling for "transparency" betrays a sort of naivety about the nature of the algorithms themselves, and an idealistic view the the programmers who made them. But particularly with the recent rise of machine learning techniques, even the creators of a system often understand very little of a system's behavior. In fact, engineers frequently employ the same experimental techniques that Seaver lamented in Section III to tune input parameters to achieve a desired result, which means that the transparency activists should be seeking that "desired result" to be made public. However, this is usually not set by engineers, and is much less easily verified.

Furthermore, Seaver proposes that even when a system is completely transparent *and* completely understood, it's still only "known" in a limited scope whose lines quickly blur when considered in context. In the wild, "likes" on Facebook shift from buttonEvents to emotional intentions. When considered in a static state, this sort of representation is perfectly acceptable, but the dynamic and interactive nature of these systems makes the definition of these variables a sort of moving target. These emotional intentions cycle in and out of a machine-human feedback loop, snowballing and accumulating bits and pieces of culture that are re-interpreted by people and learning algorithms alike. Algorithms, Seaver argues, are not stateless functions, but rather evolving systems, as much a part of us as we are part of them.

What follows are my own thoughts.

<rant>

All of these issues stem from the much deeper philosophical problem of trying to study systems from inside them. This has numerous technical analogies: no formal system can prove its own consistency and completeness (Godel), no machine can determine its future (Turing), and observation is inherently destructive (Heisenberg). We also find more heuristic versions of this idea in economics (Goodhart's Law: "when a measure becomes a target, it ceases to be a good measure") and artificial intelligence (Seymour Papert: "you can't think about thinking without thinking about thinking about something").

The only reason we have faith in the rest of experimental science is that we believe the physical world to be unchanged by our measurement and relatively independent to the size the the system we consider it in (gravity works similarly on a 10^1 m scale as it does on a 10^10 m scale). But even this has proven problematic (relativity et. al.), and it was a risk to assume that to begin with.

Ultimately, you can only rigorously study a system from within it for so long before you run into a version of the Halting Problem or Incompleteness Theorem that sends all analysis into a paradoxical loop. So algorithms can be "known" only in a theoretical vacuum, and their social affects can be studied only in isolated cultures.

Once the algorithm is let out of the computational Pandora's Box, we can only approximate its behavior.

</rant>

Hi Joel - 

Interesting rant. I am reminded of an economic historian I once read who was asked what it would mean if in fact everything was random chance and not (as he had argued) governed by the laws of economics. He said, well, that may be true, but history as random chance is too much for the human spirit to bear, so that's why we do history. 

One might ask why we try to understand algorithms, and one answer might be that well, we have to to, to try and regain some sense of human agency in what feels like an increasingly futile human condition. 

I don't think Nick would disagree with your analysis/critique (I think it would make him laugh ruefully); the question in his work, as for most unpretentious academic work, is to simply try to understand a particular delineated context on its own terms, and go from there. 

So it goes. 

Charles Bachmeier: 
DQ4: Why/how does Eveleth think self-tracking apps exclude women? What design methodologies or strategic approaches would you use to be less exclusive? (hint: the PLATO reading might be helpful here)


The main piece in Eveleth’s argument revolved around Apple Health which was supposed to be an app that tracked all aspects of a customer’s health from exercise, to diet, to sleep. But received a lot of criticism for not being able to track a woman’s menstrual cycle, a large part of half of apple customer’s health. Eveleth argues that this would have been a simple feature to add and is much less complex than some of the features already implemented, so why was it not included? Eveleth believes that do to the majority of workers in Apple, and in tech in general, being male, they simply overlooked this major part of every woman’s life. She argued that the skipping of this feature wasn’t malicious in intent, Apple, and self-tracking apps as a whole, are just a symptom of a larger issue which is the lack of women in tech.


Now there are health tracking apps which include the tracking of a woman’s menstrual cycle, however these are more than often created by men and made too look “feminine”, covered in flowers and drenched in the color pink. Often time function is made to take a backseat to form as male developers believe women will only download an app if it’s bright pink and covered in rainbows. Now this is not always the case, take for example the app Clue, which was designed by a Ms. Ida Tin and made as an effective and straightforward period tracker. Ms. Tin argues that by gendering these apps it furthers ostracizes periods as something strange and not a normal part of billions of people’s lives. But thanks to apps like Clue woman can successfully monitor aspects of their health often left out of big name apps and in a way that doesn’t talk down to them. And this was all thanks to having a woman’s perspective in the tech industry.


The most obvious way to combat this would be for tech companies to hire more women in the tech industry and encourage more young women to study computer science. But this is not a straightforward solution, as Eveleth explained in her article, woman developers, creating apps specifically for a female demographic often have a hard time attracting investors who, as you guessed it, are predominantly male. The male investors too often say they can’t relate to a product and thus refuse to fund it, stifling a lot of female developers whereas their male counterparts would have no such trouble. To fix the issue of sexism in health tracking apps, and for all app development really, would require a societal change in the way products created by women, designed for women are seen. For when only men design products, [like this](http://imgur.com/gallery/GFOnLyo) made for women, especially in regards to health tracking apps, key features are left out.

Hi Charles - 

Thanks for this response. I think you've basically read Evelyth right. Do you think things have changed now that Apple incorporates this material into the HealthKit infrastructure? 

Frankie Schembri: 
**DQ5: How does Winner think technologies can have political properties? Can you think of any technologies you've encountered in your own life that seem to you to have political properties or effects -- or conversely, where an effect was widely believed, but you found the opposite?**

In Langdon Winner’s *Do Artifacts Have Politics?*, the author conjectures that technologies (manmade systems of hardware, software, or other media) have political properties in two ways. The first way is when technologies are used as the means of executing political ends – i.e. using technology directly to address an issue within a community or user-base. The second way, Winner states, is when technologies are created with imbedded politics – when a system is built in a way that requires it to be governed by a certain type of political structure. 

I’ve had experiences with both of Winner’s two types of political artifacts. A recent example of the first type, using technology as a tool for solving an issue in a community involves the relabeling of bathroom door signs in my dorm on MIT’s campus. Originally intended to indicate for which single gender (aligning with the male-female binary) the bathroom was intended, the signs in my dorm have recently been modified to be unisex. While not a perfect solution, this change in the technology allows for greater bathroom convenience and inclusion for individuals not falling on one side of the traditional gender binary. This change reflects the changing politics around ideas of gender identification and gender separation within my dorm’s community.

The second type of political technology – artifacts that are created with inherent political structures in place or built in away in which they will function under certain forms of governance – arises in my experiences playing the MMORPG Runescape in the early 2000’s. Runescape initially seemed to function, at least from the player-side, as a merit-based society, in which more hours of gameplay were rewarded by increased ability in skill and the collection of items of greater value. While a small group of developers had built the world and set up the logistical rules of gameplay, they ran little interference on players’ actions within the game. As Runescape grew in popularity, Jagex, the game’s developers, began to exercise more control of the game, including adding censorship of swear words in game chat, banning the use of bots, and adding rules to prevent real-world trading. While initially players within the game environment operated with as much freedom as the gameplay allowed, as soon as players began selling items and leveled-up characters for real-world compensation, the developers were quick to intervene. Were the developers acting to preserve the merit-based, democratic world of the game environment by preventing real-world advantages from factoring into gameplay, or were they restricting a natural extension of gameplay and imposing their own authoritarian rule upon users? 

Online culture and its associated artifacts bring up the complexity of technologies’ politics because of the ambiguity of ownership. Who owns the characters of Runescape? The users who spent many hours shaping their abilities and interactions with other players? The developers who built the game environment, manage the servers, and moderate player interactions? The wireless providers who give players access to the game servers? The unique act of creating an artifact online has many layers of politics, both imbedded and external, which complicate Winner’s argument. When systems exist in the physical world, the boundaries of use and ownership, while still sometimes blurry, are more clearly defined than those of online technologies. Online artifacts have the potential to be even more politically charged as they reflect and are shaped by the agendas of many different actors. 


Hi Frankie -- 

Thanks for this response. I think the examples of the bathroom signs are a good example here, and would have been for Star as well. As for Runescape, I'm curious: did players come up with any workarounds for those swears that elided the technological rules designed to prevent them? 

Daniela Morin: 
DQ3 How does information technology have the capacity to so strongly influence our societal beliefs and form subjective moral values? 
It seems that the smooth function of everyday life is contingent upon the information technology that in some ways has become an extension of ourselves. Today every aspect of every day life seems to have a form of IT integrated into it and is constantly molding the ways in which we communicate with each other. With such a ubiquitous entity permeating our existence and relationships, it is crucial that we come to understand, or at least attempt to decode, the ethical implications of the freedom and repercussions that come with sharing personal information that social media platforms allows us to create and disseminate unrestrained. In the digital age, there now exists massive amounts of data that is recorded, stored and organized for multipurpose use. It is imperative that we question who is in control of this data, what is to be done with it, and how will its accuracy be insured. In a capitalist society, the production, access and control of digital information presents a complicated multidimensional moral challenge. 

Let's consider how digital information is non-exclusory, theoretically we can possess the same digital information someone else does, because copying it from one digital source to another does not require deleting the previous copy. Since there is no physical obstacle to the spread of all information,  morality or economic justice remains as the factor with which we might prevent distributing certain forms of information. Therefore, understanding the role of moral values in information technology is indispensable to the design and use of these systems. How can we protect the integrity of identity for the parties involved  online?  When is a breach in privacy reached for an individual's available online data? To what extent are these "democratizing liberating forces"? in our  networking scope ? We have a notion that whatever is occurring " behind the curtain" (Seaver 7) should be regulated and contained. When we think about the discuss the issue of transparency we come to a divide or discrepancy between two what is know on the "inside" and how the information can be passed on to an entity of "critical perspective" (Seaver 8). It is also important to consider the infrastructure of digital networks and how they translate into the hierarchical social structures through social media platforms and other forms of technology. The question that Crawford and boyd proposed, "will big data usher in a wave of privacy incursions and invasive marketing?" was one that caught my attention as an important repercussion of the "bid data socio-technical" phenomenon. The ability of algorithms to "extract and illustrate large scale patterns of human behavior" has powerful implications for the future of our societal networks and identity, which is regulated by social norms and flawed human perception. The devices and online network technologies with which we interact with have an undeniable role in organizing and sometimes determining how we order our daily activities and inadvertently our lives for long period of time. Unanimously and sometimes subconsciously the public chooses the large scale technological use structures that come to determine the course of people's relationships, consumption and ultimately identity.   

Hi Daniela - 

Thanks for this response. Your question seems to take as a given that technology can strongly influence our social beliefs and moral values. Is this an argument you're drawing from one of the readings? If so, which and where? It seems like you're thinking a lot about identity here, which is great - and very much bound up in the themes of the course - but I'm having trouble pinning it down to these readings. 

Peter Downs: 
**DQ6:** Winner argues that the "available evidence tends to show that many large, sophisticated technology systems are in fact highly compatible with centralized, hierarchical managerial control." Is the Internet a (counter)example? Why or why not? 

---

A single company, Twitter, dominates microblogging (everywhere except for China). A handful of companies (Facebook/Instagram/Whatsapp, Snapchat, Google/GMail) absolutely own the space of personal communication. You can set up your own blog but even then you’ll probably use Blogger (owned by Google) or Wordpress. According to [Adamic and Huberman](http://www.hpl.hp.com/research/idl/papers/ranking/adamicglottometrics.pdf), 0.1% of websites account for ~35% of all internet traffic, and 5% for ~75%. This was back in 2002; today, just two websites (Netflix and YouTube) are [responsible for ~50% of peak internet traffic in North America](https://www.sandvine.com/trends/global-internet-phenomena/).

On a structural perspective, Adamic and Huberman found that the distribution of traffic among nodes tends to meet a “scale-free”, power law, or zipf’s law distribution -- all different terms for the same fact, that a very small number of nodes in the network are responsible for an outsized proportion of connection and interaction. In this case, centralization leads to greater fault tolerance for the network as a whole -- the amount of damage done by taking down the communication links between nodes at random is minimized, because it’s improbable that these random failures would affect the relatively few nodes responsible for the majority of the traffic.

Compatibility with centralization is true of the internet no matter the scale at which you perform the analysis. In between the traffic level and the application level, we have the Domain Name System. DNS makes it possible for you to type in “google.com” instead of a long list of numbers; essential to the adoption and growth of the internet as we know it. But it functions by transferring information through a strict hierarchy, with very few root nodes functioning as the true source: [just seven people](https://www.sandvine.com/trends/global-internet-phenomena/) share control over the top level.

Winner immediately contextualizes his statement by asking “whether or not this pattern is in any sense a requirement of such systems, a question that is not solely an empirical one.” This is important when it comes to the internet, because [the internet has not always been centralized](http://www.newyorker.com/tech/elements/the-mission-to-decentralize-the-internet). Nor does it require centralization to function. But, [Barabasi and Albert](https://en.wikipedia.org/wiki/Barab%C3%A1si%E2%80%93Albert_model) have shown that any network that grows over time in such a way that new additions to the network are more likely to connect to nodes that are already popular (preferential attachment) will end up with these power law distributions -- as they grow, they become [more and more centralized](https://en.wikipedia.org/wiki/Betweenness_centrality).

So, yes, the internet is “highly compatible with centralized, hierarchical managerial control.” And it certainly would not be able to function as it does now without that centralization.

Hi Peter - 

I think you've well-supported your claim, particularly with the reference to the DNS management chain. My only quibble would be that I think saying this is true no matter what the level of analysis is that, at least in my view, there are some ways to look at the Internet where it looks decentralized from one angle even as it looks centralized from another. For example, the process of contributing to a Wikipedia article is decentralized compared to, say, Britannica, even as the authority structures of what-Wikipedia-is-and-where-does-it-live require well-delineated, hierarchical, in some cases hardcoded regimes of central control. But you can still trip a lot of people up in the year 2016 just by pointing out the Internet is not, in fact, a big free lawless playground where everything is a million points of liberated light, so definitely good instinct on this one. 

Casie Chen: 
**DQ4: Why/how does Eveleth think self-tracking apps exclude women? What design methodologies or strategic approaches would you use to be less exclusive?**

Eveleth outlines several ways self-tracking apps exclude or caricaturize women, opening with the "comprehensive" Apple Health app, and going on to list:

* the way sex apps rate quality of sex based on male pleasure statistics or pornographic standards (also an industry tailored to a male audience)
* how the majority of menstrual tracking apps in existence focus on stereotypical symptoms of PMS - which are oft cited to create an argument for reducing the validity of women's emotions - or focus solely on the coexistence of the woman with a man (fertility, boyfriend tips)
* how even the assumption that people always have their phones on them is a small assumption which holds true for very few women who wear women's clothing, which often has tiny, fake, or nonexistent pockets

I think this problem exists in many aspects of tech as a result of the industry being dominated by, as the article points out, straight white men. This has been a [problem for decades](http://fortune.com/2015/04/24/women-tech-documentary/), and it's [not just a gender problem](http://content.time.com/time/business/article/0,8599,1954643,00.html). As Miao and Charles pointed out, the first step is inclusion of women in all stages of product development and all levels of investment. However, I think this is only part of a solution to a societal flaw that extends beyond tech. Women have been shamed for generations for menstruation (and still are in many parts of the country and the world), for expressing their sexuality (again, still are). They are also, in many cultures, taught that being quiet and timid is a positive trait, which is a possible contributor to the wage gap ([less aggressive negotiation](http://onlinelibrary.wiley.com/doi/10.1111/j.1744-6570.1999.tb00175.x/abstract)).

I don't know that there are any approaches aside from the obvious answer of inclusion and integration (as opposed to exclusion) that would solve this. Perhaps more of an effort to dismantle gender stereotypes, but that often comes along with more representation. In the meantime, there are some beautiful things happening with products designed by women for women (and whose teams are well-balanced gender-wise!). These are just a few that I know about as a consequence of running the Student Sex-positive Club, so I'm not going to guarantee these links are SFW, though they're not immediately explicit.

* [Happy PlayTime](http://www.happyplaytime.com/index.html#sthash.6tFZlcPt.dpbs), an education app on female masturbation
* [OMGYes](http://www.happyplaytime.com/index.html#sthash.6tFZlcPt.dpbs), a website centered around spreading research-based information on women's pleasure

Hi Casie - 

I really appreciate the historical/cultural context (re: women's bodies as objects) you brought into this response. One question I have for you - really implied by the broader PLATO readings - is whether a 'feminist' self-tracking app can exist, or rather whether feminism demands an *ecosystem* of apps. At least some traditions of feminist tech criticism suggest that the problem of apps is their proposed universality. It's sort of the inverse of the intersectional olympics problem, i.e., how do you build an app that builds for everyone's experience, or do you instead try to build lots of apps. This is something I've been thinking about for awhile and don't feel like I have an answer -- would be interested in your thoughts. 

Casie Chen: 
I've been thinking about this a bunch over the past few days, having just gone to career fair and a bunch of tech dinners where I was the only woman, or the only talkative woman, and discussed gender imbalance and general problems re: women in tech. Most specifically, [this post](https://medium.com/tech-diversity-files/if-you-think-women-in-tech-is-just-a-pipeline-problem-you-haven-t-been-paying-attention-cb7a2073b996#.8nmmb38pj) has been on my mind and in my conversations. I was discussing the "What can we do about it?" section of this post with a friend, and he pointed out that while he's not a huge fan of drinking, he would enjoy working in an environment that encouraged more time spent developing relationships with coworkers, whether that be going out for drinks or playing pong or staying after-hours in general, and that he also appreciated competitive environments. I'm glad for my friend, and I'm glad that he's in an industry whose culture fits his technical interest. However, the main point that I got across to him was that while I was glad these things existed for him, there needed to exist more prominently the same level of fulfilment for people who don't appreciate those things, but share his technical interests.

In the same sense, I think that an ecosystem of apps is really the only solution. I don't think it's reasonable to expect any team that can build a "feminist" app that encompasses all the aspects of being a woman (a woman of color? a trans woman? an infertile woman? a disabled woman? etc.), or to socially penalize a team that tries. What is lacking, though, seems to be well-publicized/successful/popular examples of apps that represent women from any perspective other than the prevailing one which Eveleth is describing.

Julia Guo: 
**DQ8: What do boyd and Crawford see as some of the limitations of 'Big Data' and associated 'social network' research? How are these methods like or unlike other ways of understanding social science networks?**

In "Critical Questions for Big Data" (2012), boyd and Crawford acknowledge the rise and era of ‘Big Data,’ the method of using technology to analyze massive aggregate amounts of data in order to (hopefully) draw insightful and novel conclusions. Boyd and Crawford define Big Data as a "cultural, technological, and scholarly phenomenon" that deserves a critical interrogation regarding its assumptions, biases, and limitations (663). 

Now that Big Data gives us the capability to collect and analyze data at a huge scale, boyd and Crawford argue that this "reveals an arrogant undercurrent in many Big Data debates where other forms of analysis are too easily sidelined" (666). That is, the assumption prevails that Big Data is the ultimate form of research and knowledge, trumping over traditional methodologies of social science research, because of the literal sheer amount of data backing it up. However, this is dangerous to believe for multiple reasons, one of which is that the specialized tools used for Big Data analysis have their own inherent limitations - they are not infinite in their capabilities, and with each design choice shifts the potential of what insights they can offer, such as the example given where Twitter and Facebook have poor archiving and search functions, focusing researchers’ attention on mainly present posts.

One of the reasons Big Data is so appealing is because of the idea that is offers an objective, quantifiable, accurate, and representative analysis, even for domains that are generally suffer from claims of subjectivity, such as social sciences. After all, how can one argue against a quantifiable dataset with millions of datapoints? Boyd and Crawford warn that this is  a misleading assumption. Working with Big Data is still subjective, and all researchers are interpreters of data, especially with the data cleaning process -- information filtering is inherently a natural subjective task. Additionally, Big Data presents another problem because with an overwhelming amount of data, it is possible to see almost any connection simply because of the immense amount of information available at the researcher’s disposal. It is also important to note that the datasets available for social science networks does not accurately represent the population. For instance, Twitter users are far from representing ‘all people,’ and in fact introduces several biases and skewed assumptions from the beginning. Taken out of context, Big Data loses its meaning as well, and its representation of personal networks is not encompassing. The number of likes and photos taken with a friend on Facebook is hardly exactly representative of the personal relationship with that friend in “real life.” It would be dangerous to believe that all things Big Data are objective truths, and in some cases even more valuable to hone in on ‘small data’ for stories and case studies, such as the work of Veinot (670).

Some unique limitations posed by Big Data stem from its inherent ties to technology, such as the issues of privacy and digital divides. The ethicality of using any available public posts on the internet, such as public blog posts or Facebook, is still unclear. What if, in the ocean of gathered data, your public post is taken out of context and grossly overanalyzed to reach some conclusion? Moreover, the technical skills and access to information required for Big Data analysis creates a digital divide between those who have the means to acquire the skills and information, and those who do not. Introducing specialized technological skills and privileged access to information widens the gap between scholars in the field, which is detrimental to social science research as a whole -- only a subset of researchers will have the means to determine how Big Data is used and who gets to participate, and that ultimately unfairly decides the future of the research field.

Hi Julia - 

Thanks for this post. I'm curious: what is 'unique' about the limitations of Big Data that is based in its 'inherent ties to technology'? Are there other forms of knowledge less-limited by their reliance on technology? 

Julia Guo: 
Hey Chris, thanks for the reply. Many of the limitations of Big Data I think are centered around its actual methodology and execution rather than the potential of its results (more to come on that later). If researchers want to use Big Data as their main method of analysis for a study, they are limited by the amount and kind of information available to them (such as which datasets they are given access to/allowed to use in a study) which ultimately determines what kinds of questions they are allowed to answer. Plus, this tie to technology (especially the Internet) adds another layer of uncertainty. A researcher might believe that a raw, unfiltered dataset of Twitter posts is in its purest form and a reliable starting point to use for analysis, but how many of those data points come from bot or spam posts? For social scientists, these present new obstacles that are much less apparent in direct human studies.

Other forms of knowledge are less limited in their initial execution methodology, since there are fewer unknowns and dependencies on technological capabilities (both in terms of technologies available and researchers' technical skills). But generally these other forms are more limited in the scope of their results. To perhaps oversimplify it, I would say Big Data analysis offers more breadth because it has the advantage of having so many data points, while other traditional forms of study (e.g. tracing archives, interviews, etc) offer more depth because they allow researchers to dive deeper into the lives of a smaller set of individuals.

I think that's mostly right, at least w/r/t that one weakness of Big Data (even as it might eventually be a strength) is that the amount/type of data collected is so capacious that it's hard to distinguish signal from noise, and so new that strong disciplinary traditions have not yet arisen to self-evaluate this kind of work. 

I'd push back a bit on the claim that other forms of knowledge-gathering are less-dependent on technologies, though. One mainstay of the field of science studies (of which STS is the department at MIT) is that when you change the instruments of analysis you change what the analysis will find. This includes (but goes beyond) e.g. the observer effect in physics. Even in anthropology or sociology, for example, there are pretty big debates about how talking to people online or through skype is different than in person, for example. This is one point that (personally) I don't think boyd and Crawford make quite strongly enough (mostly because it's not the goal of their paper). So IMHO it's not quite correct to say it's about being less-dependent, but rather a) dependent at a different point along the analytical chain, and b) more or less 'reflexive' (i.e., self-aware) about one's own dependency on the instruments of analysis. 

Christina Wang: 
DQ4: Why/how does Evelyth think self-tracking apps exclude women? What design methodologies or strategic approaches would you use to be less exclusive? (hint: the PLATO reading might be helpful here)

It goes without explaining that self-tracking apps, especially those released by companies with a global presence as widespread as Apple’s, should cater to all users. This is especially important for health tracking apps, since men and women have very specific differences in health. Of course menstruation is one of the more obvious, distinct differences, but by ignoring this feature in a health tracking app, Apple did themselves a great disservice by sending out a message that they do not fully acknowledging the most basic needs of all their users. 

As the article mentions, a main reason for this lack of attention is the great imbalance of men to women within the tech industry. In the Dynamic Interface Design course I am taking, we discussed how this imbalance within the gaming industry also negatively affects the products produced, resulting in highly objectified female characters, less girls being interested in (including competing in gaming competitions) or feeling comfortable pursuing careers within the field, and limited support for those who do. In addition, since those playing video games are mostly straight white men in their 20s, games are thus designed for straight white men in their 20s, capitalizing on objectified female characters and stereotypical masculine plot lines. 

The lack of menstruation tracking of a health app highlights a larger problem of the gender imbalance within the tech industry. The consequence results not only in products that exclude women, who comprise half the population of viable costumers, but also the normalization of this discrimination. Because Apple’s health app does not track menstruation, women will continue using period apps that do. Evelyth mentions that phones are designed for the bigger hands of men, yet there are little or no products available specialized for women, therefore women must continue using whatever models are being sold. 

The simple solution to this problem, as many other people have said, would be to hire more women or to promote and support girls who may be interested in joining, therefore adding diversity into the analysis and collection of user data, model designing, and general ideology that motivates concept designs, such as in the instance of sex tracking apps which currently cater only to straight male definitions of sex. Although this may help with the problem of bias in all of those areas, the reality is much more complex. Institutionalized sexism still affects women already in the industry, who, as minorities amongst their peers, suffer symptoms of the imposter syndrome, and have a limited access to resources and support because of the smaller size of their community. I believe that awareness of this issue needs to motivate the men already successful in the industry, so that they can effectively support women trying to balance the glaring gender inequality and exclusion. 

Hi Christina! 

Whoa, I have no idea how this was formatted, but I copied/pasted into another text editor to respond. 

>It goes without explaining that self-tracking apps, especially those released by companies with a global presence as widespread as Apple’s, should cater to all users. 

Similar to the question I asked Casie above (https://www.reddit.com/r/NetworkCultures16/comments/51u89m/week_2_responses_september_14th_cultures_of/d7lhacr), I'm actually interested if this *does* go without saying. I mean I think this is a compelling case, but there's another way to read feminist theory / the PLATO stuff which says the aspirations to universality are in fact what is problematic, and a networked universe of incomplete apps that *together* become sufficient is another approach. This is not incompatible with the desire to create a more diverse tech ecosystem, just another manifestation of it. I'm wondering if you have any thoughts or reactions to this line of thinking (which is not strongly held by me). 



Christina Wang: 
Hi Chris! Thank you for your reply. About the formatting, I reached out to Alyssa about how to fix it so hopefully everything should be good now!

Christina

Nick Gomez: 
SDQ8: What do boyd and Crawford see as some of the limitations of 'Big Data' and associated 'social network' research? How are these methods like or unlike other ways of understanding social science networks?


Boy’d and Crawford lay out six specific “provocations” that they see, from the perspective of social media scholars, as topics of discussion and debate in order to properly understand and scope the reach and efficacy of Big Data. To lay a common ground, Boy’d and Crawford define Big Data as “a cultural, technological, and scholarly phenomenon that rests on the interplay of technology, analysis, and mythology”. However, in doing so, Boy’d and Crawford build in skepticism into the definition of Big Data by presenting mythology as part of the definitive factors of interplay of Big Data. They make a scathing statement about the widespread “belief” that large data sets offer a higher form of intelligence, without quite taking the time and care to ask if that is a true statement (rather than a broad generalization from their impression) nor do they allowing room for a more nuanced and balanced explanation definition. This, alone, summarizes the commonalities of Boy’d and Crawford’s six “provocations”: a general skepticism towards what they see as overconfidence and over-reliance in Big Data as an “aura of truth, objectivity, and accuracy”.

The authors start their argumentation of the subject by stating that “Big Data changes the definition of knowledge”. They draw a comparison to Fordism and the assembly line and how it changed the understanding of labor as we knew it from a collection of artisan, specialized creators to the collective effort of low-skilled workers, machinery, and other factors of production are optimized for mass and rapid production. This is a rather emotive parallel as many people relate Fordism to the desensitization towards the individual, yet, it’s a strikingly strong parallel. In the same way that many were, and possibly still are, wary of that very desensitization of the individual, many people, including the authors, root their arguments and opinions on Big Data in the same manner. They content that Big Data scientists rely solely on the data and the end behavior of people rather than the the “why” as much as taxonomists, ontologists, and psychologists do. They contend that mapping out insights of the individual from huge and wildly data sets is myopic and misrepresentative, that Big Data scientists claim objectivity and quantifiable knowledge is limited because there is a “line between that is and is not quantifiable knowledge in the social domain”. They contend that Big Data is too big to be better, implying that Big Data scientists don’t have their work as rooted in “systematic approach to data collection and analysis” as ethnographers, experimentalists, survey researchers, and quantitative researchers. In short, the authors are skeptic of the over-confidence in big-data and its result insights, and are afraid that Big Data is dismissive of other kinds of social science and that it ignores the elements of those other social sciences which make them valuable. To be clear, there are many points of consideration in the paper that are worth of discussion, but it seems that the authors are more intent at undermining the Big Data than having a frank discussion about its possible limitations. Big Data is often used in conjunction with ideas and techniques from other social science methodology, often being framed from that perspective and trying to draw bigger patterns and substantiations to hypothesis formed in those other social domains. Big Data researchers are very aware that the “internet” self is likely not an ideal nor full characterization of the individual (although some argue it’s a good representation of the primitive and uninhibited self). In the end, Fordism, for all it’s faults and limitations, revolutionized the material and commercial world and allowed for the fast growth in material standard of living for the entire world. Similarly, Big Data gives us insights into the self in a scale and depth never achievable before, and with care, it already is and will continue to revolutionize our understanding of networks and individuals.


Hi Edwin - 

Thanks for this post. I think you did a good job summarizing the critiques that boyd and Crawford have for Big Data, but I'm wondering if you have a sense, from the piece or from your own prior experience, what some of the comparative strengths/weaknesses are to other social science approaches. Systematic, yes, but systematic *how*?

I think you're right that the point of this paper is to undermine 'Big Data,' or at the very least strongly critique it (or a popularly understood version of it). It's interesting to note that the authors are researchers embedded at Microsoft Research who frequently work with (in one case, is married to) big data researchers. Biography isn't the whole story, of course, but I think you've definitely picked up on some of the positioning that's going on here. 

Kenny (Kenneth) Friedman: 
DQ5: How does Winner think technologies can have political properties? Can you think of any technologies you've encountered in your own life that seem to you to have political properties or effects -- or conversely, where an effect was widely believed, but you found the opposite?

As Bob Dylan once said, “I've been through this movie before.”

In “Do Artifacts Have Politics?”, Winner makes the case that any technology or developed system effects the users. That is, technology can influence the “power and authority” in society. By pointing to a series of prior works, and going through numerous examples, he lays out the case that “social determinism”. Which is the idea that society dictates the future, is a flawed concept. Instead, technology inherently shapes cultural as much as cultural shapes technology. This occurs regardless of whether or not the technology was purposefully designed with certain goals in mind.

Three decades later, this piece holds up surprisingly well. The internet (whereby I mostly mean the World Wide Web), entered the zeitgeist approximately half way between now and when this piece was written. The internet is a world wide distributed network that allows the free flow of information and communication. So how could it possibly have political properties? 
Although I’ve only recently discovered and understood this to be the case, I would argue that the internet is not only an example of Winner’s political artifact, technological determinism stance, but in fact a prime example.

The main reason is that the internet is not fundamentally different from a societal perspective than previous technologies. It’s goals and ideals, connecting the world, archiving history, augmenting human intellect, etc. are not new ideals. Books, telephones, telegraphs, and many other technologies have had similar motivations, and yet their initial design impacted the cultural in unpredicted ways.

I believe it is impossible to tell how the current state of the internet is influencing society. However, since the technology is rapidly changing, we can look back to the past few years to understand how it’s changed and what effect it had in the internet’s previous state.

Hi Kenny - 

I think you're right about the consequences of Winner's argument - that technologies have political properties, and there's a feedback interaction between users and systems - but I'd like to see more here about the how he thinks it works (i.e., what are the specific mechanisms he proposes). 

I'm also not sure that Winner would consider himself a technological determinist (although some call him that), which, in its strong form at least, has a somewhat different set of arguments than those Winner advances in this piece. If you're going to characterize him as that, I'd like to see a bit more about what you think that means and why you think Winner fits the bill. 

Kenny (Kenneth) Friedman: 
Hi! Ok great, thanks for the feedback! Looking forward to tonight!

Erica Yuen: 
**DQ4: Why/how does Evelyth think self-tracking apps exclude women? What design methodologies or strategic approaches would you use to be less exclusive? (hint: the PLATO reading might be helpful here)**

Evelyth argues that self-tracking apps exclude women because they either ignore their needs or address them in a stereotypical fashion that are not actually effective. This issue exists primarily because the developers behind self-tracking apps and other related technologies consist mostly of men, who do not have the same motivations and experiences as women. As a result, while the designers of new self-tracking apps and related technologies may not be purposely excluding women, these apps are not improving the lives of women to the extent in which they are improving the lives of men. 
	
In her article “How Self-Tracking Apps Exclude Women,” Evelyth uses the Apple Health app as a primary example of this concern. The app, which was advertised as a tool that could “monitor all…metrics that you’re interested in” fails to address menstruation, a huge metric whose ease of tracking has been sought after by women for ages. As a result, an app that is advertised as “comprehensive” is only comprehensive for men, not women. Therefore, this technology excludes women as their target audience.

How does this exclusion happen? The article states that “the vast majority of tech companies are staffed by men, especially on the developmental side.” Self-tracking apps target metrics found in the human body. Given an end product to design, the developers would create the technology based on ideas that they believe would best improve the lives of their audience. However, male developers would most likely have different ideas than female developers, since they will have different experiences.  According to the excerpt “Situated Knowers” from Stanford PLATO, “People have first-personal access to some of their own bodily and mental states, yielding direct knowledge of phenomenological facts about what it is like for them to be in these states. Third parties may know these states only by interpreting external symptoms, imaginative projection, or obtaining their testimony.” In other words, only women can fully understand their own bodily needs because they are the only ones with first-person access to their bodily experiences. Therefore, a team comprised of mostly men can will mostly properly target the needs of men, not women.
	
Gender imbalance of technology development results in products that address what men think women want, rather than what women really want. For example, Evelyth highlights the fact that many menstruation tracking apps are full of flowers, the color pink, and other stereotypical feminine elements. In addition, many of these apps focus on mood swings and other features that target the partner of the woman rather than the woman herself. 
	
The solution to this gender exclusion is more complex than simply encouraging women to join technological development. When Ida Tin developed Clue, an app for menstruation tracking, she felt like her product had to be validated by men first. She felt that her and her team “were very lucky because about a month before we launched Max announced he was launching Glow… he kind of validated this category of apps, and he could do that because he’s a celebrity and he’s a nerdy guy who knows about data.” In order to tackle the gender exclusion problem for the future, not only do we need to encourage more women to pursue developing technology in order to address the needs of women using their experiences, we also need to reduce gender stereotyping in general so that women do not need to depend on men to validate their products. By reducing barriers such as expected gender roles and providing more opportunities for women to be exposed to and excel in technology so that they can be a greater influence in developing these apps, these self-tracking apps will then not exclude women like they do today. 


Hi Erica - 

I think you've accurately summarized most of Evelyth's key points. I'm glad to see you bringing the PLATO reading in. It's worth thinking about how situated knowledges work across multiple modalities of identity: not only gender, but other intersections (i.e., can one or some women speak on behalf of all women?). Not a defense of Apple, but (since I know you're 6-3, right?) an enumeration of the difficulty, when trying to build a diverse team, knowing what kind of diversity you need, and how to know when you have it. 

Jonathan Sun: 
**DQ4: Why/how does Evelyth think self-tracking apps exclude women? What design methodologies or strategic approaches would you use to be less exclusive? (hint: the PLATO reading might be helpful here)**

Much of this discussion makes me think of Wayne Brekhus’ Sociology of the Unmarked, and the distinction between Marked and Unmarked cultures/people. Brekhus defines Marked groups as those singled out or explicitly defined as “different” or “deviant” from the norm, whereas Unmarked groups are accepted as the default or the norm and therefore escape scrutiny or examination. This potentially creates a larger gap or divide, due to the process of “othering” Marked groups due to the fact that they were marked. Evelyth opens the piece by highlighting the male majority at Apple. In Evelyth’s piece, and in tech in general, the default unmarked group are men – they are seen as the neutral, “general population” – whereas women are treated as a marked group – a distinctly different set of users. Because female-oriented apps are oriented as a distinction from a male norm, and are seen as for a special population, women are cast away from the “norm”. The needs of women are excluded or marginalized.

From this framework, of viewing male needs as the default, unmarked state, any feature for women is “othered”. And when these female-focused apps are design by men on in a predominantly male culture, we see that insulting image of pink, flowery interfaces on period trackers.

One point I’m struck with in the Winner piece is that this is not a new problem -- that perhaps inherently political or politicized technology has existed for as long as technology has existed. I don’t think it’s always as malicious or intentional as Moses’ lowrise underpasses, but technology, it can be argued, has always reflected the power structures of the society from which they were created, and explicitly or not, reinforced the attitudes of those in power.

Because tech is a male-dominated field, we’ve seen that it is slow and stubborn in recognizing non-male-focused needs as any sort of norm (or even as a set of needs that even need to be addressed!). The current direction and attitudes in tech seem to tend toward “leaving women to design for women” while men design for what they declare is “everyone” but is actually focused on men. While women designing for women is a development, I think that the patriarchy is still in place because female-focused apps are being othered, and marked as different from a male-centric norm. 

Evelyth concludes the piece by saying there is no universal list that applies to everyone – I agree. And I agree in regards to the Plato piece that one needs to have some sort of lived experience to understand how to design for the needs of a that particular group. One issue is the acceptance of male needs as the norm, as the needs of an undefined everybody. I’d like to imagine that an approach that would help is an acknowledgement of implicit male-focus in products designed by men or in a male-dominant society. By Marking men, or calling out the implicit bias of declaring the unmarked neutral as actually a marked male group, perhaps we can step away from the idea of “normal” or “general” focus. I don’t think this is the end game, but I think there needs to be an acknowledgement of a patriarchal power structure in order for more inclusive change to occur. 


> In Evelyth’s piece, and in tech in general, the default unmarked group are men – they are seen as the neutral, “general population” – whereas women are treated as a marked group – a distinctly different set of users. Because female-oriented apps are oriented as a distinction from a male norm, and are seen as for a special population, women are cast away from the “norm”. 

I think this is a really great point: it's not only about exclusion, but marked as different (i.e., exclusion as naturalized common knowledge), that is part of the complicating/alienating factor here. 

